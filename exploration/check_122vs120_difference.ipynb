{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Check not dropping 2 stations\n",
    "- I have values slightly differing from the Paper\n",
    "- the only changes I undertook are dropping 2 stations due to nan values and including early stopping.\n",
    "- My hypothesis is that this action might lead to a better result\n",
    "- Therefore, I will check if the GNN gives the same result as in the Paper if I do not drop the 2 stations"
   ],
   "id": "491e7223665b3c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T17:56:35.264737Z",
     "start_time": "2025-05-17T17:56:35.253512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%cd /home/ltchen/gnnpp\n",
    "import sys\n",
    "import json\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
    "from torch.optim import AdamW\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils.data122 import *\n",
    "from exploration.get_graphs_and_data import *\n"
   ],
   "id": "69f43aaf9b342316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T17:56:36.570136Z",
     "start_time": "2025-05-17T17:56:36.562366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "DIRECTORY = os.getcwd()\n",
    "print(DIRECTORY)\n",
    "\n",
    "leadtime = \"24h\"\n",
    "graph_name = \"g1\"\n",
    "\n",
    "# JSONPATH, SAVEPATH, RESULTPATH = get_json_save_result_paths(leadtime=leadtime, graph_name=graph_name)"
   ],
   "id": "e6f5f935aea88c4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T17:56:43.132915Z",
     "start_time": "2025-05-17T17:56:38.129522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = load_dataframes_1(leadtime=leadtime)\n",
    "dataframes = summary_statistics(dataframes)"
   ],
   "id": "2bb0ba18bf4ef35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for valid\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T17:56:43.561650Z",
     "start_time": "2025-05-17T17:56:43.138628Z"
    }
   },
   "cell_type": "code",
   "source": "dataframes['train'][0].nunique()",
   "id": "b5e3d10e26b677ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time                  2612\n",
       "station_id             122\n",
       "model_orography        116\n",
       "station_altitude       118\n",
       "station_latitude       122\n",
       "                     ...  \n",
       "v_mean              306905\n",
       "v_std               308216\n",
       "t_mean              248620\n",
       "t_std               308216\n",
       "number                   1\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T17:54:34.193882Z",
     "start_time": "2025-05-17T17:54:34.181793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graph_name = \"g1\"\n",
    "drn = False\n",
    "if drn == True:\n",
    "    SAVEPATH = os.path.join(DIRECTORY, f\"leas_trained_models/drn_{leadtime}/models\")\n",
    "    JSONPATH = os.path.join(DIRECTORY, f\"trained_models/drn_{leadtime}/params.json\")\n",
    "else:\n",
    "    SAVEPATH = os.path.join(DIRECTORY, f\"leas_trained_models/sum_stats_{leadtime}/122{graph_name}_{leadtime}/models\")\n",
    "    JSONPATH = os.path.join(DIRECTORY, f\"leas_trained_models/sum_stats_{leadtime}/{graph_name}_{leadtime}/params.json\")\n",
    "    RESULTPATH = os.path.join(DIRECTORY, f\"leas_trained_models/sum_stats_{leadtime}/122{graph_name}_{leadtime}\")\n",
    "\n",
    "\n",
    "with open(JSONPATH, \"r\") as f:\n",
    "    print(f\"[INFO] Loading {JSONPATH}\")\n",
    "    args_dict = json.load(f)\n",
    "config = args_dict\n",
    "\n",
    "print(SAVEPATH)\n",
    "print(JSONPATH)\n",
    "print(RESULTPATH)"
   ],
   "id": "4eac5b9a66b0847",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/g1_24h/params.json\n",
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models\n",
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/g1_24h/params.json\n",
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:24:56.451972Z",
     "start_time": "2025-05-10T06:24:27.564362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graphs1_train_rf, tests1 = normalize_features_and_create_graphs1(df_train=dataframes['train'], df_valid_test=[dataframes['valid'], dataframes['test_rf'], dataframes['test_f']], station_df=dataframes['stations'], attributes=[\"geo\"], edges=[(\"geo\", 50)], sum_stats = True)\n",
    "graphs1_valid_rf, graphs1_test_rf, graphs1_test_f = tests1\n",
    "\n",
    "g1_train_loader = DataLoader(graphs1_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "g1_valid_loader = DataLoader(graphs1_valid_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "g1_test_f_loader = DataLoader(graphs1_test_f, batch_size=config['batch_size'], shuffle=False)\n",
    "g1_test_rf_loader = DataLoader(graphs1_test_rf, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "train_loader = g1_train_loader\n",
    "valid_loader = g1_valid_loader\n",
    "test_f_loader = g1_test_f_loader\n",
    "test_rf_loader = g1_test_rf_loader\n",
    "test_loader = [test_f_loader, test_rf_loader]\n",
    "\n",
    "emb_dim = 20\n",
    "in_channels = graphs1_train_rf[0].x.shape[1] + emb_dim - 1\n",
    "edge_dim = graphs1_train_rf[0].num_edge_features\n",
    "# max_epochs = 100"
   ],
   "id": "36a4e160e47033a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n",
      "transform 2\n",
      "transform 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2612/2612 [00:12<00:00, 217.16it/s]\n",
      "100%|██████████| 836/836 [00:03<00:00, 264.88it/s]\n",
      "100%|██████████| 732/732 [00:02<00:00, 288.82it/s]\n",
      "100%|██████████| 730/730 [00:02<00:00, 260.45it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:24:56.467251Z",
     "start_time": "2025-05-10T06:24:56.461047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_epochs = config['max_epochs']\n",
    "num_nodes = graphs1_train_rf[0].num_nodes\n",
    "print(max_epochs)\n",
    "print(num_nodes)"
   ],
   "id": "38ab5e11ee3745ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "122\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T05:09:01.880609Z",
     "start_time": "2025-05-10T05:08:59.927068Z"
    }
   },
   "cell_type": "code",
   "source": "print(load_distances_1(dataframes['stations']).shape)",
   "id": "52e7c6d52360a40b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Computing distances...\n",
      "(122, 122)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:37:06.084693Z",
     "start_time": "2025-05-10T06:25:36.133028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECTNAME = \"g122_run1\"\n",
    "\n",
    "for i in range(5, 11):\n",
    "    TRAINNAME = f\"{graph_name}_{leadtime}_train_run{i}_max_epoch23\"\n",
    "\n",
    "    with wandb.init(\n",
    "            project=PROJECTNAME, id=TRAINNAME, config=args_dict, tags=[\"check_122\"], resume=\"never\"\n",
    "    ):\n",
    "        config = wandb.config\n",
    "\n",
    "        multigraph = Multigraph(\n",
    "            num_nodes=num_nodes, #\n",
    "            embedding_dim=emb_dim,\n",
    "            edge_dim=edge_dim,\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels_gnn=config['gnn_hidden'],\n",
    "            out_channels_gnn=config['gnn_hidden'],\n",
    "            num_layers_gnn=config['gnn_layers'],\n",
    "            heads=config['heads'],\n",
    "            hidden_channels_deepset=config['gnn_hidden'],\n",
    "            optimizer_class=AdamW,\n",
    "            optimizer_params=dict(lr=config['lr']),\n",
    "        )\n",
    "        torch.compile(multigraph)\n",
    "        batch = next(iter(train_loader))\n",
    "        multigraph.forward(batch)\n",
    "\n",
    "        wandb_logger = WandbLogger(project=PROJECTNAME)\n",
    "        # early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "        progress_bar = TQDMProgressBar(refresh_rate=0)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=SAVEPATH, filename=TRAINNAME, monitor=\"val_loss\", mode=\"min\", save_top_k=1\n",
    "        )\n",
    "\n",
    "        trainer = L.Trainer(\n",
    "                max_epochs=max_epochs,\n",
    "                log_every_n_steps=1,\n",
    "                accelerator=\"gpu\",\n",
    "                devices = 1,\n",
    "                enable_progress_bar=True,\n",
    "                logger=wandb_logger,\n",
    "                # callbacks=[early_stop, progress_bar, checkpoint_callback],\n",
    "                callbacks=[checkpoint_callback, progress_bar],\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=multigraph, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ],
   "id": "320fc7962c316eda",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mleachen01\u001B[0m (\u001B[33mleachen01-karlsruhe-institute-of-technology\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250510_082536-g1_24h_train_run5_max_epoch23</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run5_max_epoch23' target=\"_blank\">g1_24h_train_run5_max_epoch23</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run5_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run5_max_epoch23</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 878 K  | train\n",
      "2 | aggr        | DeepSetAggregator | 197 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.317     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=23` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▂▃▂▂▃▂▂▁▂▁▂▁▁▁▁▁▁▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>train_loss_epoch</td><td>0.6017</td></tr><tr><td>train_loss_step</td><td>0.60181</td></tr><tr><td>trainer/global_step</td><td>7520</td></tr><tr><td>val_loss</td><td>0.68253</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g1_24h_train_run5_max_epoch23</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run5_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run5_max_epoch23</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250510_082536-g1_24h_train_run5_max_epoch23/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250510_082732-g1_24h_train_run6_max_epoch23</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run6_max_epoch23' target=\"_blank\">g1_24h_train_run6_max_epoch23</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run6_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run6_max_epoch23</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 878 K  | train\n",
      "2 | aggr        | DeepSetAggregator | 197 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.317     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=23` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▅▄▃▆▆▃▃▃▄▂▂▂▂▃▂▃▄▁▂▂▄▄▃▁▃▂▃▃▄▃▁▃▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>train_loss_epoch</td><td>0.60709</td></tr><tr><td>train_loss_step</td><td>0.57233</td></tr><tr><td>trainer/global_step</td><td>7520</td></tr><tr><td>val_loss</td><td>0.66634</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g1_24h_train_run6_max_epoch23</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run6_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run6_max_epoch23</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250510_082732-g1_24h_train_run6_max_epoch23/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250510_082928-g1_24h_train_run7_max_epoch23</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run7_max_epoch23' target=\"_blank\">g1_24h_train_run7_max_epoch23</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run7_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run7_max_epoch23</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 878 K  | train\n",
      "2 | aggr        | DeepSetAggregator | 197 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.317     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=23` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>train_loss_epoch</td><td>0.60124</td></tr><tr><td>train_loss_step</td><td>0.52883</td></tr><tr><td>trainer/global_step</td><td>7520</td></tr><tr><td>val_loss</td><td>0.65599</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g1_24h_train_run7_max_epoch23</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run7_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run7_max_epoch23</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250510_082928-g1_24h_train_run7_max_epoch23/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250510_083122-g1_24h_train_run8_max_epoch23</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run8_max_epoch23' target=\"_blank\">g1_24h_train_run8_max_epoch23</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run8_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run8_max_epoch23</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 878 K  | train\n",
      "2 | aggr        | DeepSetAggregator | 197 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.317     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=23` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▃▂▂▂▁▂▂▁▁▁▁▂▁▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>train_loss_epoch</td><td>0.60666</td></tr><tr><td>train_loss_step</td><td>0.60735</td></tr><tr><td>trainer/global_step</td><td>7520</td></tr><tr><td>val_loss</td><td>0.70218</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g1_24h_train_run8_max_epoch23</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run8_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run8_max_epoch23</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250510_083122-g1_24h_train_run8_max_epoch23/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250510_083317-g1_24h_train_run9_max_epoch23</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run9_max_epoch23' target=\"_blank\">g1_24h_train_run9_max_epoch23</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run9_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run9_max_epoch23</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 878 K  | train\n",
      "2 | aggr        | DeepSetAggregator | 197 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.317     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=23` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▄▅▆▄▃▅▃▃▃▃▂▃▃▃▂▃▁▃▃▄▃▃▁▁▂▁▃▁▂▂▃▂▂▁▁▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▄▃▃▄▂▃▂▃▂▂▂▁▂▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>train_loss_epoch</td><td>0.60573</td></tr><tr><td>train_loss_step</td><td>0.63176</td></tr><tr><td>trainer/global_step</td><td>7520</td></tr><tr><td>val_loss</td><td>0.66172</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g1_24h_train_run9_max_epoch23</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run9_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run9_max_epoch23</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250510_083317-g1_24h_train_run9_max_epoch23/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250510_083512-g1_24h_train_run10_max_epoch23</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run10_max_epoch23' target=\"_blank\">g1_24h_train_run10_max_epoch23</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run10_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run10_max_epoch23</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 878 K  | train\n",
      "2 | aggr        | DeepSetAggregator | 197 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.317     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=23` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇█▆▅▂▄▄▅▃▃▃▃▂▃▃▃▅▃▄▃▃▂▃▂▅▁▂▄▂▃▃▃▅▂▁▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▃▃▃▃▂▂▃▁▂▁▁▁▁▁▁▁▁▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>train_loss_epoch</td><td>0.6085</td></tr><tr><td>train_loss_step</td><td>0.67044</td></tr><tr><td>trainer/global_step</td><td>7520</td></tr><tr><td>val_loss</td><td>0.66827</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g1_24h_train_run10_max_epoch23</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run10_max_epoch23' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1/runs/g1_24h_train_run10_max_epoch23</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/g122_run1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250510_083512-g1_24h_train_run10_max_epoch23/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:37:20.448529Z",
     "start_time": "2025-05-10T06:37:06.116111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_list = [\"f\", \"rf\"]\n",
    "print(SAVEPATH)\n",
    "for data, tl in zip(data_list, test_loader):\n",
    "    preds_list = []\n",
    "    for path in os.listdir(SAVEPATH):\n",
    "        if path.endswith(\".ckpt\"):\n",
    "            print(f\"[INFO] Loading model from {path}\")\n",
    "            # Load Model from checkpoint\n",
    "\n",
    "            multigraph = Multigraph.load_from_checkpoint(\n",
    "                os.path.join(SAVEPATH, path),\n",
    "                num_nodes=num_nodes,\n",
    "                embedding_dim=emb_dim,\n",
    "                edge_dim=edge_dim,\n",
    "                in_channels=in_channels,\n",
    "                hidden_channels_gnn=config['gnn_hidden'],\n",
    "                out_channels_gnn=config['gnn_hidden'],\n",
    "                num_layers_gnn=config['gnn_layers'],\n",
    "                heads=config['heads'],\n",
    "                hidden_channels_deepset=config['gnn_hidden'],\n",
    "                optimizer_class=AdamW,\n",
    "                optimizer_params=dict(lr=config['lr']),\n",
    "            )\n",
    "            multigraph.eval()\n",
    "            batch = next(iter(train_loader))\n",
    "            batch = batch.to(\"cuda\")\n",
    "            multigraph.to(\"cuda\")\n",
    "            multigraph.forward(batch)\n",
    "\n",
    "            trainer = L.Trainer(log_every_n_steps=1, accelerator=\"gpu\", devices=[1], enable_progress_bar=True)\n",
    "\n",
    "            ####################################################################################################\n",
    "            preds = trainer.predict(model=multigraph, dataloaders=[tl])\n",
    "            preds = torch.cat(preds, dim=0)\n",
    "            preds_list.append(preds)\n",
    "            print()\n",
    "            print(preds.shape)\n",
    "\n",
    "    targets = dataframes[f\"test_{data}\"][1]\n",
    "    targets = torch.tensor(targets.t2m.values) - 273.15\n",
    "\n",
    "    stacked = torch.stack(preds_list)\n",
    "    final_preds = torch.mean(stacked, dim=0)\n",
    "\n",
    "    res = multigraph.loss_fn.crps(final_preds, targets)\n",
    "    print(\"#############################################\")\n",
    "    print(\"#############################################\")\n",
    "    print(f\"final crps for {data}: {res.item()}\")\n",
    "    print(\"#############################################\")\n",
    "    print(\"#############################################\")\n",
    "\n",
    "    ####################################################################################################\n",
    "    os.makedirs(RESULTPATH, exist_ok=True)\n",
    "    print(RESULTPATH)\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate([targets.view(-1, 1), final_preds], axis=1), columns=[\"t2m\", \"mu\", \"sigma\"])\n",
    "    df.to_csv(os.path.join(RESULTPATH, f\"{data}_{graph_name}_{leadtime}_results.csv\"), index=False)\n",
    "\n",
    "    # Create Log File ###############################################################\n",
    "    log_file = os.path.join(RESULTPATH, f\"{data}.txt\")\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(f\"Data: {data}\\n\")\n",
    "        f.write(f\"Leadtime: {leadtime}\\n\")\n",
    "        f.write(f\"Final crps: {res.item()}\")"
   ],
   "id": "7fe56e47a7b49ac6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models\n",
      "[INFO] Loading model from g1_24h_train_run5_max_epoch23.ckpt\n",
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 144.24it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run9_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 179.42it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run3_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 178.92it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run0_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 173.52it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run6_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 158.15it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run7_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 179.05it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run1_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 154.17it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run8_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 172.65it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run10_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 155.29it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run2_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 165.55it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "#############################################\n",
      "#############################################\n",
      "final crps for f: 0.6168083832539281\n",
      "#############################################\n",
      "#############################################\n",
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model from g1_24h_train_run5_max_epoch23.ckpt\n",
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 181.58it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run9_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 178.18it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run3_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 151.88it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run0_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 167.38it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run6_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 161.01it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run7_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 162.64it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run1_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 154.13it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run8_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 151.26it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run10_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 161.66it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run2_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 183.69it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "#############################################\n",
      "#############################################\n",
      "final crps for rf: 0.6250079273463535\n",
      "#############################################\n",
      "#############################################\n",
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:48:25.242748Z",
     "start_time": "2025-05-10T06:48:16.916260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_list = [\"f\", \"rf\"]\n",
    "print(SAVEPATH)\n",
    "for data, tl in zip(data_list, test_loader):\n",
    "    preds_list = []\n",
    "    for path in os.listdir(SAVEPATH):\n",
    "        if path.endswith(\".ckpt\"):\n",
    "            print(f\"[INFO] Loading model from {path}\")\n",
    "            # Load Model from checkpoint\n",
    "\n",
    "            multigraph = Multigraph.load_from_checkpoint(\n",
    "                os.path.join(SAVEPATH, path),\n",
    "                num_nodes=num_nodes,\n",
    "                embedding_dim=emb_dim,\n",
    "                edge_dim=edge_dim,\n",
    "                in_channels=in_channels,\n",
    "                hidden_channels_gnn=config['gnn_hidden'],\n",
    "                out_channels_gnn=config['gnn_hidden'],\n",
    "                num_layers_gnn=config['gnn_layers'],\n",
    "                heads=config['heads'],\n",
    "                hidden_channels_deepset=config['gnn_hidden'],\n",
    "                optimizer_class=AdamW,\n",
    "                optimizer_params=dict(lr=config['lr']),\n",
    "            )\n",
    "            multigraph.eval()\n",
    "            batch = next(iter(train_loader))\n",
    "            batch = batch.to(\"cuda\")\n",
    "            multigraph.to(\"cuda\")\n",
    "            multigraph.forward(batch)\n",
    "\n",
    "            trainer = L.Trainer(log_every_n_steps=1, accelerator=\"gpu\", devices=[1], enable_progress_bar=False)\n",
    "\n",
    "            ####################################################################################################\n",
    "            preds = trainer.predict(model=multigraph, dataloaders=[tl])\n",
    "            preds = torch.cat(preds, dim=0)\n",
    "            # preds_list.append(preds)\n",
    "            print()\n",
    "            print(preds.shape)\n",
    "\n",
    "            targets = dataframes[f\"test_{data}\"][1]\n",
    "            targets = torch.tensor(targets.t2m.values) - 273.15\n",
    "\n",
    "            #stacked = torch.stack(preds_list)\n",
    "            #final_preds = torch.mean(stacked, dim=0)\n",
    "\n",
    "            res = multigraph.loss_fn.crps(preds, targets).item()\n",
    "            # print(res)\n",
    "            preds_list.append(res)\n",
    "\n",
    "    print(len(preds_list))\n",
    "    mean = sum(preds_list) / len(preds_list)\n",
    "    print(\"#############################################\")\n",
    "    print(\"#############################################\")\n",
    "    print(f\"mean crps for {data}: {mean}\")\n",
    "    print(\"#############################################\")\n",
    "    print(\"#############################################\")\n",
    "\n",
    "    ####################################################################################################\n",
    "'''\n",
    "    os.makedirs(RESULTPATH, exist_ok=True)\n",
    "    print(RESULTPATH)\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate([targets.view(-1, 1), final_preds], axis=1), columns=[\"t2m\", \"mu\", \"sigma\"])\n",
    "    df.to_csv(os.path.join(RESULTPATH, f\"{data}_{graph_name}_{leadtime}_results.csv\"), index=False)\n",
    "\n",
    "    # Create Log File ###############################################################\n",
    "    log_file = os.path.join(RESULTPATH, f\"{data}.txt\")\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(f\"Data: {data}\\n\")\n",
    "        f.write(f\"Leadtime: {leadtime}\\n\")\n",
    "        f.write(f\"Final crps: {res.item()}\")\n",
    "'''"
   ],
   "id": "b260b35a5f60d81f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models\n",
      "[INFO] Loading model from g1_24h_train_run5_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run9_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run3_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run0_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run6_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run7_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run1_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run8_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run10_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "[INFO] Loading model from g1_24h_train_run2_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89060, 2])\n",
      "10\n",
      "#############################################\n",
      "#############################################\n",
      "mean crps for f: 0.6355066190245144\n",
      "#############################################\n",
      "#############################################\n",
      "[INFO] Loading model from g1_24h_train_run5_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run9_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run3_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run0_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run6_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run7_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run1_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run8_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run10_max_epoch23.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([89304, 2])\n",
      "[INFO] Loading model from g1_24h_train_run2_max_epoch23.ckpt\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "10\n",
      "#############################################\n",
      "#############################################\n",
      "mean crps for rf: 0.6443902809471849\n",
      "#############################################\n",
      "#############################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    os.makedirs(RESULTPATH, exist_ok=True)\\n    print(RESULTPATH)\\n\\n    df = pd.DataFrame(np.concatenate([targets.view(-1, 1), final_preds], axis=1), columns=[\"t2m\", \"mu\", \"sigma\"])\\n    df.to_csv(os.path.join(RESULTPATH, f\"{data}_{graph_name}_{leadtime}_results.csv\"), index=False)\\n\\n    # Create Log File ###############################################################\\n    log_file = os.path.join(RESULTPATH, f\"{data}.txt\")\\n    with open(log_file, \"w\") as f:\\n        f.write(f\"Data: {data}\\n\")\\n        f.write(f\"Leadtime: {leadtime}\\n\")\\n        f.write(f\"Final crps: {res.item()}\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T06:42:32.453942Z",
     "start_time": "2025-05-10T06:42:32.367615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f_df = pd.read_csv(os.path.join(RESULTPATH, f\"f_{graph_name}_{leadtime}_results.csv\"))\n",
    "f_df"
   ],
   "id": "2abb260a3bbc87b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       t2m        mu     sigma\n",
       "0      5.5  5.584488  0.870826\n",
       "1      2.1  1.735488  0.907235\n",
       "2      6.6  5.977023  0.867696\n",
       "3      6.0  5.880330  0.909379\n",
       "4      1.9  1.077887  0.933794\n",
       "...    ...       ...       ...\n",
       "89055  4.8  5.256744  1.192812\n",
       "89056  3.7  4.261754  1.431870\n",
       "89057  3.2  3.373278  1.461015\n",
       "89058 -2.5 -1.312616  1.152949\n",
       "89059 -4.3 -1.212199  1.162798\n",
       "\n",
       "[89060 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t2m</th>\n",
       "      <th>mu</th>\n",
       "      <th>sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.584488</td>\n",
       "      <td>0.870826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1</td>\n",
       "      <td>1.735488</td>\n",
       "      <td>0.907235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.6</td>\n",
       "      <td>5.977023</td>\n",
       "      <td>0.867696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.880330</td>\n",
       "      <td>0.909379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.9</td>\n",
       "      <td>1.077887</td>\n",
       "      <td>0.933794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89055</th>\n",
       "      <td>4.8</td>\n",
       "      <td>5.256744</td>\n",
       "      <td>1.192812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89056</th>\n",
       "      <td>3.7</td>\n",
       "      <td>4.261754</td>\n",
       "      <td>1.431870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89057</th>\n",
       "      <td>3.2</td>\n",
       "      <td>3.373278</td>\n",
       "      <td>1.461015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89058</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>-1.312616</td>\n",
       "      <td>1.152949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89059</th>\n",
       "      <td>-4.3</td>\n",
       "      <td>-1.212199</td>\n",
       "      <td>1.162798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89060 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T23:34:25.871892Z",
     "start_time": "2025-05-09T23:34:23.833391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_list = [\"f\", \"rf\"]\n",
    "print(SAVEPATH)\n",
    "for data, tl in zip(data_list, test_loader):\n",
    "    preds_list = []\n",
    "    # for path in os.listdir(SAVEPATH):\n",
    "        # if path.endswith(\".ckpt\"):\n",
    "    path = os.path.join(SAVEPATH, f\"{graph_name}_{leadtime}_train_run1-v1.ckpt\")\n",
    "    print(f\"[INFO] Loading model from {path}\")\n",
    "    # Load Model from checkpoint\n",
    "\n",
    "    multigraph = Multigraph.load_from_checkpoint(\n",
    "        os.path.join(SAVEPATH, path),\n",
    "        num_nodes=num_nodes,\n",
    "        embedding_dim=emb_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    multigraph.eval()\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch.to(\"cuda\")\n",
    "    multigraph.to(\"cuda\")\n",
    "    multigraph.forward(batch)\n",
    "\n",
    "    trainer = L.Trainer(log_every_n_steps=1, accelerator=\"gpu\", devices=[1], enable_progress_bar=True)\n",
    "\n",
    "    ####################################################################################################\n",
    "    preds = trainer.predict(model=multigraph, dataloaders=[tl])\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    preds_list.append(preds)\n",
    "    print()\n",
    "    print(preds.shape)\n",
    "\n",
    "    targets = dataframes[f\"test_{data}\"][1]\n",
    "    targets = torch.tensor(targets.t2m.values) - 273.15\n",
    "\n",
    "    stacked = torch.stack(preds_list)\n",
    "    final_preds = torch.mean(stacked, dim=0)\n",
    "\n",
    "    res = multigraph.loss_fn.crps(final_preds, targets)\n",
    "    print(\"#############################################\")\n",
    "    print(\"#############################################\")\n",
    "    print(f\"final crps for {data}: {res.item()}\")\n",
    "    print(\"#############################################\")\n",
    "    print(\"#############################################\")\n",
    "\n",
    "    ####################################################################################################\n",
    "    os.makedirs(RESULTPATH, exist_ok=True)\n",
    "    print(RESULTPATH)\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate([targets.view(-1, 1), final_preds], axis=1), columns=[\"t2m\", \"mu\", \"sigma\"])\n",
    "    df.to_csv(os.path.join(RESULTPATH, f\"{data}_{graph_name}_{leadtime}_results.csv\"), index=False)\n",
    "\n",
    "    # Create Log File ###############################################################\n",
    "    log_file = os.path.join(RESULTPATH, f\"{data}.txt\")\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(f\"Data: {data}\\n\")\n",
    "        f.write(f\"Leadtime: {leadtime}\\n\")\n",
    "        f.write(f\"Final crps: {res.item()}\")"
   ],
   "id": "75a083afc9cd9e69",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models\n",
      "[INFO] Loading model from /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models/g1_24h_train_run1-v1.ckpt\n",
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 158.85it/s]\n",
      "\n",
      "torch.Size([89060, 2])\n",
      "#############################################\n",
      "#############################################\n",
      "final crps for f: 0.6443530764200678\n",
      "#############################################\n",
      "#############################################\n",
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model from /home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h/models/g1_24h_train_run1-v1.ckpt\n",
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:00<00:00, 159.33it/s]\n",
      "\n",
      "torch.Size([89304, 2])\n",
      "#############################################\n",
      "#############################################\n",
      "final crps for rf: 0.6451957248009318\n",
      "#############################################\n",
      "#############################################\n",
      "/home/ltchen/gnnpp/leas_trained_models/sum_stats_24h/122g1_24h\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
