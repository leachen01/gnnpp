{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-15T04:29:02.174115Z",
     "start_time": "2025-04-15T04:28:58.611903Z"
    }
   },
   "source": [
    "%cd /home/ltchen/gnnpp\n",
    "import sys\n",
    "import os\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torch_geometric\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.utils import scatter\n",
    "from torch.nn import Linear, ModuleList, ReLU\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.optim import AdamW\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from models.loss import NormalCRPS\n",
    "from models.model_utils import MakePositive, EmbedStations\n",
    "from utils.data import (\n",
    "    load_dataframes,\n",
    "    load_distances,\n",
    "    normalize_features_and_create_graphs,\n",
    "    rm_edges,\n",
    "    summary_statistics,\n",
    ")\n",
    "from exploration.graph_creation import *\n",
    "from models.graphensemble import *"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:29:05.476744Z",
     "start_time": "2025-04-15T04:29:05.469345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "DIRECTORY = os.getcwd()\n",
    "SAVEPATH = os.path.join(DIRECTORY, \"explored_models/gnn_new_attr_24h/models\")\n",
    "JSONPATH = os.path.join(DIRECTORY, \"trained_models/best_24h/params.json\")"
   ],
   "id": "12226f102ec600be",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:30:35.941951Z",
     "start_time": "2025-04-15T04:29:19.103763Z"
    }
   },
   "cell_type": "code",
   "source": "dataframes = load_dataframes(mode=\"eval\", leadtime= \"24h\")",
   "id": "c55d87460c21cbe0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data files not found, will load from zarr.\n",
      "[INFO] Loading data...\n",
      "[INFO] Loading all features\n",
      "[INFO] Loading training data (1997-2013)\n",
      "<xarray.Dataset>\n",
      "Dimensions:             (station_id: 122, number: 11, time: 3449)\n",
      "Coordinates: (12/13)\n",
      "    model_altitude      (station_id) float32 ...\n",
      "    model_land_usage    (station_id) int8 ...\n",
      "    model_latitude      (station_id) float64 ...\n",
      "    model_longitude     (station_id) float64 ...\n",
      "    model_orography     (station_id) float64 ...\n",
      "  * number              (number) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "    ...                  ...\n",
      "  * station_id          (station_id) int64 11101 11105 11308 ... 340 344 330\n",
      "    station_land_usage  (station_id) int8 ...\n",
      "    station_latitude    (station_id) float64 ...\n",
      "    station_longitude   (station_id) float64 ...\n",
      "    station_name        (station_id) <U20 ...\n",
      "  * time                (time) datetime64[ns] 1997-01-02 ... 2014-01-01\n",
      "Data variables: (12/30)\n",
      "    cape                (station_id, number, time) float32 ...\n",
      "    cin                 (station_id, number, time) float32 ...\n",
      "    cp6                 (station_id, number, time) float32 ...\n",
      "    mn2t6               (station_id, number, time) float32 ...\n",
      "    mx2t6               (station_id, number, time) float32 ...\n",
      "    p10fg6              (station_id, number, time) float32 ...\n",
      "    ...                  ...\n",
      "    u100                (station_id, number, time) float32 ...\n",
      "    v                   (station_id, number, time) float32 ...\n",
      "    v10                 (station_id, number, time) float32 ...\n",
      "    v100                (station_id, number, time) float32 ...\n",
      "    vis                 (station_id, number, time) float32 ...\n",
      "    z                   (station_id, number, time) float32 ...\n",
      "Attributes:\n",
      "    Conventions:             CF-1.7\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_edition:            1\n",
      "    GRIB_subCentre:          0\n",
      "    history:                 2022-07-08T08:03 GRIB to CDM+CF via cfgrib-0.9.1...\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    land usage history:      Retrieved from https://land.copernicus.eu/pan-eu...\n",
      "    land usage legend:       {1: {'label': '111 - Continuous urban fabric', '...\n",
      "    land usage source:       European Union, Copernicus Land Monitoring Servi...\n",
      "    model altitude history:  Retrieved from https://land.copernicus.eu/imager...\n",
      "    model altitude source:   European Union, Copernicus Land Monitoring Servi...\n",
      "[INFO] Loading data for forecasts (2017-2018)\n",
      "[INFO] Loading data for reforecasts (2014-2017)\n",
      "test\n",
      "test\n",
      "test\n",
      "<xarray.Dataset>\n",
      "Dimensions:            (station_id: 122, number: 11, time: 3449)\n",
      "Coordinates:\n",
      "    model_orography    (station_id) float64 689.3 972.9 ... -0.1254 0.6393\n",
      "  * number             (number) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "    station_altitude   (station_id) float64 424.0 439.0 1.478e+03 ... -4.3 11.9\n",
      "  * station_id         (station_id) int64 11101 11105 11308 ... 340 344 330\n",
      "    station_latitude   (station_id) float64 47.5 47.27 47.26 ... 51.96 51.99\n",
      "    station_longitude  (station_id) float64 9.746 9.6 10.19 ... 4.447 4.122\n",
      "    station_name       (station_id) <U20 'Bregenz' ... 'Hoek Van Holland'\n",
      "  * time               (time) datetime64[ns] 1997-01-02 ... 2014-01-01\n",
      "Data variables: (12/30)\n",
      "    cape               (station_id, number, time) float32 ...\n",
      "    cin                (station_id, number, time) float32 ...\n",
      "    cp6                (station_id, number, time) float32 ...\n",
      "    mn2t6              (station_id, number, time) float32 ...\n",
      "    mx2t6              (station_id, number, time) float32 ...\n",
      "    p10fg6             (station_id, number, time) float32 ...\n",
      "    ...                 ...\n",
      "    u100               (station_id, number, time) float32 ...\n",
      "    v                  (station_id, number, time) float32 ...\n",
      "    v10                (station_id, number, time) float32 ...\n",
      "    v100               (station_id, number, time) float32 ...\n",
      "    vis                (station_id, number, time) float32 ...\n",
      "    z                  (station_id, number, time) float32 ...\n",
      "Attributes:\n",
      "    Conventions:             CF-1.7\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_edition:            1\n",
      "    GRIB_subCentre:          0\n",
      "    history:                 2022-07-08T08:03 GRIB to CDM+CF via cfgrib-0.9.1...\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    land usage history:      Retrieved from https://land.copernicus.eu/pan-eu...\n",
      "    land usage legend:       {1: {'label': '111 - Continuous urban fabric', '...\n",
      "    land usage source:       European Union, Copernicus Land Monitoring Servi...\n",
      "    model altitude history:  Retrieved from https://land.copernicus.eu/imager...\n",
      "    model altitude source:   European Union, Copernicus Land Monitoring Servi...\n",
      "[INFO] Data loaded successfully. Forecasts shape:            (122, 51, 730), Reforecasts shape: (122, 11, 732)\n",
      "df_train loaded\n",
      "df_train_targets loaded\n",
      "df_f loaded\n",
      "df_f_targets Index(['time', 'station_id', 't2m'], dtype='object')\n",
      "df_rfIndex(['time', 'number', 'station_id', 'cape', 'cin', 'cp6', 'mn2t6',\n",
      "       'model_orography', 'mx2t6', 'p10fg6', 'q', 'sd', 'slhf6', 'sshf6',\n",
      "       'ssr6', 'ssrd6', 'station_altitude', 'station_latitude',\n",
      "       'station_longitude', 'station_name', 'stl1', 'str6', 'strd6', 'swvl1',\n",
      "       't', 't2m', 'tcc', 'tcw', 'tcwv', 'tp6', 'u', 'u10', 'u100', 'v', 'v10',\n",
      "       'v100', 'vis', 'z'],\n",
      "      dtype='object')\n",
      "df_rf_targets loaded\n",
      "[INFO] Saving dataframes to disk...\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:42:08.810191Z",
     "start_time": "2025-04-15T04:42:08.681848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_target = dataframes['train'][1]\n",
    "print(train_target[train_target['station_id'] == 62]['t2m'].isna().sum())\n",
    "print(train_target[train_target['station_id'] == 74].isna().sum())\n",
    "print(train_target[train_target['station_id'] == 2].isna().sum())\n",
    "\n",
    "# wie viele haben ueberhaupt keine nans\n",
    "counter = 0\n",
    "list = []\n",
    "for i in range(122):\n",
    "    if (train_target[train_target['station_id'] == i]['t2m'].isna().sum() != 0):\n",
    "        list.append(i)\n",
    "        counter += 1\n",
    "print(counter)\n",
    "print(list)"
   ],
   "id": "acd2bf069ee72ada",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3448\n",
      "time             0\n",
      "station_id       0\n",
      "t2m           3448\n",
      "dtype: int64\n",
      "time           0\n",
      "station_id     0\n",
      "t2m           27\n",
      "dtype: int64\n",
      "76\n",
      "[2, 19, 30, 31, 33, 34, 35, 37, 40, 41, 42, 43, 44, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 115, 118, 119, 120, 121]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T03:20:19.140839Z",
     "start_time": "2025-04-15T03:20:19.122259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(JSONPATH, \"r\") as f:\n",
    "    print(f\"[INFO] Loading {JSONPATH}\")\n",
    "    args_dict = json.load(f)\n",
    "config = args_dict\n",
    "print(config)\n",
    "print(config['lr'])\n",
    "print(config['max_dist'])\n",
    "print(type(config))\n",
    "print(type(config['lr']))\n",
    "print(type(config['gnn_hidden']))\n",
    "'''{\"batch_size\":8,\n",
    "\"gnn_hidden\":265,\n",
    "\"gnn_layers\":2,\n",
    "\"heads\":8,\n",
    "\"lr\":0.0002,\n",
    "\"max_dist\":100,\n",
    "\"max_epochs\": 31}'''"
   ],
   "id": "d7c44d07c4d68a02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/ltchen/gnnpp/trained_models/best_24h/params.json\n",
      "{'batch_size': 8, 'gnn_hidden': 265, 'gnn_layers': 2, 'heads': 8, 'lr': 0.0002, 'max_dist': 100, 'max_epochs': 31}\n",
      "0.0002\n",
      "100\n",
      "<class 'dict'>\n",
      "<class 'float'>\n",
      "<class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"batch_size\":8,\\n\"gnn_hidden\":265,\\n\"gnn_layers\":2,\\n\"heads\":8,\\n\"lr\":0.0002,\\n\"max_dist\":100,\\n\"max_epochs\": 31}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check GAT",
   "id": "e4879f7848e9aed6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T03:21:03.356692Z",
     "start_time": "2025-04-15T03:20:29.200007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = load_dataframes(mode=\"eval\", leadtime= \"24h\") # load newly created dataframes\n",
    "dataframes = summary_statistics(dataframes)\n",
    "dist = load_distances(dataframes[\"stations\"])\n",
    "\n",
    "graphs1_train_rf, tests1 = normalize_features_and_create_graphs1(df_train=dataframes['train'], df_valid_test=[dataframes['test_rf'], dataframes['test_f']], station_df=dataframes['stations'], attributes=[\"geo\"], edges=[(\"geo\", 100)], sum_stats = True)\n",
    "\n",
    "graphs1_test_rf, graphs1_test_f = tests1\n",
    "graphs1_test = graphs1_test_rf\n"
   ],
   "id": "556146d73ff761e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n",
      "[INFO] Loading distances from file...\n",
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n",
      "transform 2\n",
      "[INFO] Converting temperature values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3448/3448 [00:16<00:00, 205.29it/s]\n",
      "100%|██████████| 732/732 [00:02<00:00, 288.06it/s]\n",
      "100%|██████████| 730/730 [00:02<00:00, 245.80it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T03:21:40.722149Z",
     "start_time": "2025-04-15T03:21:06.762901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graphs2_train_rf, tests2 = normalize_features_and_create_graphs1(df_train=dataframes['train'], df_valid_test=[dataframes['test_rf'], dataframes['test_f']], station_df=dataframes['stations'], attributes=[\"geo\", \"alt\", \"lon\", \"lat\", \"alt-orog\"], edges=[(\"geo\", 100)], sum_stats = True)\n",
    "\n",
    "graphs2_test_rf, graphs2_test_f = tests2\n",
    "graphs2_test = graphs2_test_rf"
   ],
   "id": "9b025f7abb09585f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n",
      "transform 2\n",
      "[INFO] Converting temperature values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3448/3448 [00:16<00:00, 210.09it/s]\n",
      "100%|██████████| 732/732 [00:02<00:00, 260.57it/s]\n",
      "100%|██████████| 730/730 [00:02<00:00, 278.09it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T03:21:40.737123Z",
     "start_time": "2025-04-15T03:21:40.727619Z"
    }
   },
   "cell_type": "code",
   "source": "graphs2_train_rf[0].y",
   "id": "59229945da1c40c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-268.5500, -266.7500, -269.8500, -270.5500, -266.9500, -269.8500,\n",
       "        -268.8500, -271.0500, -270.0500, -268.3500, -271.9500, -270.0500,\n",
       "        -271.0500, -272.0500, -269.7500, -273.6500, -270.6500, -264.2500,\n",
       "        -264.4500,       nan, -264.8500, -264.3500, -264.8500, -266.2500,\n",
       "        -265.2500, -266.4500, -265.7500, -267.0500, -264.5500, -267.3500,\n",
       "        -267.4500, -277.7500, -276.3500, -277.7500,       nan, -275.1500,\n",
       "        -267.5500, -267.2500, -274.6500, -270.4500, -265.3500, -270.4500,\n",
       "        -270.2500, -272.2500, -274.3500, -270.7500, -276.8500, -272.7500,\n",
       "        -275.5500, -271.8500, -273.3500, -273.2500, -271.0500, -268.8500,\n",
       "        -268.0500, -266.4500, -276.4500, -271.5500, -270.7500, -273.1500,\n",
       "        -274.1500, -273.2500,       nan, -268.0500, -272.8500, -269.6500,\n",
       "        -267.1500, -272.0500, -278.3500, -271.4500, -269.2500, -270.1500,\n",
       "        -267.7500, -266.3500,       nan, -276.3500, -268.9500, -272.7500,\n",
       "        -274.3500, -271.5500, -267.9500, -263.5500, -264.3500, -264.6500,\n",
       "        -264.0500, -264.7500, -264.8500, -264.3500, -264.2500, -264.4500,\n",
       "        -265.5500, -266.2500, -264.4500, -265.3500, -266.4500, -266.8500,\n",
       "        -265.7500, -266.0500, -264.9500, -265.1500, -266.4500, -268.6500,\n",
       "        -264.6500, -265.7500, -265.6500, -267.0500, -267.9500, -269.3500,\n",
       "        -268.6500, -267.5500, -264.5500, -265.1500, -266.1500, -266.9500,\n",
       "        -267.2500, -267.4500, -267.3500, -266.8500, -268.9500, -269.9500,\n",
       "        -273.9500, -273.8500])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T02:52:05.765543Z",
     "start_time": "2025-04-15T02:52:05.759744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = config['batch_size']\n",
    "\n",
    "print(\"[INFO] Creating data loaders...\")\n",
    "g2_train_loader = DataLoader(graphs2_train_rf, batch_size=batch_size, shuffle=True)\n",
    "g2_test_f_loader = DataLoader(graphs2_test_f, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"[INFO] Creating model...\")\n",
    "emb_dim = 20\n",
    "\n",
    "in_channels = graphs2_train_rf[0].x.shape[1] + emb_dim - 1\n",
    "\n",
    "edge_dim = graphs2_train_rf[0].num_edge_features\n",
    "embedding_dim = emb_dim\n",
    "in_channels = in_channels\n",
    "hidden_channels_gnn = config['gnn_hidden']\n",
    "out_channels_gnn = config['gnn_hidden']\n",
    "num_layers_gnn = config['gnn_hidden']\n",
    "heads = config['heads']\n",
    "hidden_channels_deepset = config['gnn_hidden']\n",
    "optimizer_class = AdamW\n",
    "optimizer_params = dict(lr=config['lr'])\n"
   ],
   "id": "979bd8c993ab39e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating data loaders...\n",
      "[INFO] Creating model...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PROJECTNAME = \"test\"\n",
    "FILENAME = \"test_g2_train_run_24h\"\n",
    "with wandb.init(\n",
    "        project=PROJECTNAME, id=FILENAME, config=args_dict, tags=[\"reproduction\"]\n",
    "):\n",
    "    config = wandb.config\n",
    "\n",
    "    multigraph = Multigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph)\n",
    "    batch = next(iter(g2_train_loader))\n",
    "    # batch = batch  # .to(\"cuda\")\n",
    "    # multigraph  # .to(\"cuda\")\n",
    "    multigraph.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=PROJECTNAME)\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=FILENAME, monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    # print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph, train_dataloaders=train_loader)"
   ],
   "id": "58a9457ada5bc038"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check equality",
   "id": "bb088f9bee4b9a35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T13:58:11.806008Z",
     "start_time": "2025-04-14T13:58:03.497861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = load_dataframes(mode=\"eval\", leadtime= \"24h\") # load newly created dataframes\n",
    "dataframes = summary_statistics(dataframes)\n",
    "dist = load_distances(dataframes[\"stations\"])\n",
    "\n",
    "\n",
    "#self-created\n",
    "l_graphs_train_rf, l_tests = normalize_features_and_create_graphs1(df_train=dataframes['train'], df_valid_test=[dataframes['test_rf'], dataframes['test_f']], station_df=dataframes['stations'], attributes=[\"geo\", \"alt\", \"lon\", \"lat\", \"alt-orog\"], edges=[(\"geo\", 100)], sum_stats = True)\n",
    "\n",
    "l_graphs_test_rf, l_graphs_test_f = l_tests\n",
    "\n",
    "l_graphs_test = l_graphs_test_rf\n",
    "\n",
    "#moritz\n",
    "m_graphs_train_rf, m_tests = normalize_features_and_create_graphs(\n",
    "    training_data=dataframes[\"train\"],\n",
    "    valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    mat=dist,\n",
    "    max_dist=config['max_dist'],\n",
    ")\n",
    "m_graphs_test_rf, m_graphs_test_f = m_tests\n",
    "\n",
    "m_graphs_test = m_graphs_test_rf\n",
    "\n",
    "# print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n"
   ],
   "id": "d0a9cb7c5d611edd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n",
      "[INFO] Loading distances from file...\n",
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n",
      "transform 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (out=NoneType, axis=int, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim = False)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim = False)\n      didn't match because some of the keywords were incorrect: out, axis\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m dist \u001B[38;5;241m=\u001B[39m load_distances(dataframes[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstations\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#self-created\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m l_graphs_train_rf, l_tests \u001B[38;5;241m=\u001B[39m \u001B[43mnormalize_features_and_create_graphs1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataframes\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_valid_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mdataframes\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest_rf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataframes\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest_f\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstation_df\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataframes\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstations\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattributes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgeo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medges\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgeo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msum_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m l_graphs_test_rf, l_graphs_test_f \u001B[38;5;241m=\u001B[39m l_tests\n\u001B[1;32m     11\u001B[0m l_graphs_test \u001B[38;5;241m=\u001B[39m l_graphs_test_rf\n",
      "File \u001B[0;32m/tmp/pycharm_project_408/exploration/graph_creation.py:300\u001B[0m, in \u001B[0;36mnormalize_features_and_create_graphs1\u001B[0;34m(df_train, df_valid_test, station_df, attributes, edges, ensemble, sum_stats)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (features, targets) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dfs):\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 300\u001B[0m         graphs_train_rf \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_graph_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_target\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstation_df\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstation_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattributes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattributes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medges\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medges\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensemble\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mensemble\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msum_stats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msum_stats\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    303\u001B[0m         graphs_valid_test \u001B[38;5;241m=\u001B[39m create_graph_dataset(df_train\u001B[38;5;241m=\u001B[39mfeatures, df_target\u001B[38;5;241m=\u001B[39mtargets, station_df\u001B[38;5;241m=\u001B[39mstation_df, attributes\u001B[38;5;241m=\u001B[39mattributes, edges\u001B[38;5;241m=\u001B[39medges, ensemble \u001B[38;5;241m=\u001B[39m ensemble, sum_stats\u001B[38;5;241m=\u001B[39msum_stats)\n",
      "File \u001B[0;32m/tmp/pycharm_project_408/exploration/graph_creation.py:212\u001B[0m, in \u001B[0;36mcreate_graph_dataset\u001B[0;34m(df_train, df_target, station_df, attributes, edges, ensemble, sum_stats)\u001B[0m\n\u001B[1;32m    209\u001B[0m g_edge_attr \u001B[38;5;241m=\u001B[39m attr_tensor[g_adj]\n\u001B[1;32m    211\u001B[0m \u001B[38;5;66;03m# standardization\u001B[39;00m\n\u001B[0;32m--> 212\u001B[0m max_edge_attr \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg_edge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# g_edge_attr.max(dim=0).values\u001B[39;00m\n\u001B[1;32m    213\u001B[0m std_g_edge_attr \u001B[38;5;241m=\u001B[39m g_edge_attr \u001B[38;5;241m/\u001B[39m max_edge_attr\n\u001B[1;32m    215\u001B[0m n_nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(df_train\u001B[38;5;241m.\u001B[39mstation_id\u001B[38;5;241m.\u001B[39munique())\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mamax\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/.conda/envs/gnn_env4/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2820\u001B[0m, in \u001B[0;36mamax\u001B[0;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[1;32m   2703\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_amax_dispatcher)\n\u001B[1;32m   2704\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mamax\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue, initial\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue,\n\u001B[1;32m   2705\u001B[0m          where\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue):\n\u001B[1;32m   2706\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2707\u001B[0m \u001B[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001B[39;00m\n\u001B[1;32m   2708\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2818\u001B[0m \u001B[38;5;124;03m    5\u001B[39;00m\n\u001B[1;32m   2819\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2820\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaximum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2821\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/gnn_env4/lib/python3.10/site-packages/numpy/core/fromnumeric.py:84\u001B[0m, in \u001B[0;36m_wrapreduction\u001B[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[1;32m     82\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[1;32m     83\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 84\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpasskwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ufunc\u001B[38;5;241m.\u001B[39mreduce(obj, axis, dtype, out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n",
      "\u001B[0;31mTypeError\u001B[0m: max() received an invalid combination of arguments - got (out=NoneType, axis=int, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim = False)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim = False)\n      didn't match because some of the keywords were incorrect: out, axis\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:14:44.959934Z",
     "start_time": "2025-04-13T19:14:44.955860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l_train_loader = DataLoader(l_graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "m_train_loader = DataLoader(m_graphs_train_rf, batch_size=config['batch_size'], shuffle=True)"
   ],
   "id": "bfb4323d09814ddd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:54:47.697818Z",
     "start_time": "2025-04-14T05:54:47.669891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(l_graphs_train_rf[0])\n",
    "print(m_graphs_train_rf[0])\n",
    "\n",
    "graph1 = l_graphs_train_rf[0]\n",
    "graph2 = m_graphs_train_rf[0]\n",
    "\n",
    "print(f\"edge indices are the same: {torch.equal(graph1.edge_index, graph2.edge_index)}\")\n",
    "print(f\"targets are the same: {torch.equal(graph1.y, graph2.y)}\")\n",
    "print(f\"targets are almost the same: {torch.allclose(graph1.y, graph2.y, atol=1e-50)}\")\n",
    "\n",
    "print(graph1.y)\n",
    "print(graph2.y)\n",
    "print(type(graph1))\n",
    "print(type(graph2))\n",
    "comparison = np.array(graph1.x) == np.array(graph2.x)\n",
    "diff_indices = np.where(comparison == False)\n",
    "print(np.array(graph1.x)==np.array(graph2.x))\n",
    "print(diff_indices)\n",
    "print(\"graph1[diff]:\", graph1.x[diff_indices[0]][0])\n",
    "print(\"graph2[diff]:\", graph2.x[diff_indices[0]][0])\n",
    "print(np.allclose(graph1.x, graph2.x, atol=1e-50))\n",
    "print(torch.equal(graph1.x, graph2.x))\n",
    "print(122*65)"
   ],
   "id": "370b4c2785f24366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[122, 65], edge_index=[2, 1420], edge_attr=[1420, 1], y=[122, 1], pos=[122, 2], timestamp=1997-01-02 00:00:00, n_idx=[122])\n",
      "Data(x=[122, 65], edge_index=[2, 1420], edge_attr=[1420, 1], y=[122], timestamp=1997-01-02 00:00:00, n_idx=[122])\n",
      "edge indices are the same: True\n",
      "targets are the same: False\n",
      "targets are almost the same: False\n",
      "tensor([[ 4.6000],\n",
      "        [ 6.4000],\n",
      "        [ 3.3000],\n",
      "        [ 2.6000],\n",
      "        [ 6.2000],\n",
      "        [ 3.3000],\n",
      "        [ 4.3000],\n",
      "        [ 2.1000],\n",
      "        [ 3.1000],\n",
      "        [ 4.8000],\n",
      "        [ 1.2000],\n",
      "        [ 3.1000],\n",
      "        [ 2.1000],\n",
      "        [ 1.1000],\n",
      "        [ 3.4000],\n",
      "        [-0.5000],\n",
      "        [ 2.5000],\n",
      "        [ 8.9000],\n",
      "        [ 8.7000],\n",
      "        [    nan],\n",
      "        [ 8.3000],\n",
      "        [ 8.8000],\n",
      "        [ 8.3000],\n",
      "        [ 6.9000],\n",
      "        [ 7.9000],\n",
      "        [ 6.7000],\n",
      "        [ 7.4000],\n",
      "        [ 6.1000],\n",
      "        [ 8.6000],\n",
      "        [ 5.8000],\n",
      "        [ 5.7000],\n",
      "        [-4.6000],\n",
      "        [-3.2000],\n",
      "        [-4.6000],\n",
      "        [    nan],\n",
      "        [-2.0000],\n",
      "        [ 5.6000],\n",
      "        [ 5.9000],\n",
      "        [-1.5000],\n",
      "        [ 2.7000],\n",
      "        [ 7.8000],\n",
      "        [ 2.7000],\n",
      "        [ 2.9000],\n",
      "        [ 0.9000],\n",
      "        [-1.2000],\n",
      "        [ 2.4000],\n",
      "        [-3.7000],\n",
      "        [ 0.4000],\n",
      "        [-2.4000],\n",
      "        [ 1.3000],\n",
      "        [-0.2000],\n",
      "        [-0.1000],\n",
      "        [ 2.1000],\n",
      "        [ 4.3000],\n",
      "        [ 5.1000],\n",
      "        [ 6.7000],\n",
      "        [-3.3000],\n",
      "        [ 1.6000],\n",
      "        [ 2.4000],\n",
      "        [ 0.0000],\n",
      "        [-1.0000],\n",
      "        [-0.1000],\n",
      "        [    nan],\n",
      "        [ 5.1000],\n",
      "        [ 0.3000],\n",
      "        [ 3.5000],\n",
      "        [ 6.0000],\n",
      "        [ 1.1000],\n",
      "        [-5.2000],\n",
      "        [ 1.7000],\n",
      "        [ 3.9000],\n",
      "        [ 3.0000],\n",
      "        [ 5.4000],\n",
      "        [ 6.8000],\n",
      "        [    nan],\n",
      "        [-3.2000],\n",
      "        [ 4.2000],\n",
      "        [ 0.4000],\n",
      "        [-1.2000],\n",
      "        [ 1.6000],\n",
      "        [ 5.2000],\n",
      "        [ 9.6000],\n",
      "        [ 8.8000],\n",
      "        [ 8.5000],\n",
      "        [ 9.1000],\n",
      "        [ 8.4000],\n",
      "        [ 8.3000],\n",
      "        [ 8.8000],\n",
      "        [ 8.9000],\n",
      "        [ 8.7000],\n",
      "        [ 7.6000],\n",
      "        [ 6.9000],\n",
      "        [ 8.7000],\n",
      "        [ 7.8000],\n",
      "        [ 6.7000],\n",
      "        [ 6.3000],\n",
      "        [ 7.4000],\n",
      "        [ 7.1000],\n",
      "        [ 8.2000],\n",
      "        [ 8.0000],\n",
      "        [ 6.7000],\n",
      "        [ 4.5000],\n",
      "        [ 8.5000],\n",
      "        [ 7.4000],\n",
      "        [ 7.5000],\n",
      "        [ 6.1000],\n",
      "        [ 5.2000],\n",
      "        [ 3.8000],\n",
      "        [ 4.5000],\n",
      "        [ 5.6000],\n",
      "        [ 8.6000],\n",
      "        [ 8.0000],\n",
      "        [ 7.0000],\n",
      "        [ 6.2000],\n",
      "        [ 5.9000],\n",
      "        [ 5.7000],\n",
      "        [ 5.8000],\n",
      "        [ 6.3000],\n",
      "        [ 4.2000],\n",
      "        [ 3.2000],\n",
      "        [-0.8000],\n",
      "        [-0.7000]])\n",
      "tensor([-268.5500, -266.7500, -269.8500, -270.5500, -266.9500, -269.8500,\n",
      "        -268.8500, -271.0500, -270.0500, -268.3500, -271.9500, -270.0500,\n",
      "        -271.0500, -272.0500, -269.7500, -273.6500, -270.6500, -264.2500,\n",
      "        -264.4500,       nan, -264.8500, -264.3500, -264.8500, -266.2500,\n",
      "        -265.2500, -266.4500, -265.7500, -267.0500, -264.5500, -267.3500,\n",
      "        -267.4500, -277.7500, -276.3500, -277.7500,       nan, -275.1500,\n",
      "        -267.5500, -267.2500, -274.6500, -270.4500, -265.3500, -270.4500,\n",
      "        -270.2500, -272.2500, -274.3500, -270.7500, -276.8500, -272.7500,\n",
      "        -275.5500, -271.8500, -273.3500, -273.2500, -271.0500, -268.8500,\n",
      "        -268.0500, -266.4500, -276.4500, -271.5500, -270.7500, -273.1500,\n",
      "        -274.1500, -273.2500,       nan, -268.0500, -272.8500, -269.6500,\n",
      "        -267.1500, -272.0500, -278.3500, -271.4500, -269.2500, -270.1500,\n",
      "        -267.7500, -266.3500,       nan, -276.3500, -268.9500, -272.7500,\n",
      "        -274.3500, -271.5500, -267.9500, -263.5500, -264.3500, -264.6500,\n",
      "        -264.0500, -264.7500, -264.8500, -264.3500, -264.2500, -264.4500,\n",
      "        -265.5500, -266.2500, -264.4500, -265.3500, -266.4500, -266.8500,\n",
      "        -265.7500, -266.0500, -264.9500, -265.1500, -266.4500, -268.6500,\n",
      "        -264.6500, -265.7500, -265.6500, -267.0500, -267.9500, -269.3500,\n",
      "        -268.6500, -267.5500, -264.5500, -265.1500, -266.1500, -266.9500,\n",
      "        -267.2500, -267.4500, -267.3500, -266.8500, -268.9500, -269.9500,\n",
      "        -273.9500, -273.8500])\n",
      "<class 'torch_geometric.data.data.Data'>\n",
      "<class 'torch_geometric.data.data.Data'>\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "(array([  1,   4,   8,  12,  13,  13,  14,  15,  15,  16,  17,  21,  27,\n",
      "        30,  30,  30,  31,  32,  33,  34,  34,  34,  35,  35,  35,  36,\n",
      "        36,  37,  38,  39,  40,  40,  41,  41,  42,  42,  43,  43,  43,\n",
      "        43,  44,  44,  44,  44,  45,  47,  47,  48,  48,  49,  50,  51,\n",
      "        51,  52,  55,  56,  56,  56,  56,  57,  59,  60,  61,  61,  62,\n",
      "        62,  63,  63,  66,  67,  67,  68,  69,  70,  70,  71,  71,  72,\n",
      "        73,  73,  74,  74,  74,  75,  76,  77,  77,  77,  78,  78,  79,\n",
      "        80,  83,  84,  88,  89,  90,  91,  92,  93,  94,  94,  95,  95,\n",
      "        96,  97,  98,  99, 100, 101, 102, 103, 103, 105, 106, 107, 108,\n",
      "       109, 111, 112, 114, 115, 118, 118, 118, 119]), array([49, 51, 12,  4,  4,  8,  4,  8, 51,  4, 11,  8, 51,  1,  4, 32,  8,\n",
      "        8,  8,  8, 12, 51,  8, 30, 51,  4, 14, 15,  8, 12,  2,  8,  8, 52,\n",
      "        1,  8,  1,  8, 51, 52,  1,  7,  8, 51,  8,  7, 22,  7,  8,  7,  7,\n",
      "        1,  8,  8,  8,  6,  7,  8, 51,  7,  8,  7,  8, 51,  2,  8,  4,  8,\n",
      "        1,  7,  8,  8,  8,  8, 32,  8, 32,  8,  4,  8,  2,  7, 12,  7, 12,\n",
      "        1,  7,  8,  8, 51,  8, 42, 12,  6,  8,  8,  8,  8,  8,  8,  2,  8,\n",
      "        1,  8,  8,  8,  8,  8,  7,  7,  8,  3,  8,  8,  8,  8,  8,  8,  8,\n",
      "       59,  8, 12,  7,  8, 32,  7]))\n",
      "graph1[diff]: tensor([ 1.0000e+00, -7.3700e-01, -7.7860e-01,  1.0161e+00, -8.9124e-01,\n",
      "        -1.6470e-01, -2.3303e-01, -1.3895e-01, -1.3039e-01, -4.6505e-01,\n",
      "         1.0730e+00,  1.8275e+00,  2.8539e-01, -3.1817e-01,  6.1921e-01,\n",
      "         1.0774e+00, -1.1164e+00,  1.3888e-01,  6.0102e-01,  9.5343e-02,\n",
      "         3.1746e-01, -2.4744e+00,  1.0052e+00, -2.2047e+00,  8.7349e-01,\n",
      "         1.2595e+00,  2.7410e+00,  1.2958e+00,  1.9505e+00, -1.4323e+00,\n",
      "         4.3588e-01,  4.8850e-01,  9.3346e-01, -3.0281e-01,  5.5341e-01,\n",
      "        -5.4016e-01,  1.4611e+00,  1.4545e+00,  1.3814e+00, -2.2196e-01,\n",
      "         1.2465e+00,  4.4024e-01,  1.5271e+00, -5.5207e-01, -5.0227e-01,\n",
      "        -5.5320e-01, -5.0425e-01,  5.7114e-01,  2.4737e+00, -1.8663e-04,\n",
      "         2.3089e+00,  1.7978e-01,  7.9958e-01, -1.1903e+00,  8.0984e-01,\n",
      "         4.3332e-01,  3.5857e-01, -7.4692e-01,  5.4329e+00,  1.6662e+00,\n",
      "         2.5205e+00, -7.5758e-01,  1.5635e+00,  9.9941e-01,  3.4422e-02])\n",
      "graph2[diff]: tensor([ 1.0000e+00, -7.3700e-01, -7.7860e-01,  1.0161e+00, -8.9124e-01,\n",
      "        -1.6470e-01, -2.3303e-01, -1.3895e-01, -1.3039e-01, -4.6505e-01,\n",
      "         1.0730e+00,  1.8275e+00,  2.8539e-01, -3.1817e-01,  6.1921e-01,\n",
      "         1.0774e+00, -1.1164e+00,  1.3888e-01,  6.0102e-01,  9.5343e-02,\n",
      "         3.1746e-01, -2.4744e+00,  1.0052e+00, -2.2047e+00,  8.7349e-01,\n",
      "         1.2595e+00,  2.7410e+00,  1.2958e+00,  1.9505e+00, -1.4323e+00,\n",
      "         4.3588e-01,  4.8850e-01,  9.3346e-01, -3.0281e-01,  5.5341e-01,\n",
      "        -5.4016e-01,  1.4611e+00,  1.4545e+00,  1.3814e+00, -2.2196e-01,\n",
      "         1.2465e+00,  4.4024e-01,  1.5271e+00, -5.5207e-01, -5.0227e-01,\n",
      "        -5.5320e-01, -5.0425e-01,  5.7114e-01,  2.4737e+00, -1.8663e-04,\n",
      "         2.3089e+00,  1.7978e-01,  7.9958e-01, -1.1903e+00,  8.0984e-01,\n",
      "         4.3332e-01,  3.5857e-01, -7.4692e-01,  5.4329e+00,  1.6662e+00,\n",
      "         2.5205e+00, -7.5758e-01,  1.5635e+00,  9.9941e-01,  3.4422e-02])\n",
      "True\n",
      "False\n",
      "7930\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:14:45.055428Z",
     "start_time": "2025-04-13T19:14:45.050188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb_dim=20\n",
    "# edge_dim=l_graphs_test_f[0].num_edge_features\n",
    "edge_dim = 1\n",
    "in_channels = m_graphs_train_rf[0].x.shape[1] + emb_dim - 1"
   ],
   "id": "18ffc00f4461ac56",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:22:18.227676Z",
     "start_time": "2025-04-13T19:15:09.913415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with wandb.init(\n",
    "    project=PROJECTNAME, id=f\"m_graph_training_run_24h\", config=args_dict, tags=[\"final_training\"], reinit=True\n",
    "):\n",
    "    config = wandb.config\n",
    "\n",
    "    multigraph = Multigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        # edge_dim=edge_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph)\n",
    "\n",
    "    # understand what this is\n",
    "    batch = next(iter(m_train_loader))\n",
    "    # batch = batch  # .to(\"cuda\")\n",
    "    # multigraph  # .to(\"cuda\")\n",
    "    multigraph.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=PROJECTNAME)\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"m_graph_run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    # print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph, train_dataloaders=m_train_loader) # trainer speichern und entweder neuladen oder\n",
    "wandb.finish()"
   ],
   "id": "4c9b0c897e513a09",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mleachen\u001B[0m (\u001B[33mleachen_thesis\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250413_211510-m_graph_training_run_24h</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/reproduce_gnn/runs/m_graph_training_run_24h' target=\"_blank\">m_graph_training_run_24h</a></strong> to <a href='https://wandb.ai/leachen_thesis/reproduce_gnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/reproduce_gnn' target=\"_blank\">https://wandb.ai/leachen_thesis/reproduce_gnn</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/reproduce_gnn/runs/m_graph_training_run_24h' target=\"_blank\">https://wandb.ai/leachen_thesis/reproduce_gnn/runs/m_graph_training_run_24h</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/gnn_new_attr_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.571    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:13<00:00, 31.69it/s, v_num=_24h, train_loss_step=1.070, train_loss_epoch=1.520]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=31` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:13<00:00, 31.68it/s, v_num=_24h, train_loss_step=1.070, train_loss_epoch=1.520]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▃▃▃▂▃▂▂▂▁▂▂▁▂▁▂▁▁▁▂▁▁▁▁▂▁▁▁▁▂▁▂▁▁▁▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_loss_epoch</td><td>1.52217</td></tr><tr><td>train_loss_step</td><td>1.06947</td></tr><tr><td>trainer/global_step</td><td>13360</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">m_graph_training_run_24h</strong> at: <a href='https://wandb.ai/leachen_thesis/reproduce_gnn/runs/m_graph_training_run_24h' target=\"_blank\">https://wandb.ai/leachen_thesis/reproduce_gnn/runs/m_graph_training_run_24h</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/reproduce_gnn' target=\"_blank\">https://wandb.ai/leachen_thesis/reproduce_gnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250413_211510-m_graph_training_run_24h/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T15:07:29.437043Z",
     "start_time": "2025-04-13T15:07:29.427325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb_dim=20\n",
    "# edge_dim=l_graphs_test_f[0].num_edge_features\n",
    "edge_dim = 1\n",
    "in_channels = m_graphs_train_rf[0].x.shape[1] + emb_dim - 1"
   ],
   "id": "9aec188ee5531ab6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -7.3829e-01, -7.6410e-01,  ...,  6.1836e-01,\n",
       "          9.9941e-01,  3.4422e-02],\n",
       "        [ 1.0000e+00, -7.3700e-01, -7.7860e-01,  ...,  1.5635e+00,\n",
       "          9.9941e-01,  3.4422e-02],\n",
       "        [ 2.0000e+00, -7.3185e-01, -7.3317e-01,  ...,  7.6520e-01,\n",
       "          9.9941e-01,  3.4422e-02],\n",
       "        ...,\n",
       "        [ 1.1900e+02,  2.3386e+00,  6.4645e-01,  ..., -6.1813e-01,\n",
       "          9.9941e-01,  3.4422e-02],\n",
       "        [ 1.2000e+02,  4.7996e+00,  3.9940e+00,  ..., -6.0907e-01,\n",
       "          9.9941e-01,  3.4422e-02],\n",
       "        [ 1.2100e+02,  5.9139e+00,  4.3452e+00,  ..., -4.7565e-01,\n",
       "          9.9941e-01,  3.4422e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T15:03:49.843928Z",
     "start_time": "2025-04-13T15:03:49.799315Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "24ef7ea4b69a006f",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcompare_data_ignore_extra_keys\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph2\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 22\u001B[0m, in \u001B[0;36mcompare_data_ignore_extra_keys\u001B[0;34m(data1, data2, tol)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompare_data_ignore_extra_keys\u001B[39m(data1, data2, tol\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-6\u001B[39m):\n\u001B[0;32m---> 22\u001B[0m     keys_to_compare \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mintersection(\u001B[38;5;28mset\u001B[39m(data2\u001B[38;5;241m.\u001B[39mkeys))\n\u001B[1;32m     24\u001B[0m     all_match \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m keys_to_compare:\n",
      "\u001B[0;31mTypeError\u001B[0m: 'method' object is not iterable"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
