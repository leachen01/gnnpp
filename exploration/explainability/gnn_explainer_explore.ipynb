{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T17:05:09.187219Z",
     "start_time": "2025-04-21T17:05:09.173128Z"
    }
   },
   "source": [
    "%cd /home/ltchen/gnnpp\n",
    "import sys\n",
    "import os\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torch_geometric\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.utils import scatter\n",
    "from torch.nn import Linear, ModuleList, ReLU\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.optim import AdamW\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from models.loss import NormalCRPS\n",
    "from models.model_utils import MakePositive, EmbedStations\n",
    "from utils.data import (\n",
    "    load_dataframes,\n",
    "    load_distances,\n",
    "    normalize_features_and_create_graphs,\n",
    "    rm_edges,\n",
    "    summary_statistics,\n",
    ")\n",
    "from exploration.graph_creation import *\n",
    "from models.graphensemble.multigraph import *\n",
    "import shap\n",
    "from torch_geometric.explain import GNNExplainer"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T16:14:07.521321Z",
     "start_time": "2025-04-21T16:14:07.509941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "leadtime = \"24h\"\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "DIRECTORY = os.getcwd()\n",
    "SAVEPATH = os.path.join(DIRECTORY, f\"leas_final_models/gnn_run4_{leadtime}/models\")\n",
    "JSONPATH = os.path.join(DIRECTORY, f\"trained_models/best_{leadtime}/params.json\")\n",
    "\n",
    "with open(JSONPATH, \"r\") as f:\n",
    "    print(f\"[INFO] Loading {JSONPATH}\")\n",
    "    args_dict = json.load(f)\n",
    "config = args_dict\n",
    "\n",
    "# from gnn_run3 ###############################\n",
    "max_epoch_list = {\n",
    "    'g1': 31,\n",
    "    'g2': 26,\n",
    "    'g3': 31,\n",
    "    'g4': 32,\n",
    "    'g5': 23,\n",
    "}"
   ],
   "id": "f96c9f9d22ab2ee4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/ltchen/gnnpp/trained_models/best_24h/params.json\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T16:14:15.935890Z",
     "start_time": "2025-04-21T16:14:10.710836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = load_dataframes(mode=\"eval\", leadtime=leadtime)\n",
    "dataframes = summary_statistics(dataframes)"
   ],
   "id": "a445577be64c2b0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T16:14:44.392956Z",
     "start_time": "2025-04-21T16:14:15.941768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graph_name = \"g1\"\n",
    "graphs1_train_rf, tests1 = normalize_features_and_create_graphs1(df_train=dataframes['train'], df_valid_test=[dataframes['test_rf'], dataframes['test_f']], station_df=dataframes['stations'], attributes=[\"geo\"], edges=[(\"geo\", 100)], sum_stats = True)\n",
    "graphs1_test_rf, graphs1_test_f = tests1\n",
    "\n",
    "g1_train_loader = DataLoader(graphs1_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "g1_test_f_loader = DataLoader(graphs1_test_f, batch_size=config['batch_size'], shuffle=False)\n",
    "g1_test_rf_loader = DataLoader(graphs1_test_rf, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "train_loader = g1_train_loader\n",
    "test_f_loader = g1_test_f_loader\n",
    "test_rf_loader = g1_test_rf_loader\n",
    "test_loader = [test_f_loader, test_rf_loader]\n",
    "\n",
    "emb_dim = 20\n",
    "in_channels = graphs1_train_rf[0].x.shape[1] + emb_dim - 1\n",
    "edge_dim = graphs1_train_rf[0].num_edge_features\n",
    "max_epochs = max_epoch_list[graph_name]"
   ],
   "id": "bd35ed497e23d842",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n",
      "transform 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3448/3448 [00:16<00:00, 208.27it/s]\n",
      "100%|██████████| 732/732 [00:02<00:00, 280.94it/s]\n",
      "100%|██████████| 730/730 [00:02<00:00, 256.63it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T16:14:55.318839Z",
     "start_time": "2025-04-21T16:14:55.200554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECTNAME = \"gnn_run4\"\n",
    "FILENAME = graph_name + \"_run_\" + leadtime\n",
    "TRAINNAME = graph_name + \"_train_run_\" + leadtime\n",
    "CKPT_PATH = os.path.join(SAVEPATH, TRAINNAME + '.ckpt')\n",
    "RESULTPATH = os.path.join(DIRECTORY, f\"leas_trained_models/best_{leadtime}/best_{leadtime}_{graph_name}\")\n",
    "\n",
    "multigraph = Multigraph.load_from_checkpoint(\n",
    "    CKPT_PATH,\n",
    "    embedding_dim=emb_dim,\n",
    "    edge_dim=edge_dim,\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels_gnn=config['gnn_hidden'],\n",
    "    out_channels_gnn=config['gnn_hidden'],\n",
    "    num_layers_gnn=config['gnn_layers'],\n",
    "    heads=config['heads'],\n",
    "    hidden_channels_deepset=config['gnn_hidden'],\n",
    "    optimizer_class=AdamW,\n",
    "    optimizer_params=dict(lr=config['lr']),\n",
    ")\n",
    "\n",
    "multigraph.eval()\n",
    "trainer = L.Trainer()"
   ],
   "id": "56aa353bbeb60830",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T16:15:01.676603Z",
     "start_time": "2025-04-21T16:14:58.041874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_list = [\"f\", \"rf\"]\n",
    "for data, tl in zip(data_list, test_loader):\n",
    "    preds_list = []\n",
    "    preds = trainer.predict(model=multigraph, dataloaders=[tl]) # 92 x 976 x 2 forecasts with mu and sigma of 122 stations\n",
    "    print(preds[0].shape)\n",
    "    # preds = [prediction.reshape(1, 122, 2).mean(axis=0) for prediction in preds]\n",
    "    #ACHTUNG - reshape(1, 122, 2) mit 1 statt 5!\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    preds_list.append(preds)\n",
    "\n",
    "    targets = dataframes[f\"test_{data}\"][1]\n",
    "    targets = torch.tensor(targets.t2m.values) - 273.15\n",
    "\n",
    "    stacked = torch.stack(preds_list)\n",
    "    final_preds = torch.mean(stacked, dim=0)\n",
    "\n",
    "    res = multigraph.loss_fn.crps(final_preds, targets)\n",
    "    print(\"#############################################\")\n",
    "    print(\"#############################################\")\n",
    "    print(f\"final crps: {res.item()}\")\n",
    "    print(\"#############################################\")\n",
    "    print(\"#############################################\")\n",
    "\n",
    "    os.makedirs(RESULTPATH, exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate([targets.view(-1, 1), final_preds], axis=1), columns=[\"t2m\", \"mu\", \"sigma\"])\n",
    "    df.to_csv(os.path.join(RESULTPATH, f\"{data}_{FILENAME}_results.csv\"), index=False)\n",
    "\n",
    "    # Create Log File ###############################################################\n",
    "    log_file = os.path.join(RESULTPATH, f\"{data}.txt\")\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(f\"Data: {data}\\n\")\n",
    "        f.write(f\"Leadtime: {leadtime}\\n\")\n",
    "        f.write(f\"Final crps: {res.item()}\")"
   ],
   "id": "f9f057bfd64d232a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:01<00:00, 53.33it/s]\n",
      "torch.Size([976, 2])\n",
      "#############################################\n",
      "#############################################\n",
      "final crps: 0.6755105741389072\n",
      "#############################################\n",
      "#############################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 92/92 [00:01<00:00, 78.75it/s]\n",
      "torch.Size([976, 2])\n",
      "#############################################\n",
      "#############################################\n",
      "final crps: 0.6981425078190406\n",
      "#############################################\n",
      "#############################################\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GNN Explainer",
   "id": "aa1be4d6126bfbf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "explainer = GNNExplainer(multigraph, epochs=100, return_type='log_prob')",
   "id": "a081bfab8cecbeb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
