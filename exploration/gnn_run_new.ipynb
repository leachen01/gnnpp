{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-07T23:52:33.976716Z",
     "start_time": "2025-04-07T23:52:33.962751Z"
    }
   },
   "source": [
    "%cd /home/ltchen/gnnpp\n",
    "import sys\n",
    "import os\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torch_geometric\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.utils import scatter\n",
    "from torch.nn import Linear, ModuleList, ReLU\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.optim import AdamW\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from models.loss import NormalCRPS\n",
    "from models.model_utils import MakePositive, EmbedStations\n",
    "from utils.data import (\n",
    "    load_dataframes,\n",
    "    load_distances,\n",
    "    normalize_features_and_create_graphs,\n",
    "    rm_edges,\n",
    "    summary_statistics,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:52:35.855681Z",
     "start_time": "2025-04-07T23:52:35.849151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "DIRECTORY = os.getcwd()\n",
    "SAVEPATH = os.path.join(DIRECTORY, \"explored_models/gnn_new_24h/models\")\n",
    "JSONPATH = os.path.join(DIRECTORY, \"trained_models/best_24h/params.json\")"
   ],
   "id": "75ec733d044d00ba",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:52:37.862391Z",
     "start_time": "2025-04-07T23:52:37.845122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(JSONPATH, \"r\") as f:\n",
    "    print(f\"[INFO] Loading {JSONPATH}\")\n",
    "    args_dict = json.load(f)\n",
    "config = args_dict\n",
    "print(config)\n",
    "print(config['lr'])\n",
    "print(config['max_dist'])\n",
    "print(type(config))\n",
    "print(type(config['lr']))\n",
    "print(type(config['gnn_hidden']))\n",
    "'''{\"batch_size\":8,\n",
    "\"gnn_hidden\":265,\n",
    "\"gnn_layers\":2,\n",
    "\"heads\":8,\n",
    "\"lr\":0.0002,\n",
    "\"max_dist\":100,\n",
    "\"max_epochs\": 31}'''"
   ],
   "id": "1a46aa1396e2032b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/ltchen/gnnpp/trained_models/best_24h/params.json\n",
      "{'batch_size': 8, 'gnn_hidden': 265, 'gnn_layers': 2, 'heads': 8, 'lr': 0.0002, 'max_dist': 100, 'max_epochs': 31}\n",
      "0.0002\n",
      "100\n",
      "<class 'dict'>\n",
      "<class 'float'>\n",
      "<class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"batch_size\":8,\\n\"gnn_hidden\":265,\\n\"gnn_layers\":2,\\n\"heads\":8,\\n\"lr\":0.0002,\\n\"max_dist\":100,\\n\"max_epochs\": 31}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:52:46.000696Z",
     "start_time": "2025-04-07T23:52:40.639761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = load_dataframes(mode=\"eval\", leadtime= \"24h\") # load newly created dataframes\n",
    "\n",
    "dataframes = summary_statistics(dataframes)\n",
    "train = dataframes[\"train\"][0]\n",
    "train_target = dataframes[\"train\"][1]\n",
    "test_rf = dataframes[\"test_rf\"][0]\n",
    "test_rf_target = dataframes[\"test_rf\"][1]\n",
    "test_f = dataframes[\"test_f\"][0]\n",
    "test_f_target = dataframes[\"test_f\"][1]"
   ],
   "id": "23f4a8d243322376",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create new graphs => e.g. alt + dist\n",
    "max_dist = 100\n",
    "graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    training_data=(train, train_target),\n",
    "    valid_test_data=[(test_rf, test_rf_target), (test_f, test_f_target)],\n",
    "    mat=dist,\n",
    "    max_dist=max_dist,\n",
    ")\n",
    "\n",
    "graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "graphs_test = graphs_test_rf\n",
    "#print(graphs_train_rf) #(1342, 36)\n",
    "print(next(iter(graphs_train_rf)))\n",
    "print(len(graphs_test_rf))\n",
    "print(type(graphs_train_rf[:100]))\n",
    "print(graphs_train_rf[0].x.shape)\n",
    "print(graphs_train_rf[0].y.shape)"
   ],
   "id": "57aa15817317b1ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 8\n",
    "train_loader = DataLoader(graphs_train_rf, batch_size=batch_size, shuffle=True)\n",
    "test_f_loader = DataLoader(graphs_test_f, batch_size=batch_size, shuffle=False)"
   ],
   "id": "bb187ecfa875498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GNN Architecture",
   "id": "7b6bdd33fb63a32a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# gnn architecture\n",
    "class DeepSetAggregator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(DeepSetAggregator, self).__init__()\n",
    "\n",
    "        self.input = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        self.hidden1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.hidden2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.output = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, index):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        print(f\"Input: {x.shape}\")\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        print(f\"Hidden1: {x.shape}\")\n",
    "        x = scatter(x, index, dim=0, reduce=\"mean\")\n",
    "        print(f\"scatter: {x.shape}\")\n",
    "        print(f\"index: {index}\")\n",
    "        self.hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        print(f\"Hidden2: {x.shape}\")\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResGnn(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, num_layers: int, hidden_channels: int, heads: int):\n",
    "        super(ResGnn, self).__init__()\n",
    "        assert num_layers > 0, \"num_layers must be > 0.\"\n",
    "\n",
    "        # Create Layers\n",
    "        self.convolutions = ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convolutions.append(\n",
    "                GATv2Conv(-1, hidden_channels, heads=heads, edge_dim=1, add_self_loops=True, fill_value=0.01)\n",
    "            )\n",
    "        self.lin = Linear(hidden_channels * heads, out_channels)\n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.float()\n",
    "        edge_attr = edge_attr.float()\n",
    "        for i, conv in enumerate(self.convolutions):\n",
    "            if i == 0:\n",
    "                # First Layer\n",
    "                x = conv(x, edge_index, edge_attr)\n",
    "                x = self.relu(x)\n",
    "            else:\n",
    "                x = x + self.relu(conv(x, edge_index, edge_attr))  # Residual Layers\n",
    "\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attention(\n",
    "        self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Runs a forward Pass for the given graph only though the ResGNN layer.\n",
    "        NOTE: the data that is given to this method must first pass through the layers before this layer in the Graph\n",
    "\n",
    "        :param torch.Tensor x: Tensor of Node Features (NxD)\n",
    "        :param torch.Tensor edge_index: Tensor of Edges (2xE)\n",
    "        :param torch.Tensor edge_attr: Edge Attributes (ExNum_Attr)\n",
    "        :return x, edge_index_attention, attention_weights: Tensor of Node Features (NxD), Tensor of Edges with\n",
    "        self loops (2xE), Tensor of Attention per edge (ExNum_Heads)\n",
    "        \"\"\"\n",
    "        x = x.float()\n",
    "        edge_attr = edge_attr.float()\n",
    "\n",
    "        # Pass Data though Layer to get the Attention\n",
    "        attention_list = []\n",
    "        # Note: edge_index_attention has to be added since we have self loops now\n",
    "        edge_index_attention, attention_weights = None, None\n",
    "\n",
    "        for i, conv in enumerate(\n",
    "            self.convolutions,\n",
    "        ):\n",
    "            if i == 0:\n",
    "                # First Layer\n",
    "                x, (edge_index_attention, attention_weights) = conv(\n",
    "                    x, edge_index, edge_attr, return_attention_weights=True\n",
    "                )\n",
    "                print(\"attention_weights:\")\n",
    "                print(attention_weights)\n",
    "                print(\"edge_index_attention\")\n",
    "                print(edge_index_attention)\n",
    "                print(f\"attention_weights.shape{attention_weights.shape}\")\n",
    "                print(f\"type(attention_weights){type(attention_weights)}\")\n",
    "                attention_list.append(attention_weights)\n",
    "                x = self.relu(x)\n",
    "                x = self.norm(x)\n",
    "            else:\n",
    "                x_conv, (edge_index_attention, attention_weights) = conv(\n",
    "                    x, edge_index, edge_attr, return_attention_weights=True\n",
    "                )\n",
    "                attention_list.append(attention_weights)\n",
    "                x = x + self.relu(x_conv)  # Residual Layers\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Attention weights of first layer\n",
    "        attention_weights = attention_weights.mean(dim=1)\n",
    "        print(\"attention_weights.mean(dim=1)\")\n",
    "        print(attention_weights)\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "        return x, edge_index_attention, attention_weights, attention_list\n",
    "\n",
    "# gnn architecture\n",
    "class ThisMultigraph(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        in_channels,\n",
    "        hidden_channels_gnn,\n",
    "        out_channels_gnn,\n",
    "        num_layers_gnn,\n",
    "        heads,\n",
    "        hidden_channels_deepset,\n",
    "        optimizer_class,\n",
    "        optimizer_params,\n",
    "    ):\n",
    "        super(ThisMultigraph, self).__init__()\n",
    "\n",
    "        self.encoder = EmbedStations(num_stations_max=122, embedding_dim=embedding_dim)\n",
    "\n",
    "        self.conv = ResGnn(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels_gnn,\n",
    "            out_channels=out_channels_gnn,\n",
    "            num_layers=num_layers_gnn,\n",
    "            heads=heads,\n",
    "        )\n",
    "\n",
    "        self.aggr = DeepSetAggregator(\n",
    "            in_channels=out_channels_gnn, hidden_channels=hidden_channels_deepset, out_channels=2\n",
    "        )\n",
    "\n",
    "        self.postprocess = MakePositive()\n",
    "        self.loss_fn = NormalCRPS()\n",
    "\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch_id, node_idx = data.x, data.edge_index, data.edge_attr, data.batch, data.n_idx\n",
    "        node_idx = node_idx + batch_id * 122  # add batch_id to node_idx to get unique node indices\n",
    "        x = self.encoder(x)\n",
    "        x = self.conv(x, edge_index, edge_attr)\n",
    "        x = self.aggr(x, node_idx)\n",
    "        x = self.postprocess(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=1\n",
    "        )  # The batch size is not actually 1 but the loss is already averaged over the batch\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.parameters(), **self.optimizer_params)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        return loss\n",
    "\n",
    "    def initialize(self, dataloader):\n",
    "        batch = next(iter(dataloader))\n",
    "        self.validation_step(batch, 0)"
   ],
   "id": "44be3299dc76b86c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load Graphs",
   "id": "39f9b06d4d02a511"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check if it runs for the first few batches\n",
    "in_channels = graphs_train_rf[0].x.shape[1]\n",
    "\n",
    "# model = SimpleGCN(in_features=in_channels, h_features=100, out_features=1, optimizer_class=AdamW, optimizer_params={\"lr\": 0.001})\n",
    "model = SimpleGCN(in_features=in_channels, h_features=100, out_features=2, optimizer_class=torch.optim.SGD, optimizer_params={\"lr\": 0.001})\n",
    "\n",
    "#print(model)\n",
    "train_iter = iter(train_loader)\n",
    "batch = next(train_iter)\n",
    "batch2 = next(train_iter)\n",
    "print(batch.y.shape)\n",
    "#print(len(batch))\n",
    "model.forward(batch)\n",
    "# print(model.forward(batch2))\n",
    "print(batch)\n",
    "print(batch2)\n",
    "\n",
    "\n",
    "print(\"[INFO] Creating data loaders...\")\n",
    "train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "print(\"[INFO] Creating model...\")\n",
    "emb_dim=20\n",
    "in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1\n",
    "\n",
    "embedding_dim=emb_dim\n",
    "in_channels=in_channels\n",
    "hidden_channels_gnn=config['gnn_hidden']\n",
    "out_channels_gnn=config['gnn_hidden']\n",
    "num_layers_gnn=config['gnn_hidden']\n",
    "heads=config['heads']\n",
    "hidden_channels_deepset=config['gnn_hidden']\n",
    "optimizer_class=AdamW\n",
    "optimizer_params=dict(lr=config['lr'])"
   ],
   "id": "23752d90b85fb597"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with wandb.init(\n",
    "    project=\"multigraph\", id=f\"training_run_24h\", config=args_dict, tags=[\"final_training\"]\n",
    "):\n",
    "    config = wandb.config\n",
    "\n",
    "    multigraph = ThisMultigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph)\n",
    "\n",
    "    # understand what this is\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch  # .to(\"cuda\")\n",
    "    multigraph  # .to(\"cuda\")\n",
    "    multigraph.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"multigraph\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph, train_dataloaders=train_loader)"
   ],
   "id": "aed19a2480556cb1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
