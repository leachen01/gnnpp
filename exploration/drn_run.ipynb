{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run DRN",
   "id": "2a41077302fdadb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:57:38.977345Z",
     "start_time": "2025-03-06T18:57:35.054949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#from typing import Any\n",
    "#from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "#from exploration.gnn_run import in_channels\n",
    "# load data first\n",
    "%cd /home/ltchen/gnnpp\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from models.drn import DRN\n",
    "from models.model_utils import EmbedStations\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "\n",
    "from utils.data import load_dataframes, summary_statistics\n",
    "from utils.drn_utils import *\n",
    "from models.loss import NormalCRPS"
   ],
   "id": "259579d6231826a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load dataframes for train, valid, test",
   "id": "d2df53cbcd0652e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:57:46.790411Z",
     "start_time": "2025-03-06T18:57:40.414218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = load_dataframes(mode=\"train\", leadtime=\"24h\") # train mode => for training nn? Wie wird das im Paper beschrieben?\n",
    "dataframes = summary_statistics(dataframes) # wie sehen die daten von summary statistics aus? => wenn das nur die Daten von einer Station sind, dann über Zeitpunkte\n",
    "dataframes.pop(\"stations\") # .pop(\"stations\") => entfernt den df mit stations, wofuer brauche ich die dann überhaupt? Grafik?\n",
    "\n",
    "# test\n",
    "for X, y in dataframes.values(): # wofuer?\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train, valid_test = normalize_features(\n",
    "    training_data=dataframes[\"train\"], valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]]\n",
    ")\n",
    "\n",
    "train = drop_nans(train)\n",
    "(test_rf, test_f) = valid_test\n",
    "test_rf = drop_nans(test_rf)\n",
    "test_f = drop_nans(test_f)\n",
    "\n",
    "DIRECTORY = os.getcwd()\n",
    "SAVEPATH = os.path.join(DIRECTORY, \"explored_models/drn_24h/models\")\n",
    "#print(train[1].isna().sum()) #drop_nans does not work without summary_statistics"
   ],
   "id": "e6d863460e3de5e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n",
      "[INFO] Normalizing features...\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T14:40:18.042661Z",
     "start_time": "2025-03-05T14:40:18.034485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nans = train[1][\"t2m\"].isna().reset_index(drop=True)\n",
    "print(train[0].index)\n",
    "print(train[1].index)\n",
    "#nans.index\n",
    "#train[0][~nans]\n",
    "#res = (train[0][~nans], train[1][~nans])\n",
    "#res"
   ],
   "id": "bc2332f570572189",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4627216, step=1)\n",
      "RangeIndex(start=0, stop=420656, step=1)\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T15:17:26.271842Z",
     "start_time": "2025-03-03T15:17:26.265961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# one station only\n",
    "# train\n",
    "for i in train:\n",
    "    print(i.shape)\n",
    "    print(i.columns)\n",
    "\n",
    "# valid_test\n",
    "for (i, j) in valid_test:\n",
    "    print(i.shape)\n",
    "    print(i.columns)"
   ],
   "id": "6c927fe1e7b6ae17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398866, 65)\n",
      "Index(['station_id', 'model_orography', 'station_altitude', 'station_latitude',\n",
      "       'station_longitude', 'cape_mean', 'cape_std', 'sd_mean', 'sd_std',\n",
      "       'stl1_mean', 'stl1_std', 'swvl1_mean', 'swvl1_std', 't2m_mean',\n",
      "       't2m_std', 'tcc_mean', 'tcc_std', 'tcw_mean', 'tcw_std', 'tcwv_mean',\n",
      "       'tcwv_std', 'u10_mean', 'u10_std', 'u100_mean', 'u100_std', 'v10_mean',\n",
      "       'v10_std', 'v100_mean', 'v100_std', 'vis_mean', 'vis_std', 'cp6_mean',\n",
      "       'cp6_std', 'mn2t6_mean', 'mn2t6_std', 'mx2t6_mean', 'mx2t6_std',\n",
      "       'p10fg6_mean', 'p10fg6_std', 'slhf6_mean', 'slhf6_std', 'sshf6_mean',\n",
      "       'sshf6_std', 'ssr6_mean', 'ssr6_std', 'ssrd6_mean', 'ssrd6_std',\n",
      "       'str6_mean', 'str6_std', 'strd6_mean', 'strd6_std', 'tp6_mean',\n",
      "       'tp6_std', 'z_mean', 'z_std', 'q_mean', 'q_std', 'u_mean', 'u_std',\n",
      "       'v_mean', 'v_std', 't_mean', 't_std', 'cos_doy', 'sin_doy'],\n",
      "      dtype='object')\n",
      "(398866, 3)\n",
      "Index(['time', 'station_id', 't2m'], dtype='object')\n",
      "(89304, 65)\n",
      "Index(['station_id', 'model_orography', 'station_altitude', 'station_latitude',\n",
      "       'station_longitude', 'cape_mean', 'cape_std', 'sd_mean', 'sd_std',\n",
      "       'stl1_mean', 'stl1_std', 'swvl1_mean', 'swvl1_std', 't2m_mean',\n",
      "       't2m_std', 'tcc_mean', 'tcc_std', 'tcw_mean', 'tcw_std', 'tcwv_mean',\n",
      "       'tcwv_std', 'u10_mean', 'u10_std', 'u100_mean', 'u100_std', 'v10_mean',\n",
      "       'v10_std', 'v100_mean', 'v100_std', 'vis_mean', 'vis_std', 'cp6_mean',\n",
      "       'cp6_std', 'mn2t6_mean', 'mn2t6_std', 'mx2t6_mean', 'mx2t6_std',\n",
      "       'p10fg6_mean', 'p10fg6_std', 'slhf6_mean', 'slhf6_std', 'sshf6_mean',\n",
      "       'sshf6_std', 'ssr6_mean', 'ssr6_std', 'ssrd6_mean', 'ssrd6_std',\n",
      "       'str6_mean', 'str6_std', 'strd6_mean', 'strd6_std', 'tp6_mean',\n",
      "       'tp6_std', 'z_mean', 'z_std', 'q_mean', 'q_std', 'u_mean', 'u_std',\n",
      "       'v_mean', 'v_std', 't_mean', 't_std', 'cos_doy', 'sin_doy'],\n",
      "      dtype='object')\n",
      "(89060, 65)\n",
      "Index(['station_id', 'model_orography', 'station_altitude', 'station_latitude',\n",
      "       'station_longitude', 'cape_mean', 'cape_std', 'sd_mean', 'sd_std',\n",
      "       'stl1_mean', 'stl1_std', 'swvl1_mean', 'swvl1_std', 't2m_mean',\n",
      "       't2m_std', 'tcc_mean', 'tcc_std', 'tcw_mean', 'tcw_std', 'tcwv_mean',\n",
      "       'tcwv_std', 'u10_mean', 'u10_std', 'u100_mean', 'u100_std', 'v10_mean',\n",
      "       'v10_std', 'v100_mean', 'v100_std', 'vis_mean', 'vis_std', 'cp6_mean',\n",
      "       'cp6_std', 'mn2t6_mean', 'mn2t6_std', 'mx2t6_mean', 'mx2t6_std',\n",
      "       'p10fg6_mean', 'p10fg6_std', 'slhf6_mean', 'slhf6_std', 'sshf6_mean',\n",
      "       'sshf6_std', 'ssr6_mean', 'ssr6_std', 'ssrd6_mean', 'ssrd6_std',\n",
      "       'str6_mean', 'str6_std', 'strd6_mean', 'strd6_std', 'tp6_mean',\n",
      "       'tp6_std', 'z_mean', 'z_std', 'q_mean', 'q_std', 'u_mean', 'u_std',\n",
      "       'v_mean', 'v_std', 't_mean', 't_std', 'cos_doy', 'sin_doy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## One Station",
   "id": "e082b2a18d2a4050"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:53:01.177123Z",
     "start_time": "2025-03-06T18:53:01.120337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train\n",
    "one_station_X = train[0][train[0][\"station_id\"]==1]\n",
    "one_station_y = train[1][train[1][\"station_id\"]==1]\n",
    "\n",
    "one_station_X = one_station_X.drop(\"station_id\", axis=1)\n",
    "one_station_y = one_station_y.drop(\"station_id\", axis=1)\n",
    "\n",
    "print(one_station_X)\n",
    "print(one_station_X.shape)\n",
    "print(one_station_y.shape)\n",
    "\n",
    "# test_rf\n",
    "s1_test_rf_X = test_rf[0][test_rf[0][\"station_id\"]==1]\n",
    "s1_test_rf_y = test_rf[1][test_rf[1][\"station_id\"]==1]\n",
    "\n",
    "s1_test_rf_X = s1_test_rf_X.drop(\"station_id\", axis=1)\n",
    "s1_test_rf_y = s1_test_rf_y.drop(\"station_id\", axis=1)\n",
    "\n",
    "# test_f\n",
    "s1_test_f_X = test_f[0][test_f[0][\"station_id\"]==1]\n",
    "s1_test_f_y = test_f[1][test_f[1][\"station_id\"]==1]\n",
    "\n",
    "s1_test_f_X = s1_test_f_X.drop(\"station_id\", axis=1)\n",
    "s1_test_f_y = s1_test_f_y.drop(\"station_id\", axis=1)"
   ],
   "id": "5318bf9a70ee77e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model_orography  station_altitude  station_latitude  \\\n",
      "1             -0.737002           -0.7786          1.016052   \n",
      "123           -0.737002           -0.7786          1.016052   \n",
      "245           -0.737002           -0.7786          1.016052   \n",
      "367           -0.737002           -0.7786          1.016052   \n",
      "489           -0.737002           -0.7786          1.016052   \n",
      "...                 ...               ...               ...   \n",
      "420047        -0.737002           -0.7786          1.016052   \n",
      "420169        -0.737002           -0.7786          1.016052   \n",
      "420291        -0.737002           -0.7786          1.016052   \n",
      "420413        -0.737002           -0.7786          1.016052   \n",
      "420535        -0.737002           -0.7786          1.016052   \n",
      "\n",
      "        station_longitude  cape_mean  cape_std   sd_mean    sd_std  stl1_mean  \\\n",
      "1                -0.89124  -0.164696 -0.233030 -0.138945 -0.130389  -0.465046   \n",
      "123              -0.89124  -0.127184 -0.138486 -0.138945 -0.130389  -0.443237   \n",
      "245              -0.89124  -0.157128 -0.205144 -0.138945 -0.130389  -0.493848   \n",
      "367              -0.89124  -0.179347 -0.224208 -0.138569 -0.118298  -0.666115   \n",
      "489              -0.89124  -0.194627 -0.269349 -0.128484 -0.094832  -1.032942   \n",
      "...                   ...        ...       ...       ...       ...        ...   \n",
      "420047           -0.89124  -0.180904 -0.217095 -0.138945 -0.130389  -0.408190   \n",
      "420169           -0.89124  -0.194627 -0.269349  0.049665  0.074999  -1.481411   \n",
      "420291           -0.89124  -0.031851 -0.021526 -0.138945 -0.130389  -0.087933   \n",
      "420413           -0.89124  -0.193998 -0.266479  0.195411  0.577944  -1.399988   \n",
      "420535           -0.89124  -0.190646 -0.252057 -0.134015 -0.125014  -1.370927   \n",
      "\n",
      "        stl1_std  ...    q_mean     q_std    u_mean     u_std    v_mean  \\\n",
      "1       1.073037  ...  0.433324  0.358571 -0.746920  5.432942  1.666245   \n",
      "123    -0.729082  ... -0.331529 -0.091183 -0.846796  0.530674  0.527320   \n",
      "245    -0.433906  ...  0.209089  0.499193  0.630721  1.430988  2.049817   \n",
      "367     0.323421  ... -0.490498 -0.462935  0.708757  1.573345 -1.295278   \n",
      "489    -0.800538  ... -1.349110 -0.811540 -0.002433  2.239311 -2.185997   \n",
      "...          ...  ...       ...       ...       ...       ...       ...   \n",
      "420047 -0.003070  ... -0.810062  0.193430  0.240393 -0.045242  0.851824   \n",
      "420169 -0.919173  ... -0.777223  0.669660 -0.460586 -0.380500  0.012031   \n",
      "420291 -0.913360  ...  0.608128  0.277408 -0.048647  2.699677  0.350894   \n",
      "420413 -0.529402  ... -0.944738 -0.154593  1.177332  1.458282  0.345556   \n",
      "420535  0.409809  ... -1.229235 -1.199663  0.113013 -0.301731  0.078417   \n",
      "\n",
      "           v_std    t_mean     t_std   cos_doy       sin_doy  \n",
      "1       2.520527 -0.757580  1.563501  0.999407  3.442161e-02  \n",
      "123     0.694997 -0.886288  0.894268  0.996298  8.596480e-02  \n",
      "245     1.632936 -0.570165 -0.268864  0.988023  1.543088e-01  \n",
      "367     1.865991 -1.100426  0.275097  0.978740  2.051045e-01  \n",
      "489     0.384951 -2.033739 -0.047349  0.962309  2.719582e-01  \n",
      "...          ...       ...       ...       ...           ...  \n",
      "420047 -0.678904 -0.126731 -0.880790  0.992749 -1.202080e-01  \n",
      "420169 -0.118070 -1.776431  0.891437  0.994671 -1.031017e-01  \n",
      "420291  0.586493 -0.020650  0.483000  0.997630 -6.880243e-02  \n",
      "420413  0.454055 -1.693830 -0.947345  0.998667 -5.161967e-02  \n",
      "420535 -0.118211 -0.965405 -0.356925  1.000000  6.432491e-16  \n",
      "\n",
      "[3448 rows x 64 columns]\n",
      "(3448, 64)\n",
      "(3448, 2)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### One Station MSE and CRPS NNs\n",
    "Station (station_id=1) with one hidden layer and loss functions MSE or CRPS"
   ],
   "id": "241d282af9a75045"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:54:27.122703Z",
     "start_time": "2025-03-06T18:54:27.112935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSEStationNN(L.LightningModule):\n",
    "    def __init__(self, in_feat, hidden_size, optimizer_class, optimizer_params):\n",
    "        super(MSEStationNN, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=in_feat, out_features=hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear_t2m = torch.nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_t2m(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y.flatten())\n",
    "        self.log(\"train_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.parameters(), **self.optimizer_params)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y.flatten())\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0): # unterschied zwischen predict und test_step?\n",
    "        x, y = batch # wieso hat test_step auch y? => um score zu berechnen\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y.flatten())\n",
    "        return loss\n"
   ],
   "id": "89a9fc3e00e76201",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:56:42.841495Z",
     "start_time": "2025-03-06T18:56:42.822814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CRPSStationNN(L.LightningModule):\n",
    "    def __init__(self, in_feat, hidden_size, optimizer_class, optimizer_params):\n",
    "        super(CRPSStationNN, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=in_feat, out_features=hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        #self.linear_t2m = torch.nn.Linear(in_features=hidden_size, out_features=2) => wieso nicht direkt 2 outputs?\n",
    "        self.softplus = torch.nn.Softplus()\n",
    "        self.last_linear_mu = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        self.last_linear_sigma = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "        self.loss_fn = NormalCRPS()\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        mu = self.last_linear_mu(x)\n",
    "        sigma = self.softplus(self.last_linear_sigma(x))\n",
    "        res = torch.cat([mu, sigma], dim=1)\n",
    "        return res\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=y.flatten())\n",
    "        self.log(\"train_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.parameters(), **self.optimizer_params)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=y.flatten())\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=y.flatten())\n",
    "        print(f'test_loss: {loss}')\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, _ = batch\n",
    "        y_hat = self.forward(x)\n",
    "        return y_hat\n"
   ],
   "id": "2a867835aca7d93c",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train One Station NN (MSE or CRPS)",
   "id": "85bca1426de9002b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:56:51.719558Z",
     "start_time": "2025-03-06T18:56:45.315672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with wandb.init(\n",
    "    project=\"exploration\",\n",
    "    id = f\"training_run_24h_crps\",\n",
    "    tags=[\"exploration\"],\n",
    "):\n",
    "\n",
    "    y_scaler = StandardScaler(with_std=False) # wieso scalen wir überhaupt? => robuster?\n",
    "    y_scaler = y_scaler.fit(one_station_y[[\"t2m\"]])\n",
    "\n",
    "    batch_size = 512\n",
    "    hidden_size=128\n",
    "    lr=0.0002\n",
    "    max_epochs=31\n",
    "    in_feat = one_station_X.shape[1]\n",
    "\n",
    "    one_station_train_ds = TensorDataset(torch.Tensor(one_station_X.to_numpy()), torch.Tensor(y_scaler.transform(one_station_y[[\"t2m\"]])))\n",
    "    one_station_loader = DataLoader(one_station_train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    s1_test_rf_ds = TensorDataset(torch.Tensor(s1_test_rf_X.to_numpy()), torch.Tensor(y_scaler.transform(s1_test_rf_y[[\"t2m\"]])))\n",
    "    s1_test_rf_loader = DataLoader(s1_test_rf_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    one_station_nn = CRPSStationNN(\n",
    "        in_feat=in_feat,\n",
    "        hidden_size=hidden_size,\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params={\"lr\": lr}\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"one_station_crps\")\n",
    "\n",
    "    os_checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    one_station_trainer = L.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        enable_model_summary=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=os_checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    value = one_station_trainer.fit(model=one_station_nn, train_dataloaders=one_station_loader)\n",
    "\n",
    "    final_loss = one_station_trainer.logged_metrics[\"train_loss_step\"] # nochmal step und epoch nachschauen\n",
    "    print(\"Final MSE Loss:\", final_loss)\n",
    "\n",
    "\n",
    "# wo finde ich den tatsaechlichen wert? => bei test, jetzt wird nur das Modell trainiert"
   ],
   "id": "4b50303c1b2a53dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250306_195645-training_run_24h_crps</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/exploration/runs/training_run_24h_crps' target=\"_blank\">training_run_24h_crps</a></strong> to <a href='https://wandb.ai/leachen_thesis/exploration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/exploration' target=\"_blank\">https://wandb.ai/leachen_thesis/exploration</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/exploration/runs/training_run_24h_crps' target=\"_blank\">https://wandb.ai/leachen_thesis/exploration/runs/training_run_24h_crps</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/drn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name              | Type       | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | linear            | Linear     | 8.3 K  | train\n",
      "1 | relu              | ReLU       | 0      | train\n",
      "2 | softplus          | Softplus   | 0      | train\n",
      "3 | last_linear_mu    | Linear     | 129    | train\n",
      "4 | last_linear_sigma | Linear     | 129    | train\n",
      "5 | loss_fn           | NormalCRPS | 0      | train\n",
      "---------------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 7/7 [00:00<00:00, 57.77it/s, v_num=crps, train_loss_step=1.320, train_loss_epoch=1.280]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=31` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 7/7 [00:00<00:00, 52.44it/s, v_num=crps, train_loss_step=1.320, train_loss_epoch=1.280]\n",
      "Final MSE Loss: tensor(1.3195)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>███▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇██▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_loss_epoch</td><td>1.28279</td></tr><tr><td>train_loss_step</td><td>1.31945</td></tr><tr><td>trainer/global_step</td><td>216</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h_crps</strong> at: <a href='https://wandb.ai/leachen_thesis/exploration/runs/training_run_24h_crps' target=\"_blank\">https://wandb.ai/leachen_thesis/exploration/runs/training_run_24h_crps</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/exploration' target=\"_blank\">https://wandb.ai/leachen_thesis/exploration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_195645-training_run_24h_crps/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Validate and test one station NN (MSE and CRPS)",
   "id": "a235b5768b328247"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:56:52.292576Z",
     "start_time": "2025-03-06T18:56:52.258300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# validation and test for both mse and crps\n",
    "s1_test_f_ds = TensorDataset(torch.Tensor(s1_test_f_X.to_numpy()), torch.Tensor(y_scaler.transform(s1_test_f_y[[\"t2m\"]])))\n",
    "s1_test_f_loader = DataLoader(s1_test_f_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "loss = one_station_trainer.test(model=one_station_nn, dataloaders=s1_test_f_loader)\n",
    "print(loss)\n"
   ],
   "id": "98751ab483dbdbad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]test_loss: 1.2687277793884277\n",
      "Testing DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 351.05it/s]test_loss: 1.2436953783035278\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 225.69it/s]\n",
      "[{}]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:56:55.343547Z",
     "start_time": "2025-03-06T18:56:55.298072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds_list = []\n",
    "preds = one_station_trainer.predict(model=one_station_nn, dataloaders=s1_test_f_loader)\n",
    "preds = torch.cat(preds, dim=0)\n",
    "print(f\"preds.shape: {preds.shape}\")\n",
    "print(f\"first preds: {preds[0]}\")\n",
    "# Reverse transform of the y_scaler (only on the mean)\n",
    "preds[:, 0] = torch.Tensor(y_scaler.inverse_transform(preds[:, 0].view(-1, 1))).flatten()\n",
    "\n",
    "preds_list.append(preds)\n",
    "print(f\"preds_list length: {preds_list[0][0]}\")\n",
    "targets = s1_test_f_y\n",
    "targets = torch.Tensor(targets.t2m.values)\n",
    "\n",
    "stacked = torch.stack(preds_list)\n",
    "print(f\"stacked shape: {stacked.shape}\")\n",
    "#final_preds = torch.mean(stacked, dim=0)\n",
    "\n",
    "final_preds = stacked[0]\n",
    "\n",
    "res = one_station_nn.loss_fn.crps(final_preds, targets)\n",
    "print(f\"final pred: {final_preds[0]}, targets: {targets[0]}\")\n",
    "print(res)"
   ],
   "id": "3459bfa367dd8d7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 218.93it/s]\n",
      "preds.shape: torch.Size([730, 2])\n",
      "first preds: tensor([-3.1140,  1.9057])\n",
      "preds_list length: tensor([279.2640,   1.9057])\n",
      "stacked shape: torch.Size([1, 730, 2])\n",
      "final pred: tensor([279.2640,   1.9057]), targets: 275.25\n",
      "tensor(1.2613)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## All stations\n",
    "Deterministic NN with one hidden layer using MSE as loss and embeddings"
   ],
   "id": "b03ba0eb2efcc5ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:33:48.867043Z",
     "start_time": "2025-03-06T18:33:48.854783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn mse loss with lightning\n",
    "class MyDRN(L.LightningModule):\n",
    "    def __init__(self, hidden_size, embedding_dim, in_feat, optimizer_class, optimizer_params):\n",
    "        super(MyDRN, self).__init__()\n",
    "        self.embedding = EmbedStations(num_stations_max=122, embedding_dim=embedding_dim)\n",
    "        self.linear = torch.nn.Linear(in_features=in_feat, out_features=hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear_t2m = torch.nn.Linear(in_features=hidden_size, out_features=1) # output t2m value\n",
    "\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #print(x.shape) # (8, 65)\n",
    "        x = self.embedding(x)\n",
    "        #print(f\"After embedding: {x.shape}\") # (8, 84)\n",
    "        x = self.linear(x)\n",
    "        #print(x.shape) # (8, 64)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.linear_t2m(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y.flatten()) # why y.flatten()?\n",
    "        self.log(\"train_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.parameters(), **self.optimizer_params)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y.flatten())\n",
    "        self.log(\"validation_loss\", loss.item(), on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0): # unterschied zwischen predict und test_step?\n",
    "        x, y = batch # wieso hat test_step auch y?\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y.flatten())\n",
    "        self.log(\"test_loss\", loss.item(), on_epoch=True, prog_bar=True)\n",
    "        return loss"
   ],
   "id": "44c786dfddc886f5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:57:57.444154Z",
     "start_time": "2025-03-06T18:57:57.431459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn crps loss with lightning\n",
    "class CRPSDRN(L.LightningModule):\n",
    "    def __init__(self, embedding_dim, in_channels, hidden_channels, optimizer_class, optimizer_params):\n",
    "        super(CRPSDRN, self).__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = len(hidden_channels)\n",
    "\n",
    "        self.embedding = EmbedStations(num_stations_max=122, embedding_dim=embedding_dim)\n",
    "        self.linear = nn.ModuleList()\n",
    "        for hidden_size in self.hidden_channels:\n",
    "            self.linear.append(nn.Linear(in_features=in_channels, out_features=hidden_size))\n",
    "            in_channels = hidden_size\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softplus = torch.nn.Softplus()\n",
    "        self.last_linear_mu = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        self.last_linear_sigma = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "        self.loss_fn = NormalCRPS()\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x) #(8, 65)\n",
    "        for layer in self.linear:\n",
    "            x = layer(x)\n",
    "            print(x.shape)\n",
    "            x = self.relu(x)\n",
    "            print(x.shape)\n",
    "        mu = self.last_linear_mu(x)\n",
    "        x = self.relu(x) #(8, 64)\n",
    "        mu = self.last_linear_mu(x)\n",
    "        sigma = self.softplus(self.last_linear_sigma(x))\n",
    "        res = torch.cat([mu, sigma], dim=1)\n",
    "        return res\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=y.flatten())\n",
    "        self.log(\"train_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.parameters(), **self.optimizer_params)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=y.flatten())\n",
    "        self.log(\"validation_loss\", loss.item(), on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0): # unterschied zwischen predict und test_step?\n",
    "        x, y = batch # wieso hat test_step auch y?\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=y.flatten())\n",
    "        self.log(\"test_loss\", loss.item(), on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, _ = batch\n",
    "        y_hat = self.forward(x)\n",
    "        return y_hat\n"
   ],
   "id": "c5fc771b6f40b322",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:58:36.191341Z",
     "start_time": "2025-03-06T18:58:36.173861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import json file to config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "CHECKPOINT_FOLDER = os.path.join(DIRECTORY, \"trained_models/drn_24h\")\n",
    "JSONPATH = os.path.join(CHECKPOINT_FOLDER, \"params.json\")\n",
    "\n",
    "with open(JSONPATH, \"r\") as f:\n",
    "    print(f\"[INFO] Loading {JSONPATH}\")\n",
    "    args_dict = json.load(f)\n",
    "config = args_dict\n",
    "# check if it works, if not: see in drn_eval\n",
    "'''\n",
    "@dataclass\n",
    "class DummyConfig:\n",
    "    pass\n",
    "\n",
    "for key, value in args_dict.items():\n",
    "    setattr(DummyConfig, key, value)\n",
    "\n",
    "config = DummyConfig()\n",
    "print(\"[INFO] Starting eval with config: \", args_dict)\n",
    "'''\n",
    "'''params.json\n",
    "{\"batch_size\":8,\n",
    "\"gnn_hidden\":265,\n",
    "\"gnn_layers\":2,\n",
    "\"heads\":8,\n",
    "\"lr\":0.0002,\n",
    "\"max_dist\":100,\n",
    "\"max_epochs\": 31}\n",
    "'''\n"
   ],
   "id": "62ef912cb76ea7f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/ltchen/gnnpp/trained_models/drn_24h/params.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'params.json\\n{\"batch_size\":8,\\n\"gnn_hidden\":265,\\n\"gnn_layers\":2,\\n\"heads\":8,\\n\"lr\":0.0002,\\n\"max_dist\":100,\\n\"max_epochs\": 31}\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train All_station NN",
   "id": "42059a627190cbd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T19:01:14.064688Z",
     "start_time": "2025-03-06T18:58:42.604475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with wandb.init(\n",
    "    project=\"reproduction\",\n",
    "    id = f\"training_run_24h_crps\",\n",
    "    config=config,\n",
    "    tags=[\"exploration\"],\n",
    "):\n",
    "    config=wandb.config\n",
    "    y_scaler = StandardScaler(with_std=False) # wieso scalen wir überhaupt? => robuster?\n",
    "    y_scaler = y_scaler.fit(train[1][[\"t2m\"]])\n",
    "\n",
    "    #batch_size =2048\n",
    "    #hidden_size=128\n",
    "    #lr=0.0002\n",
    "    #max_epochs=31\n",
    "\n",
    "    embed_dim = 20\n",
    "    in_channels = train[0].shape[1] + embed_dim - 1\n",
    "\n",
    "\n",
    "    train_dataset = TensorDataset(torch.Tensor(train[0].to_numpy()), torch.Tensor(y_scaler.transform(train[1][[\"t2m\"]])))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    mydrn = CRPSDRN(\n",
    "        embedding_dim=embed_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels=config.hidden_channels,\n",
    "\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config.lr),\n",
    ")\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"all_station_crps\")\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config.max_epochs,\n",
    "        log_every_n_steps=10,\n",
    "        accelerator=\"gpu\",\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    ")\n",
    "\n",
    "    trainer.fit(model=mydrn, train_dataloaders=train_loader)\n",
    "\n",
    "    final_loss = trainer.logged_metrics[\"train_loss_step\"]\n",
    "    print(\"Final MSE Loss:\", final_loss)"
   ],
   "id": "bf99bb0901426414",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mleachen\u001B[0m (\u001B[33mleachen_thesis\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250306_195843-training_run_24h_crps</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/reproduction/runs/training_run_24h_crps' target=\"_blank\">training_run_24h_crps</a></strong> to <a href='https://wandb.ai/leachen_thesis/reproduction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/reproduction' target=\"_blank\">https://wandb.ai/leachen_thesis/reproduction</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/reproduction/runs/training_run_24h_crps' target=\"_blank\">https://wandb.ai/leachen_thesis/reproduction/runs/training_run_24h_crps</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/drn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name              | Type          | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | embedding         | EmbedStations | 2.4 K  | train\n",
      "1 | linear            | ModuleList    | 21.8 K | train\n",
      "2 | relu              | ReLU          | 0      | train\n",
      "3 | softplus          | Softplus      | 0      | train\n",
      "4 | last_linear_mu    | Linear        | 257    | train\n",
      "5 | last_linear_sigma | Linear        | 257    | train\n",
      "6 | loss_fn           | NormalCRPS    | 0      | train\n",
      "------------------------------------------------------------\n",
      "24.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.7 K    Total params\n",
      "0.099     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/98 [00:00<?, ?it/s] torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   1%|          | 1/98 [00:00<01:07,  1.45it/s, v_num=crps, train_loss_step=4.800]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   2%|▏         | 2/98 [00:00<00:34,  2.75it/s, v_num=crps, train_loss_step=3.890]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   3%|▎         | 3/98 [00:00<00:24,  3.94it/s, v_num=crps, train_loss_step=2.850]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   4%|▍         | 4/98 [00:00<00:19,  4.91it/s, v_num=crps, train_loss_step=2.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   5%|▌         | 5/98 [00:00<00:15,  5.90it/s, v_num=crps, train_loss_step=1.720]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   6%|▌         | 6/98 [00:01<00:16,  5.53it/s, v_num=crps, train_loss_step=1.880]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   7%|▋         | 7/98 [00:01<00:14,  6.11it/s, v_num=crps, train_loss_step=2.080]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   8%|▊         | 8/98 [00:01<00:13,  6.72it/s, v_num=crps, train_loss_step=2.100]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:   9%|▉         | 9/98 [00:01<00:12,  7.35it/s, v_num=crps, train_loss_step=1.900]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  10%|█         | 10/98 [00:01<00:11,  7.85it/s, v_num=crps, train_loss_step=1.680]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  11%|█         | 11/98 [00:01<00:10,  8.43it/s, v_num=crps, train_loss_step=1.440]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  12%|█▏        | 12/98 [00:01<00:09,  8.84it/s, v_num=crps, train_loss_step=1.340]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  13%|█▎        | 13/98 [00:01<00:09,  9.34it/s, v_num=crps, train_loss_step=1.300]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  14%|█▍        | 14/98 [00:01<00:08,  9.83it/s, v_num=crps, train_loss_step=1.330]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  15%|█▌        | 15/98 [00:01<00:08, 10.28it/s, v_num=crps, train_loss_step=1.260]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  16%|█▋        | 16/98 [00:01<00:07, 10.73it/s, v_num=crps, train_loss_step=1.210]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  17%|█▋        | 17/98 [00:01<00:08, 10.00it/s, v_num=crps, train_loss_step=1.180]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  18%|█▊        | 18/98 [00:01<00:07, 10.30it/s, v_num=crps, train_loss_step=1.190]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  19%|█▉        | 19/98 [00:01<00:07, 10.68it/s, v_num=crps, train_loss_step=1.140]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  20%|██        | 20/98 [00:01<00:07, 11.04it/s, v_num=crps, train_loss_step=1.050]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  21%|██▏       | 21/98 [00:01<00:06, 11.28it/s, v_num=crps, train_loss_step=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  22%|██▏       | 22/98 [00:01<00:06, 11.62it/s, v_num=crps, train_loss_step=1.000]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  23%|██▎       | 23/98 [00:01<00:06, 11.94it/s, v_num=crps, train_loss_step=1.000]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  24%|██▍       | 24/98 [00:01<00:06, 12.24it/s, v_num=crps, train_loss_step=0.990]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  26%|██▌       | 25/98 [00:01<00:05, 12.53it/s, v_num=crps, train_loss_step=0.998]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  27%|██▋       | 26/98 [00:02<00:05, 12.80it/s, v_num=crps, train_loss_step=0.961]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  28%|██▊       | 27/98 [00:02<00:05, 13.08it/s, v_num=crps, train_loss_step=0.965]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  29%|██▊       | 28/98 [00:02<00:05, 12.22it/s, v_num=crps, train_loss_step=0.940]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  30%|██▉       | 29/98 [00:02<00:05, 12.47it/s, v_num=crps, train_loss_step=0.942]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  31%|███       | 30/98 [00:02<00:05, 12.73it/s, v_num=crps, train_loss_step=0.912]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  32%|███▏      | 31/98 [00:02<00:05, 12.96it/s, v_num=crps, train_loss_step=0.891]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  33%|███▎      | 32/98 [00:02<00:05, 13.12it/s, v_num=crps, train_loss_step=0.884]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  34%|███▎      | 33/98 [00:02<00:04, 13.36it/s, v_num=crps, train_loss_step=0.879]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  35%|███▍      | 34/98 [00:02<00:04, 13.45it/s, v_num=crps, train_loss_step=0.862]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  36%|███▌      | 35/98 [00:02<00:04, 13.66it/s, v_num=crps, train_loss_step=0.868]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  37%|███▋      | 36/98 [00:02<00:04, 13.86it/s, v_num=crps, train_loss_step=0.858]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  38%|███▊      | 37/98 [00:02<00:04, 14.06it/s, v_num=crps, train_loss_step=0.837]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  39%|███▉      | 38/98 [00:02<00:04, 14.26it/s, v_num=crps, train_loss_step=0.844]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  40%|███▉      | 39/98 [00:02<00:04, 13.51it/s, v_num=crps, train_loss_step=0.833]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  41%|████      | 40/98 [00:02<00:04, 13.71it/s, v_num=crps, train_loss_step=0.814]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  42%|████▏     | 41/98 [00:02<00:04, 13.89it/s, v_num=crps, train_loss_step=0.826]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  43%|████▎     | 42/98 [00:02<00:03, 14.07it/s, v_num=crps, train_loss_step=0.801]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  44%|████▍     | 43/98 [00:03<00:03, 14.23it/s, v_num=crps, train_loss_step=0.805]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  45%|████▍     | 44/98 [00:03<00:03, 14.31it/s, v_num=crps, train_loss_step=0.799]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  46%|████▌     | 45/98 [00:03<00:03, 14.48it/s, v_num=crps, train_loss_step=0.793]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  47%|████▋     | 46/98 [00:03<00:03, 14.54it/s, v_num=crps, train_loss_step=0.795]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  48%|████▊     | 47/98 [00:03<00:03, 14.71it/s, v_num=crps, train_loss_step=0.795]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  49%|████▉     | 48/98 [00:03<00:03, 14.86it/s, v_num=crps, train_loss_step=0.793]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  50%|█████     | 49/98 [00:03<00:03, 15.01it/s, v_num=crps, train_loss_step=0.758]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  51%|█████     | 50/98 [00:03<00:03, 14.39it/s, v_num=crps, train_loss_step=0.811]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  52%|█████▏    | 51/98 [00:03<00:03, 14.54it/s, v_num=crps, train_loss_step=0.761]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  53%|█████▎    | 52/98 [00:03<00:03, 14.60it/s, v_num=crps, train_loss_step=0.769]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  54%|█████▍    | 53/98 [00:03<00:03, 14.75it/s, v_num=crps, train_loss_step=0.772]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  55%|█████▌    | 54/98 [00:03<00:02, 14.80it/s, v_num=crps, train_loss_step=0.777]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  56%|█████▌    | 55/98 [00:03<00:02, 14.91it/s, v_num=crps, train_loss_step=0.760]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  57%|█████▋    | 56/98 [00:03<00:02, 14.97it/s, v_num=crps, train_loss_step=0.766]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  58%|█████▊    | 57/98 [00:03<00:02, 15.09it/s, v_num=crps, train_loss_step=0.753]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  59%|█████▉    | 58/98 [00:03<00:02, 15.14it/s, v_num=crps, train_loss_step=0.761]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  60%|██████    | 59/98 [00:03<00:02, 15.20it/s, v_num=crps, train_loss_step=0.732]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  61%|██████    | 60/98 [00:03<00:02, 15.33it/s, v_num=crps, train_loss_step=0.767]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  62%|██████▏   | 61/98 [00:04<00:02, 14.74it/s, v_num=crps, train_loss_step=0.758]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  63%|██████▎   | 62/98 [00:04<00:02, 14.86it/s, v_num=crps, train_loss_step=0.743]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  64%|██████▍   | 63/98 [00:04<00:02, 14.89it/s, v_num=crps, train_loss_step=0.748]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  65%|██████▌   | 64/98 [00:04<00:02, 14.94it/s, v_num=crps, train_loss_step=0.739]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  66%|██████▋   | 65/98 [00:04<00:02, 15.01it/s, v_num=crps, train_loss_step=0.731]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  67%|██████▋   | 66/98 [00:04<00:02, 15.07it/s, v_num=crps, train_loss_step=0.745]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  68%|██████▊   | 67/98 [00:04<00:02, 15.10it/s, v_num=crps, train_loss_step=0.751]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  69%|██████▉   | 68/98 [00:04<00:01, 15.20it/s, v_num=crps, train_loss_step=0.742]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  70%|███████   | 69/98 [00:04<00:01, 15.28it/s, v_num=crps, train_loss_step=0.731]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  71%|███████▏  | 70/98 [00:04<00:01, 15.35it/s, v_num=crps, train_loss_step=0.721]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  72%|███████▏  | 71/98 [00:04<00:01, 15.46it/s, v_num=crps, train_loss_step=0.722]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  73%|███████▎  | 72/98 [00:04<00:01, 14.97it/s, v_num=crps, train_loss_step=0.731]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  74%|███████▍  | 73/98 [00:04<00:01, 15.07it/s, v_num=crps, train_loss_step=0.736]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  76%|███████▌  | 74/98 [00:04<00:01, 15.17it/s, v_num=crps, train_loss_step=0.717]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  77%|███████▋  | 75/98 [00:04<00:01, 15.26it/s, v_num=crps, train_loss_step=0.722]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  78%|███████▊  | 76/98 [00:04<00:01, 15.35it/s, v_num=crps, train_loss_step=0.718]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  79%|███████▊  | 77/98 [00:04<00:01, 15.45it/s, v_num=crps, train_loss_step=0.720]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  80%|███████▉  | 78/98 [00:05<00:01, 15.48it/s, v_num=crps, train_loss_step=0.714]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  81%|████████  | 79/98 [00:05<00:01, 15.56it/s, v_num=crps, train_loss_step=0.707]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  82%|████████▏ | 80/98 [00:05<00:01, 15.66it/s, v_num=crps, train_loss_step=0.712]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  83%|████████▎ | 81/98 [00:05<00:01, 15.71it/s, v_num=crps, train_loss_step=0.706]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  84%|████████▎ | 82/98 [00:05<00:01, 15.71it/s, v_num=crps, train_loss_step=0.731]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  85%|████████▍ | 83/98 [00:05<00:00, 15.30it/s, v_num=crps, train_loss_step=0.714]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  86%|████████▌ | 84/98 [00:05<00:00, 15.38it/s, v_num=crps, train_loss_step=0.715]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  87%|████████▋ | 85/98 [00:05<00:00, 15.41it/s, v_num=crps, train_loss_step=0.710]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  88%|████████▊ | 86/98 [00:05<00:00, 15.50it/s, v_num=crps, train_loss_step=0.714]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  89%|████████▉ | 87/98 [00:05<00:00, 15.52it/s, v_num=crps, train_loss_step=0.704]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  90%|████████▉ | 88/98 [00:05<00:00, 15.56it/s, v_num=crps, train_loss_step=0.725]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  91%|█████████ | 89/98 [00:05<00:00, 15.64it/s, v_num=crps, train_loss_step=0.711]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  92%|█████████▏| 90/98 [00:05<00:00, 15.73it/s, v_num=crps, train_loss_step=0.687]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  93%|█████████▎| 91/98 [00:05<00:00, 15.81it/s, v_num=crps, train_loss_step=0.725]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  94%|█████████▍| 92/98 [00:05<00:00, 15.85it/s, v_num=crps, train_loss_step=0.712]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  95%|█████████▍| 93/98 [00:05<00:00, 15.87it/s, v_num=crps, train_loss_step=0.697]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  96%|█████████▌| 94/98 [00:06<00:00, 15.46it/s, v_num=crps, train_loss_step=0.714]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  97%|█████████▋| 95/98 [00:06<00:00, 15.54it/s, v_num=crps, train_loss_step=0.704]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  98%|█████████▊| 96/98 [00:06<00:00, 15.62it/s, v_num=crps, train_loss_step=0.696]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 0:  99%|█████████▉| 97/98 [00:06<00:00, 15.69it/s, v_num=crps, train_loss_step=0.703]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 1:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.714, train_loss_epoch=1.010]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   1%|          | 1/98 [00:00<00:05, 17.54it/s, v_num=crps, train_loss_step=0.704, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   2%|▏         | 2/98 [00:00<00:05, 18.59it/s, v_num=crps, train_loss_step=0.708, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   3%|▎         | 3/98 [00:00<00:04, 21.40it/s, v_num=crps, train_loss_step=0.714, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   4%|▍         | 4/98 [00:00<00:04, 22.89it/s, v_num=crps, train_loss_step=0.698, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   5%|▌         | 5/98 [00:00<00:03, 23.66it/s, v_num=crps, train_loss_step=0.706, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   6%|▌         | 6/98 [00:00<00:03, 24.13it/s, v_num=crps, train_loss_step=0.702, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   7%|▋         | 7/98 [00:00<00:06, 14.96it/s, v_num=crps, train_loss_step=0.696, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   8%|▊         | 8/98 [00:00<00:05, 15.84it/s, v_num=crps, train_loss_step=0.711, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:   9%|▉         | 9/98 [00:00<00:05, 16.67it/s, v_num=crps, train_loss_step=0.706, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  10%|█         | 10/98 [00:00<00:05, 17.46it/s, v_num=crps, train_loss_step=0.690, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  11%|█         | 11/98 [00:00<00:04, 18.21it/s, v_num=crps, train_loss_step=0.712, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  12%|█▏        | 12/98 [00:00<00:04, 18.43it/s, v_num=crps, train_loss_step=0.679, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  13%|█▎        | 13/98 [00:00<00:04, 18.89it/s, v_num=crps, train_loss_step=0.703, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  14%|█▍        | 14/98 [00:00<00:04, 19.14it/s, v_num=crps, train_loss_step=0.699, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  15%|█▌        | 15/98 [00:00<00:04, 19.63it/s, v_num=crps, train_loss_step=0.690, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  16%|█▋        | 16/98 [00:00<00:04, 20.08it/s, v_num=crps, train_loss_step=0.700, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  17%|█▋        | 17/98 [00:01<00:04, 16.91it/s, v_num=crps, train_loss_step=0.695, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  18%|█▊        | 18/98 [00:01<00:04, 17.31it/s, v_num=crps, train_loss_step=0.680, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  19%|█▉        | 19/98 [00:01<00:04, 17.73it/s, v_num=crps, train_loss_step=0.681, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  20%|██        | 20/98 [00:01<00:04, 18.12it/s, v_num=crps, train_loss_step=0.690, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  21%|██▏       | 21/98 [00:01<00:04, 18.48it/s, v_num=crps, train_loss_step=0.679, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  22%|██▏       | 22/98 [00:01<00:04, 18.81it/s, v_num=crps, train_loss_step=0.683, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  23%|██▎       | 23/98 [00:01<00:03, 19.09it/s, v_num=crps, train_loss_step=0.688, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  24%|██▍       | 24/98 [00:01<00:03, 19.37it/s, v_num=crps, train_loss_step=0.680, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  26%|██▌       | 25/98 [00:01<00:03, 19.30it/s, v_num=crps, train_loss_step=0.684, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  27%|██▋       | 26/98 [00:01<00:03, 19.39it/s, v_num=crps, train_loss_step=0.700, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  28%|██▊       | 27/98 [00:01<00:03, 19.33it/s, v_num=crps, train_loss_step=0.698, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  29%|██▊       | 28/98 [00:01<00:04, 17.43it/s, v_num=crps, train_loss_step=0.703, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  30%|██▉       | 29/98 [00:01<00:03, 17.70it/s, v_num=crps, train_loss_step=0.685, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  31%|███       | 30/98 [00:01<00:03, 17.73it/s, v_num=crps, train_loss_step=0.672, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  32%|███▏      | 31/98 [00:01<00:03, 17.93it/s, v_num=crps, train_loss_step=0.689, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  33%|███▎      | 32/98 [00:01<00:03, 18.14it/s, v_num=crps, train_loss_step=0.690, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  34%|███▎      | 33/98 [00:01<00:03, 18.35it/s, v_num=crps, train_loss_step=0.676, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  35%|███▍      | 34/98 [00:01<00:03, 18.32it/s, v_num=crps, train_loss_step=0.708, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  36%|███▌      | 35/98 [00:01<00:03, 18.37it/s, v_num=crps, train_loss_step=0.701, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  37%|███▋      | 36/98 [00:01<00:03, 18.42it/s, v_num=crps, train_loss_step=0.672, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  38%|███▊      | 37/98 [00:01<00:03, 18.51it/s, v_num=crps, train_loss_step=0.685, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  39%|███▉      | 38/98 [00:02<00:03, 17.23it/s, v_num=crps, train_loss_step=0.690, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  40%|███▉      | 39/98 [00:02<00:03, 17.40it/s, v_num=crps, train_loss_step=0.688, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  41%|████      | 40/98 [00:02<00:03, 17.60it/s, v_num=crps, train_loss_step=0.675, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  42%|████▏     | 41/98 [00:02<00:03, 17.79it/s, v_num=crps, train_loss_step=0.683, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  43%|████▎     | 42/98 [00:02<00:03, 17.95it/s, v_num=crps, train_loss_step=0.692, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  44%|████▍     | 43/98 [00:02<00:03, 17.99it/s, v_num=crps, train_loss_step=0.674, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  45%|████▍     | 44/98 [00:02<00:02, 18.14it/s, v_num=crps, train_loss_step=0.698, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  46%|████▌     | 45/98 [00:02<00:02, 18.28it/s, v_num=crps, train_loss_step=0.694, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  47%|████▋     | 46/98 [00:02<00:02, 18.25it/s, v_num=crps, train_loss_step=0.676, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  48%|████▊     | 47/98 [00:02<00:02, 18.39it/s, v_num=crps, train_loss_step=0.689, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  49%|████▉     | 48/98 [00:02<00:02, 18.54it/s, v_num=crps, train_loss_step=0.683, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  50%|█████     | 49/98 [00:02<00:02, 17.41it/s, v_num=crps, train_loss_step=0.696, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  51%|█████     | 50/98 [00:02<00:02, 17.56it/s, v_num=crps, train_loss_step=0.685, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  52%|█████▏    | 51/98 [00:02<00:02, 17.61it/s, v_num=crps, train_loss_step=0.678, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  53%|█████▎    | 52/98 [00:02<00:02, 17.75it/s, v_num=crps, train_loss_step=0.665, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  54%|█████▍    | 53/98 [00:02<00:02, 17.90it/s, v_num=crps, train_loss_step=0.686, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  55%|█████▌    | 54/98 [00:02<00:02, 18.01it/s, v_num=crps, train_loss_step=0.673, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  56%|█████▌    | 55/98 [00:03<00:02, 18.08it/s, v_num=crps, train_loss_step=0.682, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  57%|█████▋    | 56/98 [00:03<00:02, 18.21it/s, v_num=crps, train_loss_step=0.691, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  58%|█████▊    | 57/98 [00:03<00:02, 18.34it/s, v_num=crps, train_loss_step=0.671, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  59%|█████▉    | 58/98 [00:03<00:02, 18.47it/s, v_num=crps, train_loss_step=0.687, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  60%|██████    | 59/98 [00:03<00:02, 18.50it/s, v_num=crps, train_loss_step=0.687, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  61%|██████    | 60/98 [00:03<00:02, 17.61it/s, v_num=crps, train_loss_step=0.680, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  62%|██████▏   | 61/98 [00:03<00:02, 17.71it/s, v_num=crps, train_loss_step=0.665, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  63%|██████▎   | 62/98 [00:03<00:02, 17.72it/s, v_num=crps, train_loss_step=0.682, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  64%|██████▍   | 63/98 [00:03<00:01, 17.85it/s, v_num=crps, train_loss_step=0.679, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  65%|██████▌   | 64/98 [00:03<00:01, 17.84it/s, v_num=crps, train_loss_step=0.697, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  66%|██████▋   | 65/98 [00:03<00:01, 17.84it/s, v_num=crps, train_loss_step=0.683, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  67%|██████▋   | 66/98 [00:03<00:01, 17.80it/s, v_num=crps, train_loss_step=0.684, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  68%|██████▊   | 67/98 [00:03<00:01, 17.80it/s, v_num=crps, train_loss_step=0.673, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  69%|██████▉   | 68/98 [00:03<00:01, 17.87it/s, v_num=crps, train_loss_step=0.677, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  70%|███████   | 69/98 [00:03<00:01, 17.87it/s, v_num=crps, train_loss_step=0.687, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  71%|███████▏  | 70/98 [00:03<00:01, 17.86it/s, v_num=crps, train_loss_step=0.675, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  72%|███████▏  | 71/98 [00:04<00:01, 17.04it/s, v_num=crps, train_loss_step=0.659, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  73%|███████▎  | 72/98 [00:04<00:01, 17.08it/s, v_num=crps, train_loss_step=0.695, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  74%|███████▍  | 73/98 [00:04<00:01, 17.17it/s, v_num=crps, train_loss_step=0.669, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  76%|███████▌  | 74/98 [00:04<00:01, 17.21it/s, v_num=crps, train_loss_step=0.685, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  77%|███████▋  | 75/98 [00:04<00:01, 17.22it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  78%|███████▊  | 76/98 [00:04<00:01, 17.30it/s, v_num=crps, train_loss_step=0.686, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  79%|███████▊  | 77/98 [00:04<00:01, 17.39it/s, v_num=crps, train_loss_step=0.679, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  80%|███████▉  | 78/98 [00:04<00:01, 17.42it/s, v_num=crps, train_loss_step=0.666, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  81%|████████  | 79/98 [00:04<00:01, 17.51it/s, v_num=crps, train_loss_step=0.679, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  82%|████████▏ | 80/98 [00:04<00:01, 17.60it/s, v_num=crps, train_loss_step=0.681, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  83%|████████▎ | 81/98 [00:04<00:00, 17.61it/s, v_num=crps, train_loss_step=0.668, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  84%|████████▎ | 82/98 [00:04<00:00, 17.05it/s, v_num=crps, train_loss_step=0.688, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  85%|████████▍ | 83/98 [00:04<00:00, 17.03it/s, v_num=crps, train_loss_step=0.693, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  86%|████████▌ | 84/98 [00:04<00:00, 17.11it/s, v_num=crps, train_loss_step=0.681, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  87%|████████▋ | 85/98 [00:04<00:00, 17.20it/s, v_num=crps, train_loss_step=0.682, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  88%|████████▊ | 86/98 [00:04<00:00, 17.28it/s, v_num=crps, train_loss_step=0.671, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  89%|████████▉ | 87/98 [00:05<00:00, 17.36it/s, v_num=crps, train_loss_step=0.677, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  90%|████████▉ | 88/98 [00:05<00:00, 17.42it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  91%|█████████ | 89/98 [00:05<00:00, 17.48it/s, v_num=crps, train_loss_step=0.675, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  92%|█████████▏| 90/98 [00:05<00:00, 17.56it/s, v_num=crps, train_loss_step=0.681, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  93%|█████████▎| 91/98 [00:05<00:00, 17.57it/s, v_num=crps, train_loss_step=0.673, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  94%|█████████▍| 92/98 [00:05<00:00, 17.60it/s, v_num=crps, train_loss_step=0.662, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  95%|█████████▍| 93/98 [00:05<00:00, 17.08it/s, v_num=crps, train_loss_step=0.688, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  96%|█████████▌| 94/98 [00:05<00:00, 17.16it/s, v_num=crps, train_loss_step=0.681, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  97%|█████████▋| 95/98 [00:05<00:00, 17.21it/s, v_num=crps, train_loss_step=0.676, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  98%|█████████▊| 96/98 [00:05<00:00, 17.30it/s, v_num=crps, train_loss_step=0.675, train_loss_epoch=1.010]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 1:  99%|█████████▉| 97/98 [00:05<00:00, 17.36it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=1.010]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 2:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.681, train_loss_epoch=0.685]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   1%|          | 1/98 [00:00<00:07, 12.20it/s, v_num=crps, train_loss_step=0.662, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   2%|▏         | 2/98 [00:00<00:06, 15.05it/s, v_num=crps, train_loss_step=0.676, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   3%|▎         | 3/98 [00:00<00:05, 17.07it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   4%|▍         | 4/98 [00:00<00:05, 18.47it/s, v_num=crps, train_loss_step=0.665, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   5%|▌         | 5/98 [00:00<00:04, 20.00it/s, v_num=crps, train_loss_step=0.662, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   6%|▌         | 6/98 [00:00<00:04, 21.07it/s, v_num=crps, train_loss_step=0.669, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   7%|▋         | 7/98 [00:00<00:06, 14.16it/s, v_num=crps, train_loss_step=0.674, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   8%|▊         | 8/98 [00:00<00:06, 14.65it/s, v_num=crps, train_loss_step=0.680, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:   9%|▉         | 9/98 [00:00<00:05, 15.51it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  10%|█         | 10/98 [00:00<00:05, 15.57it/s, v_num=crps, train_loss_step=0.677, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  11%|█         | 11/98 [00:00<00:05, 16.30it/s, v_num=crps, train_loss_step=0.678, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  12%|█▏        | 12/98 [00:00<00:05, 16.93it/s, v_num=crps, train_loss_step=0.677, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  13%|█▎        | 13/98 [00:00<00:04, 17.23it/s, v_num=crps, train_loss_step=0.667, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  14%|█▍        | 14/98 [00:00<00:04, 17.79it/s, v_num=crps, train_loss_step=0.668, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  15%|█▌        | 15/98 [00:00<00:04, 18.25it/s, v_num=crps, train_loss_step=0.659, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  16%|█▋        | 16/98 [00:00<00:04, 18.65it/s, v_num=crps, train_loss_step=0.684, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  17%|█▋        | 17/98 [00:00<00:04, 19.08it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  18%|█▊        | 18/98 [00:01<00:04, 16.38it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  19%|█▉        | 19/98 [00:01<00:04, 16.79it/s, v_num=crps, train_loss_step=0.663, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  20%|██        | 20/98 [00:01<00:04, 17.16it/s, v_num=crps, train_loss_step=0.685, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  21%|██▏       | 21/98 [00:01<00:04, 17.10it/s, v_num=crps, train_loss_step=0.671, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  22%|██▏       | 22/98 [00:01<00:04, 17.43it/s, v_num=crps, train_loss_step=0.665, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  23%|██▎       | 23/98 [00:01<00:04, 17.51it/s, v_num=crps, train_loss_step=0.670, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  24%|██▍       | 24/98 [00:01<00:04, 17.79it/s, v_num=crps, train_loss_step=0.662, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  26%|██▌       | 25/98 [00:01<00:04, 17.85it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  27%|██▋       | 26/98 [00:01<00:03, 18.07it/s, v_num=crps, train_loss_step=0.672, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  28%|██▊       | 27/98 [00:01<00:03, 18.15it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  29%|██▊       | 28/98 [00:01<00:04, 16.41it/s, v_num=crps, train_loss_step=0.674, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  30%|██▉       | 29/98 [00:01<00:04, 16.65it/s, v_num=crps, train_loss_step=0.680, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  31%|███       | 30/98 [00:01<00:04, 16.71it/s, v_num=crps, train_loss_step=0.668, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  32%|███▏      | 31/98 [00:01<00:03, 16.85it/s, v_num=crps, train_loss_step=0.673, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  33%|███▎      | 32/98 [00:01<00:03, 16.99it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  34%|███▎      | 33/98 [00:01<00:03, 17.06it/s, v_num=crps, train_loss_step=0.659, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  35%|███▍      | 34/98 [00:01<00:03, 17.29it/s, v_num=crps, train_loss_step=0.662, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  36%|███▌      | 35/98 [00:02<00:03, 17.45it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  37%|███▋      | 36/98 [00:02<00:03, 17.51it/s, v_num=crps, train_loss_step=0.672, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  38%|███▊      | 37/98 [00:02<00:03, 16.33it/s, v_num=crps, train_loss_step=0.670, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  39%|███▉      | 38/98 [00:02<00:03, 16.44it/s, v_num=crps, train_loss_step=0.663, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  40%|███▉      | 39/98 [00:02<00:03, 16.62it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  41%|████      | 40/98 [00:02<00:03, 16.65it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  42%|████▏     | 41/98 [00:02<00:03, 16.63it/s, v_num=crps, train_loss_step=0.670, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  43%|████▎     | 42/98 [00:02<00:03, 16.81it/s, v_num=crps, train_loss_step=0.668, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  44%|████▍     | 43/98 [00:02<00:03, 16.99it/s, v_num=crps, train_loss_step=0.676, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  45%|████▍     | 44/98 [00:02<00:03, 17.15it/s, v_num=crps, train_loss_step=0.665, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  46%|████▌     | 45/98 [00:02<00:03, 17.13it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  47%|████▋     | 46/98 [00:02<00:03, 17.24it/s, v_num=crps, train_loss_step=0.675, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  48%|████▊     | 47/98 [00:02<00:02, 17.41it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  49%|████▉     | 48/98 [00:02<00:03, 16.48it/s, v_num=crps, train_loss_step=0.658, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  50%|█████     | 49/98 [00:02<00:02, 16.64it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  51%|█████     | 50/98 [00:02<00:02, 16.76it/s, v_num=crps, train_loss_step=0.663, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  52%|█████▏    | 51/98 [00:03<00:02, 16.90it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  53%|█████▎    | 52/98 [00:03<00:02, 16.95it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  54%|█████▍    | 53/98 [00:03<00:02, 17.08it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  55%|█████▌    | 54/98 [00:03<00:02, 17.22it/s, v_num=crps, train_loss_step=0.670, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  56%|█████▌    | 55/98 [00:03<00:02, 17.35it/s, v_num=crps, train_loss_step=0.668, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  57%|█████▋    | 56/98 [00:03<00:02, 17.48it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  58%|█████▊    | 57/98 [00:03<00:02, 17.60it/s, v_num=crps, train_loss_step=0.655, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  59%|█████▉    | 58/98 [00:03<00:02, 16.77it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  60%|██████    | 59/98 [00:03<00:02, 16.91it/s, v_num=crps, train_loss_step=0.665, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  61%|██████    | 60/98 [00:03<00:02, 17.01it/s, v_num=crps, train_loss_step=0.678, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  62%|██████▏   | 61/98 [00:03<00:02, 17.15it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  63%|██████▎   | 62/98 [00:03<00:02, 17.20it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  64%|██████▍   | 63/98 [00:03<00:02, 17.32it/s, v_num=crps, train_loss_step=0.673, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  65%|██████▌   | 64/98 [00:03<00:01, 17.42it/s, v_num=crps, train_loss_step=0.658, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  66%|██████▋   | 65/98 [00:03<00:01, 17.47it/s, v_num=crps, train_loss_step=0.658, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  67%|██████▋   | 66/98 [00:03<00:01, 17.59it/s, v_num=crps, train_loss_step=0.668, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  68%|██████▊   | 67/98 [00:03<00:01, 17.67it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  69%|██████▉   | 68/98 [00:03<00:01, 17.78it/s, v_num=crps, train_loss_step=0.649, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  70%|███████   | 69/98 [00:04<00:01, 17.11it/s, v_num=crps, train_loss_step=0.663, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  71%|███████▏  | 70/98 [00:04<00:01, 17.11it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  72%|███████▏  | 71/98 [00:04<00:01, 17.14it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  73%|███████▎  | 72/98 [00:04<00:01, 17.24it/s, v_num=crps, train_loss_step=0.670, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  74%|███████▍  | 73/98 [00:04<00:01, 17.32it/s, v_num=crps, train_loss_step=0.655, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  76%|███████▌  | 74/98 [00:04<00:01, 17.36it/s, v_num=crps, train_loss_step=0.666, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  77%|███████▋  | 75/98 [00:04<00:01, 17.46it/s, v_num=crps, train_loss_step=0.658, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  78%|███████▊  | 76/98 [00:04<00:01, 17.55it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  79%|███████▊  | 77/98 [00:04<00:01, 17.64it/s, v_num=crps, train_loss_step=0.667, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  80%|███████▉  | 78/98 [00:04<00:01, 17.73it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  81%|████████  | 79/98 [00:04<00:01, 17.82it/s, v_num=crps, train_loss_step=0.692, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  82%|████████▏ | 80/98 [00:04<00:01, 17.16it/s, v_num=crps, train_loss_step=0.666, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  83%|████████▎ | 81/98 [00:04<00:00, 17.25it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  84%|████████▎ | 82/98 [00:04<00:00, 17.34it/s, v_num=crps, train_loss_step=0.655, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  85%|████████▍ | 83/98 [00:04<00:00, 17.42it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  86%|████████▌ | 84/98 [00:04<00:00, 17.51it/s, v_num=crps, train_loss_step=0.655, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  87%|████████▋ | 85/98 [00:04<00:00, 17.59it/s, v_num=crps, train_loss_step=0.668, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  88%|████████▊ | 86/98 [00:04<00:00, 17.67it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  89%|████████▉ | 87/98 [00:04<00:00, 17.70it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  90%|████████▉ | 88/98 [00:04<00:00, 17.73it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  91%|█████████ | 89/98 [00:04<00:00, 17.80it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  92%|█████████▏| 90/98 [00:05<00:00, 17.83it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  93%|█████████▎| 91/98 [00:05<00:00, 17.31it/s, v_num=crps, train_loss_step=0.655, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  94%|█████████▍| 92/98 [00:05<00:00, 17.39it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  95%|█████████▍| 93/98 [00:05<00:00, 17.42it/s, v_num=crps, train_loss_step=0.659, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  96%|█████████▌| 94/98 [00:05<00:00, 17.43it/s, v_num=crps, train_loss_step=0.649, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  97%|█████████▋| 95/98 [00:05<00:00, 17.51it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  98%|█████████▊| 96/98 [00:05<00:00, 17.59it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.685]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 2:  99%|█████████▉| 97/98 [00:05<00:00, 17.67it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.685]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 3:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.674, train_loss_epoch=0.663]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   1%|          | 1/98 [00:00<00:07, 12.43it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   2%|▏         | 2/98 [00:00<00:05, 17.08it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   3%|▎         | 3/98 [00:00<00:04, 19.28it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   4%|▍         | 4/98 [00:00<00:04, 21.03it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   5%|▌         | 5/98 [00:00<00:04, 20.55it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   6%|▌         | 6/98 [00:00<00:06, 13.18it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   7%|▋         | 7/98 [00:00<00:06, 14.35it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   8%|▊         | 8/98 [00:00<00:05, 15.36it/s, v_num=crps, train_loss_step=0.673, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:   9%|▉         | 9/98 [00:00<00:05, 16.12it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  10%|█         | 10/98 [00:00<00:05, 16.64it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  11%|█         | 11/98 [00:00<00:05, 17.34it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  12%|█▏        | 12/98 [00:00<00:04, 17.57it/s, v_num=crps, train_loss_step=0.663, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  13%|█▎        | 13/98 [00:00<00:04, 17.90it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  14%|█▍        | 14/98 [00:00<00:04, 17.95it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  15%|█▌        | 15/98 [00:00<00:04, 18.42it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  16%|█▋        | 16/98 [00:01<00:05, 15.59it/s, v_num=crps, train_loss_step=0.662, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  17%|█▋        | 17/98 [00:01<00:05, 15.78it/s, v_num=crps, train_loss_step=0.660, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  18%|█▊        | 18/98 [00:01<00:04, 16.13it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  19%|█▉        | 19/98 [00:01<00:04, 16.53it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  20%|██        | 20/98 [00:01<00:04, 16.90it/s, v_num=crps, train_loss_step=0.660, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  21%|██▏       | 21/98 [00:01<00:04, 17.28it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  22%|██▏       | 22/98 [00:01<00:04, 17.63it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  23%|██▎       | 23/98 [00:01<00:04, 17.96it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  24%|██▍       | 24/98 [00:01<00:04, 18.26it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  26%|██▌       | 25/98 [00:01<00:03, 18.32it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  27%|██▋       | 26/98 [00:01<00:03, 18.59it/s, v_num=crps, train_loss_step=0.649, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  28%|██▊       | 27/98 [00:01<00:04, 16.78it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  29%|██▊       | 28/98 [00:01<00:04, 17.00it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  30%|██▉       | 29/98 [00:01<00:04, 17.24it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  31%|███       | 30/98 [00:01<00:03, 17.35it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  32%|███▏      | 31/98 [00:01<00:03, 17.58it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  33%|███▎      | 32/98 [00:01<00:03, 17.81it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  34%|███▎      | 33/98 [00:01<00:03, 18.03it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  35%|███▍      | 34/98 [00:01<00:03, 18.21it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  36%|███▌      | 35/98 [00:01<00:03, 18.23it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  37%|███▋      | 36/98 [00:01<00:03, 18.39it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  38%|███▊      | 37/98 [00:02<00:03, 17.05it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  39%|███▉      | 38/98 [00:02<00:03, 17.19it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  40%|███▉      | 39/98 [00:02<00:03, 17.38it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  41%|████      | 40/98 [00:02<00:03, 17.58it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  42%|████▏     | 41/98 [00:02<00:03, 17.75it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  43%|████▎     | 42/98 [00:02<00:03, 17.79it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  44%|████▍     | 43/98 [00:02<00:03, 17.95it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  45%|████▍     | 44/98 [00:02<00:02, 18.12it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  46%|████▌     | 45/98 [00:02<00:02, 18.29it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  47%|████▋     | 46/98 [00:02<00:03, 17.20it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  48%|████▊     | 47/98 [00:02<00:02, 17.21it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  49%|████▉     | 48/98 [00:02<00:02, 17.21it/s, v_num=crps, train_loss_step=0.649, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  50%|█████     | 49/98 [00:02<00:02, 17.29it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  51%|█████     | 50/98 [00:02<00:02, 17.34it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  52%|█████▏    | 51/98 [00:02<00:02, 17.39it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  53%|█████▎    | 52/98 [00:02<00:02, 17.55it/s, v_num=crps, train_loss_step=0.659, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  54%|█████▍    | 53/98 [00:03<00:02, 17.62it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  55%|█████▌    | 54/98 [00:03<00:02, 17.75it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  56%|█████▌    | 55/98 [00:03<00:02, 17.89it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  57%|█████▋    | 56/98 [00:03<00:02, 18.00it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  58%|█████▊    | 57/98 [00:03<00:02, 17.16it/s, v_num=crps, train_loss_step=0.660, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  59%|█████▉    | 58/98 [00:03<00:02, 17.16it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  60%|██████    | 59/98 [00:03<00:02, 17.28it/s, v_num=crps, train_loss_step=0.663, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  61%|██████    | 60/98 [00:03<00:02, 17.31it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  62%|██████▏   | 61/98 [00:03<00:02, 17.44it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  63%|██████▎   | 62/98 [00:03<00:02, 17.53it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  64%|██████▍   | 63/98 [00:03<00:01, 17.56it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  65%|██████▌   | 64/98 [00:03<00:01, 17.59it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  66%|██████▋   | 65/98 [00:03<00:01, 17.71it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  67%|██████▋   | 66/98 [00:03<00:01, 17.82it/s, v_num=crps, train_loss_step=0.655, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  68%|██████▊   | 67/98 [00:03<00:01, 17.12it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  69%|██████▉   | 68/98 [00:03<00:01, 17.11it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  70%|███████   | 69/98 [00:04<00:01, 17.21it/s, v_num=crps, train_loss_step=0.667, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  71%|███████▏  | 70/98 [00:04<00:01, 17.32it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  72%|███████▏  | 71/98 [00:04<00:01, 17.43it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  73%|███████▎  | 72/98 [00:04<00:01, 17.53it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  74%|███████▍  | 73/98 [00:04<00:01, 17.62it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  76%|███████▌  | 74/98 [00:04<00:01, 17.65it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  77%|███████▋  | 75/98 [00:04<00:01, 17.71it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  78%|███████▊  | 76/98 [00:04<00:01, 17.81it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  79%|███████▊  | 77/98 [00:04<00:01, 17.92it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  80%|███████▉  | 78/98 [00:04<00:01, 17.32it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  81%|████████  | 79/98 [00:04<00:01, 17.39it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  82%|████████▏ | 80/98 [00:04<00:01, 17.41it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  83%|████████▎ | 81/98 [00:04<00:00, 17.47it/s, v_num=crps, train_loss_step=0.649, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  84%|████████▎ | 82/98 [00:04<00:00, 17.56it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  85%|████████▍ | 83/98 [00:04<00:00, 17.64it/s, v_num=crps, train_loss_step=0.670, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  86%|████████▌ | 84/98 [00:04<00:00, 17.70it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  87%|████████▋ | 85/98 [00:04<00:00, 17.73it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  88%|████████▊ | 86/98 [00:04<00:00, 17.82it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  89%|████████▉ | 87/98 [00:04<00:00, 17.85it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  90%|████████▉ | 88/98 [00:04<00:00, 17.89it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  91%|█████████ | 89/98 [00:05<00:00, 17.26it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  92%|█████████▏| 90/98 [00:05<00:00, 17.29it/s, v_num=crps, train_loss_step=0.649, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  93%|█████████▎| 91/98 [00:05<00:00, 17.35it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  94%|█████████▍| 92/98 [00:05<00:00, 17.40it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  95%|█████████▍| 93/98 [00:05<00:00, 17.40it/s, v_num=crps, train_loss_step=0.679, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  96%|█████████▌| 94/98 [00:05<00:00, 17.42it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  97%|█████████▋| 95/98 [00:05<00:00, 17.49it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  98%|█████████▊| 96/98 [00:05<00:00, 17.50it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.663]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 3:  99%|█████████▉| 97/98 [00:05<00:00, 17.51it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.663]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 4:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.669, train_loss_epoch=0.649]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   1%|          | 1/98 [00:00<00:04, 19.43it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   2%|▏         | 2/98 [00:00<00:04, 23.43it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   3%|▎         | 3/98 [00:00<00:04, 20.93it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   4%|▍         | 4/98 [00:00<00:08, 10.81it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   5%|▌         | 5/98 [00:00<00:08, 11.59it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   6%|▌         | 6/98 [00:00<00:07, 12.81it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   7%|▋         | 7/98 [00:00<00:06, 14.03it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   8%|▊         | 8/98 [00:00<00:05, 15.08it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:   9%|▉         | 9/98 [00:00<00:05, 15.53it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  10%|█         | 10/98 [00:00<00:05, 16.29it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  11%|█         | 11/98 [00:00<00:05, 16.55it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  12%|█▏        | 12/98 [00:00<00:05, 16.81it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  13%|█▎        | 13/98 [00:00<00:04, 17.34it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  14%|█▍        | 14/98 [00:00<00:04, 17.45it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  15%|█▌        | 15/98 [00:01<00:05, 14.59it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  16%|█▋        | 16/98 [00:01<00:05, 14.65it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  17%|█▋        | 17/98 [00:01<00:05, 15.06it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  18%|█▊        | 18/98 [00:01<00:05, 15.47it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  19%|█▉        | 19/98 [00:01<00:05, 15.78it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  20%|██        | 20/98 [00:01<00:04, 16.09it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  21%|██▏       | 21/98 [00:01<00:04, 16.21it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  22%|██▏       | 22/98 [00:01<00:04, 16.16it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  23%|██▎       | 23/98 [00:01<00:04, 16.36it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  24%|██▍       | 24/98 [00:01<00:04, 16.63it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  26%|██▌       | 25/98 [00:01<00:04, 16.91it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  27%|██▋       | 26/98 [00:01<00:04, 15.34it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  28%|██▊       | 27/98 [00:01<00:04, 15.61it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  29%|██▊       | 28/98 [00:01<00:04, 15.72it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  30%|██▉       | 29/98 [00:01<00:04, 15.85it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  31%|███       | 30/98 [00:01<00:04, 16.12it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  32%|███▏      | 31/98 [00:01<00:04, 16.37it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  33%|███▎      | 32/98 [00:01<00:03, 16.59it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  34%|███▎      | 33/98 [00:01<00:03, 16.61it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  35%|███▍      | 34/98 [00:02<00:03, 16.77it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  36%|███▌      | 35/98 [00:02<00:03, 16.84it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  37%|███▋      | 36/98 [00:02<00:03, 17.03it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  38%|███▊      | 37/98 [00:02<00:03, 15.93it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  39%|███▉      | 38/98 [00:02<00:03, 15.98it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  40%|███▉      | 39/98 [00:02<00:03, 16.03it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  41%|████      | 40/98 [00:02<00:03, 16.19it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  42%|████▏     | 41/98 [00:02<00:03, 16.36it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  43%|████▎     | 42/98 [00:02<00:03, 16.53it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  44%|████▍     | 43/98 [00:02<00:03, 16.69it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  45%|████▍     | 44/98 [00:02<00:03, 16.83it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  46%|████▌     | 45/98 [00:02<00:03, 16.99it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  47%|████▋     | 46/98 [00:02<00:03, 17.14it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  48%|████▊     | 47/98 [00:02<00:02, 17.30it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  49%|████▉     | 48/98 [00:02<00:03, 16.31it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  50%|█████     | 49/98 [00:02<00:02, 16.38it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  51%|█████     | 50/98 [00:03<00:02, 16.54it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  52%|█████▏    | 51/98 [00:03<00:02, 16.69it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  53%|█████▎    | 52/98 [00:03<00:02, 16.83it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  54%|█████▍    | 53/98 [00:03<00:02, 16.82it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  55%|█████▌    | 54/98 [00:03<00:02, 16.91it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  56%|█████▌    | 55/98 [00:03<00:02, 16.95it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  57%|█████▋    | 56/98 [00:03<00:02, 17.02it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  58%|█████▊    | 57/98 [00:03<00:02, 17.14it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  59%|█████▉    | 58/98 [00:03<00:02, 17.20it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  60%|██████    | 59/98 [00:03<00:02, 16.47it/s, v_num=crps, train_loss_step=0.662, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  61%|██████    | 60/98 [00:03<00:02, 16.45it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  62%|██████▏   | 61/98 [00:03<00:02, 16.51it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  63%|██████▎   | 62/98 [00:03<00:02, 16.54it/s, v_num=crps, train_loss_step=0.661, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  64%|██████▍   | 63/98 [00:03<00:02, 16.63it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  65%|██████▌   | 64/98 [00:03<00:02, 16.75it/s, v_num=crps, train_loss_step=0.660, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  66%|██████▋   | 65/98 [00:03<00:01, 16.87it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  67%|██████▋   | 66/98 [00:03<00:01, 16.96it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  68%|██████▊   | 67/98 [00:03<00:01, 17.09it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  69%|██████▉   | 68/98 [00:03<00:01, 17.20it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  70%|███████   | 69/98 [00:03<00:01, 17.29it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  71%|███████▏  | 70/98 [00:04<00:01, 16.58it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  72%|███████▏  | 71/98 [00:04<00:01, 16.69it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  73%|███████▎  | 72/98 [00:04<00:01, 16.78it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  74%|███████▍  | 73/98 [00:04<00:01, 16.88it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  76%|███████▌  | 74/98 [00:04<00:01, 16.90it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  77%|███████▋  | 75/98 [00:04<00:01, 16.99it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  78%|███████▊  | 76/98 [00:04<00:01, 17.07it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  79%|███████▊  | 77/98 [00:04<00:01, 17.15it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  80%|███████▉  | 78/98 [00:04<00:01, 17.23it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  81%|████████  | 79/98 [00:04<00:01, 17.33it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  82%|████████▏ | 80/98 [00:04<00:01, 17.41it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  83%|████████▎ | 81/98 [00:04<00:01, 16.80it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  84%|████████▎ | 82/98 [00:04<00:00, 16.83it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  85%|████████▍ | 83/98 [00:04<00:00, 16.91it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  86%|████████▌ | 84/98 [00:04<00:00, 17.00it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  87%|████████▋ | 85/98 [00:04<00:00, 17.08it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  88%|████████▊ | 86/98 [00:05<00:00, 17.17it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  89%|████████▉ | 87/98 [00:05<00:00, 17.25it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  90%|████████▉ | 88/98 [00:05<00:00, 17.27it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  91%|█████████ | 89/98 [00:05<00:00, 17.30it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  92%|█████████▏| 90/98 [00:05<00:00, 17.39it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  93%|█████████▎| 91/98 [00:05<00:00, 17.46it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  94%|█████████▍| 92/98 [00:05<00:00, 16.97it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  95%|█████████▍| 93/98 [00:05<00:00, 17.05it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  96%|█████████▌| 94/98 [00:05<00:00, 17.12it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  97%|█████████▋| 95/98 [00:05<00:00, 17.10it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  98%|█████████▊| 96/98 [00:05<00:00, 17.17it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.649]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 4:  99%|█████████▉| 97/98 [00:05<00:00, 17.25it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.649]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 5:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.642]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   1%|          | 1/98 [00:00<00:05, 17.95it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   2%|▏         | 2/98 [00:00<00:04, 21.22it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   3%|▎         | 3/98 [00:00<00:05, 18.84it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   4%|▍         | 4/98 [00:00<00:04, 20.73it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   5%|▌         | 5/98 [00:00<00:07, 12.37it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   6%|▌         | 6/98 [00:00<00:06, 13.63it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   7%|▋         | 7/98 [00:00<00:06, 14.75it/s, v_num=crps, train_loss_step=0.656, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   8%|▊         | 8/98 [00:00<00:05, 15.80it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:   9%|▉         | 9/98 [00:00<00:05, 16.70it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  10%|█         | 10/98 [00:00<00:05, 17.51it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  11%|█         | 11/98 [00:00<00:04, 18.25it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  12%|█▏        | 12/98 [00:00<00:04, 18.33it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  13%|█▎        | 13/98 [00:00<00:04, 18.96it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  14%|█▍        | 14/98 [00:00<00:04, 19.56it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  15%|█▌        | 15/98 [00:00<00:04, 20.08it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  16%|█▋        | 16/98 [00:00<00:04, 16.63it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  17%|█▋        | 17/98 [00:00<00:04, 17.09it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  18%|█▊        | 18/98 [00:01<00:04, 17.29it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  19%|█▉        | 19/98 [00:01<00:04, 17.47it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  20%|██        | 20/98 [00:01<00:04, 17.87it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  21%|██▏       | 21/98 [00:01<00:04, 18.24it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  22%|██▏       | 22/98 [00:01<00:04, 18.29it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  23%|██▎       | 23/98 [00:01<00:04, 18.59it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  24%|██▍       | 24/98 [00:01<00:03, 18.89it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  26%|██▌       | 25/98 [00:01<00:03, 19.16it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  27%|██▋       | 26/98 [00:01<00:03, 19.43it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  28%|██▊       | 27/98 [00:01<00:04, 17.17it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  29%|██▊       | 28/98 [00:01<00:04, 17.44it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  30%|██▉       | 29/98 [00:01<00:03, 17.69it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  31%|███       | 30/98 [00:01<00:03, 17.92it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  32%|███▏      | 31/98 [00:01<00:03, 17.89it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  33%|███▎      | 32/98 [00:01<00:03, 18.07it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  34%|███▎      | 33/98 [00:01<00:03, 18.27it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  35%|███▍      | 34/98 [00:01<00:03, 18.44it/s, v_num=crps, train_loss_step=0.652, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  36%|███▌      | 35/98 [00:01<00:03, 18.60it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  37%|███▋      | 36/98 [00:01<00:03, 18.78it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  38%|███▊      | 37/98 [00:01<00:03, 19.00it/s, v_num=crps, train_loss_step=0.649, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  39%|███▉      | 38/98 [00:02<00:03, 17.62it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  40%|███▉      | 39/98 [00:02<00:03, 17.81it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  41%|████      | 40/98 [00:02<00:03, 17.84it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  42%|████▏     | 41/98 [00:02<00:03, 17.99it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  43%|████▎     | 42/98 [00:02<00:03, 18.15it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  44%|████▍     | 43/98 [00:02<00:03, 18.29it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  45%|████▍     | 44/98 [00:02<00:02, 18.45it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  46%|████▌     | 45/98 [00:02<00:02, 18.45it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  47%|████▋     | 46/98 [00:02<00:02, 18.60it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  48%|████▊     | 47/98 [00:02<00:02, 18.53it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  49%|████▉     | 48/98 [00:02<00:02, 18.56it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  50%|█████     | 49/98 [00:02<00:02, 17.50it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  51%|█████     | 50/98 [00:02<00:02, 17.64it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  52%|█████▏    | 51/98 [00:02<00:02, 17.63it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  53%|█████▎    | 52/98 [00:02<00:02, 17.68it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  54%|█████▍    | 53/98 [00:02<00:02, 17.79it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  55%|█████▌    | 54/98 [00:03<00:02, 17.91it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  56%|█████▌    | 55/98 [00:03<00:02, 18.05it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  57%|█████▋    | 56/98 [00:03<00:02, 18.18it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  58%|█████▊    | 57/98 [00:03<00:02, 18.30it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  59%|█████▉    | 58/98 [00:03<00:02, 18.43it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  60%|██████    | 59/98 [00:03<00:02, 18.55it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  61%|██████    | 60/98 [00:03<00:02, 17.57it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  62%|██████▏   | 61/98 [00:03<00:02, 17.59it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  63%|██████▎   | 62/98 [00:03<00:02, 17.67it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  64%|██████▍   | 63/98 [00:03<00:01, 17.79it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  65%|██████▌   | 64/98 [00:03<00:01, 17.90it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  66%|██████▋   | 65/98 [00:03<00:01, 18.01it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  67%|██████▋   | 66/98 [00:03<00:01, 18.12it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  68%|██████▊   | 67/98 [00:03<00:01, 18.08it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  69%|██████▉   | 68/98 [00:03<00:01, 18.18it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  70%|███████   | 69/98 [00:03<00:01, 18.28it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  71%|███████▏  | 70/98 [00:03<00:01, 18.38it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  72%|███████▏  | 71/98 [00:04<00:01, 17.67it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  73%|███████▎  | 72/98 [00:04<00:01, 17.71it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  74%|███████▍  | 73/98 [00:04<00:01, 17.81it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  76%|███████▌  | 74/98 [00:04<00:01, 17.92it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  77%|███████▋  | 75/98 [00:04<00:01, 17.95it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  78%|███████▊  | 76/98 [00:04<00:01, 17.96it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  79%|███████▊  | 77/98 [00:04<00:01, 18.06it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  80%|███████▉  | 78/98 [00:04<00:01, 18.16it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  81%|████████  | 79/98 [00:04<00:01, 18.12it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  82%|████████▏ | 80/98 [00:04<00:00, 18.13it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  83%|████████▎ | 81/98 [00:04<00:00, 18.17it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  84%|████████▎ | 82/98 [00:04<00:00, 17.51it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  85%|████████▍ | 83/98 [00:04<00:00, 17.54it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  86%|████████▌ | 84/98 [00:04<00:00, 17.62it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  87%|████████▋ | 85/98 [00:04<00:00, 17.70it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  88%|████████▊ | 86/98 [00:04<00:00, 17.76it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  89%|████████▉ | 87/98 [00:04<00:00, 17.85it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  90%|████████▉ | 88/98 [00:04<00:00, 17.94it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  91%|█████████ | 89/98 [00:04<00:00, 18.01it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  92%|█████████▏| 90/98 [00:04<00:00, 18.08it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  93%|█████████▎| 91/98 [00:05<00:00, 18.13it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  94%|█████████▍| 92/98 [00:05<00:00, 18.21it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  95%|█████████▍| 93/98 [00:05<00:00, 17.68it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  96%|█████████▌| 94/98 [00:05<00:00, 17.76it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  97%|█████████▋| 95/98 [00:05<00:00, 17.78it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  98%|█████████▊| 96/98 [00:05<00:00, 17.86it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.642]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 5:  99%|█████████▉| 97/98 [00:05<00:00, 17.91it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.642]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 6:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.637]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   1%|          | 1/98 [00:00<00:05, 17.86it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   2%|▏         | 2/98 [00:00<00:04, 22.33it/s, v_num=crps, train_loss_step=0.647, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   3%|▎         | 3/98 [00:00<00:04, 20.37it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   4%|▍         | 4/98 [00:00<00:05, 18.61it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   5%|▌         | 5/98 [00:00<00:04, 18.78it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   6%|▌         | 6/98 [00:00<00:07, 12.16it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   7%|▋         | 7/98 [00:00<00:07, 12.96it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   8%|▊         | 8/98 [00:00<00:06, 14.04it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:   9%|▉         | 9/98 [00:00<00:06, 14.39it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  10%|█         | 10/98 [00:00<00:05, 15.09it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  11%|█         | 11/98 [00:00<00:05, 15.59it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  12%|█▏        | 12/98 [00:00<00:05, 16.22it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  13%|█▎        | 13/98 [00:00<00:05, 16.79it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  14%|█▍        | 14/98 [00:00<00:04, 17.28it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  15%|█▌        | 15/98 [00:00<00:04, 17.80it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  16%|█▋        | 16/98 [00:00<00:04, 17.96it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  17%|█▋        | 17/98 [00:01<00:05, 15.08it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  18%|█▊        | 18/98 [00:01<00:05, 15.30it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  19%|█▉        | 19/98 [00:01<00:05, 15.53it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  20%|██        | 20/98 [00:01<00:04, 15.73it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  21%|██▏       | 21/98 [00:01<00:04, 16.04it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  22%|██▏       | 22/98 [00:01<00:04, 16.11it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  23%|██▎       | 23/98 [00:01<00:04, 16.42it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  24%|██▍       | 24/98 [00:01<00:04, 16.66it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  26%|██▌       | 25/98 [00:01<00:04, 16.95it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  27%|██▋       | 26/98 [00:01<00:04, 17.22it/s, v_num=crps, train_loss_step=0.657, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  28%|██▊       | 27/98 [00:01<00:04, 17.32it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  29%|██▊       | 28/98 [00:01<00:04, 15.81it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  30%|██▉       | 29/98 [00:01<00:04, 15.93it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  31%|███       | 30/98 [00:01<00:04, 16.18it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  32%|███▏      | 31/98 [00:01<00:04, 16.27it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  33%|███▎      | 32/98 [00:01<00:04, 16.41it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  34%|███▎      | 33/98 [00:01<00:03, 16.52it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  35%|███▍      | 34/98 [00:02<00:03, 16.72it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  36%|███▌      | 35/98 [00:02<00:03, 16.94it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  37%|███▋      | 36/98 [00:02<00:03, 16.99it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  38%|███▊      | 37/98 [00:02<00:03, 17.00it/s, v_num=crps, train_loss_step=0.655, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  39%|███▉      | 38/98 [00:02<00:03, 17.20it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  40%|███▉      | 39/98 [00:02<00:03, 16.11it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  41%|████      | 40/98 [00:02<00:03, 16.31it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  42%|████▏     | 41/98 [00:02<00:03, 16.46it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  43%|████▎     | 42/98 [00:02<00:03, 16.46it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  44%|████▍     | 43/98 [00:02<00:03, 16.65it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  45%|████▍     | 44/98 [00:02<00:03, 16.84it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  46%|████▌     | 45/98 [00:02<00:03, 16.96it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  47%|████▋     | 46/98 [00:02<00:03, 17.10it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  48%|████▊     | 47/98 [00:02<00:02, 17.13it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  49%|████▉     | 48/98 [00:02<00:02, 17.19it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  50%|█████     | 49/98 [00:02<00:02, 17.17it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  51%|█████     | 50/98 [00:03<00:02, 16.25it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  52%|█████▏    | 51/98 [00:03<00:02, 16.40it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  53%|█████▎    | 52/98 [00:03<00:02, 16.45it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  54%|█████▍    | 53/98 [00:03<00:02, 16.55it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  55%|█████▌    | 54/98 [00:03<00:02, 16.53it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  56%|█████▌    | 55/98 [00:03<00:02, 16.58it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  57%|█████▋    | 56/98 [00:03<00:02, 16.71it/s, v_num=crps, train_loss_step=0.654, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  58%|█████▊    | 57/98 [00:03<00:02, 16.83it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  59%|█████▉    | 58/98 [00:03<00:02, 16.86it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  60%|██████    | 59/98 [00:03<00:02, 16.91it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  61%|██████    | 60/98 [00:03<00:02, 17.02it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  62%|██████▏   | 61/98 [00:03<00:02, 16.28it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  63%|██████▎   | 62/98 [00:03<00:02, 16.39it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  64%|██████▍   | 63/98 [00:03<00:02, 16.50it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  65%|██████▌   | 64/98 [00:03<00:02, 16.56it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  66%|██████▋   | 65/98 [00:03<00:01, 16.68it/s, v_num=crps, train_loss_step=0.648, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  67%|██████▋   | 66/98 [00:03<00:01, 16.79it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  68%|██████▊   | 67/98 [00:03<00:01, 16.86it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  69%|██████▉   | 68/98 [00:04<00:01, 16.95it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  70%|███████   | 69/98 [00:04<00:01, 17.06it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  71%|███████▏  | 70/98 [00:04<00:01, 17.17it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  72%|███████▏  | 71/98 [00:04<00:01, 17.26it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  73%|███████▎  | 72/98 [00:04<00:01, 16.66it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  74%|███████▍  | 73/98 [00:04<00:01, 16.75it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  76%|███████▌  | 74/98 [00:04<00:01, 16.78it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  77%|███████▋  | 75/98 [00:04<00:01, 16.86it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  78%|███████▊  | 76/98 [00:04<00:01, 16.94it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  79%|███████▊  | 77/98 [00:04<00:01, 17.03it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  80%|███████▉  | 78/98 [00:04<00:01, 17.12it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  81%|████████  | 79/98 [00:04<00:01, 17.15it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  82%|████████▏ | 80/98 [00:04<00:01, 17.24it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  83%|████████▎ | 81/98 [00:04<00:00, 17.34it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  84%|████████▎ | 82/98 [00:04<00:00, 17.42it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  85%|████████▍ | 83/98 [00:04<00:00, 16.76it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  86%|████████▌ | 84/98 [00:04<00:00, 16.82it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  87%|████████▋ | 85/98 [00:05<00:00, 16.85it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  88%|████████▊ | 86/98 [00:05<00:00, 16.94it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  89%|████████▉ | 87/98 [00:05<00:00, 17.02it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  90%|████████▉ | 88/98 [00:05<00:00, 17.10it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  91%|█████████ | 89/98 [00:05<00:00, 17.12it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  92%|█████████▏| 90/98 [00:05<00:00, 17.18it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  93%|█████████▎| 91/98 [00:05<00:00, 17.20it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  94%|█████████▍| 92/98 [00:05<00:00, 17.28it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  95%|█████████▍| 93/98 [00:05<00:00, 17.35it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  96%|█████████▌| 94/98 [00:05<00:00, 16.85it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  97%|█████████▋| 95/98 [00:05<00:00, 16.92it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  98%|█████████▊| 96/98 [00:05<00:00, 16.91it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.637]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 6:  99%|█████████▉| 97/98 [00:05<00:00, 16.94it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.637]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 7:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.633]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   1%|          | 1/98 [00:00<00:06, 15.65it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   2%|▏         | 2/98 [00:00<00:05, 17.59it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   3%|▎         | 3/98 [00:00<00:04, 20.04it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   4%|▍         | 4/98 [00:00<00:04, 21.68it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   5%|▌         | 5/98 [00:00<00:04, 22.90it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   6%|▌         | 6/98 [00:00<00:03, 23.83it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   7%|▋         | 7/98 [00:00<00:06, 14.37it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   8%|▊         | 8/98 [00:00<00:06, 14.84it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:   9%|▉         | 9/98 [00:00<00:05, 14.84it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  10%|█         | 10/98 [00:00<00:05, 15.08it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  11%|█         | 11/98 [00:00<00:05, 15.48it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  12%|█▏        | 12/98 [00:00<00:05, 16.14it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  13%|█▎        | 13/98 [00:00<00:05, 16.74it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  14%|█▍        | 14/98 [00:00<00:04, 17.28it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  15%|█▌        | 15/98 [00:00<00:04, 17.76it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  16%|█▋        | 16/98 [00:00<00:04, 18.19it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  17%|█▋        | 17/98 [00:01<00:05, 15.47it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  18%|█▊        | 18/98 [00:01<00:05, 15.91it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  19%|█▉        | 19/98 [00:01<00:04, 16.33it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  20%|██        | 20/98 [00:01<00:04, 16.72it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  21%|██▏       | 21/98 [00:01<00:04, 16.78it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  22%|██▏       | 22/98 [00:01<00:04, 17.02it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  23%|██▎       | 23/98 [00:01<00:04, 16.98it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  24%|██▍       | 24/98 [00:01<00:04, 17.17it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  26%|██▌       | 25/98 [00:01<00:04, 17.26it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  27%|██▋       | 26/98 [00:01<00:04, 17.34it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  28%|██▊       | 27/98 [00:01<00:04, 17.59it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  29%|██▊       | 28/98 [00:01<00:04, 16.04it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  30%|██▉       | 29/98 [00:01<00:04, 16.29it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  31%|███       | 30/98 [00:01<00:04, 16.46it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  32%|███▏      | 31/98 [00:01<00:04, 16.53it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  33%|███▎      | 32/98 [00:01<00:03, 16.58it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  34%|███▎      | 33/98 [00:01<00:03, 16.70it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  35%|███▍      | 34/98 [00:02<00:03, 16.93it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  36%|███▌      | 35/98 [00:02<00:03, 17.11it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  37%|███▋      | 36/98 [00:02<00:03, 17.27it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  38%|███▊      | 37/98 [00:02<00:03, 17.47it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  39%|███▉      | 38/98 [00:02<00:03, 16.35it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  40%|███▉      | 39/98 [00:02<00:03, 16.56it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  41%|████      | 40/98 [00:02<00:03, 16.74it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  42%|████▏     | 41/98 [00:02<00:03, 16.78it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  43%|████▎     | 42/98 [00:02<00:03, 16.80it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  44%|████▍     | 43/98 [00:02<00:03, 16.94it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  45%|████▍     | 44/98 [00:02<00:03, 17.11it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  46%|████▌     | 45/98 [00:02<00:03, 17.27it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  47%|████▋     | 46/98 [00:02<00:02, 17.42it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  48%|████▊     | 47/98 [00:02<00:02, 17.57it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  49%|████▉     | 48/98 [00:02<00:02, 17.61it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  50%|█████     | 49/98 [00:02<00:02, 16.61it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  51%|█████     | 50/98 [00:02<00:02, 16.76it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  52%|█████▏    | 51/98 [00:03<00:02, 16.80it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  53%|█████▎    | 52/98 [00:03<00:02, 16.92it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  54%|█████▍    | 53/98 [00:03<00:02, 16.97it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  55%|█████▌    | 54/98 [00:03<00:02, 17.10it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  56%|█████▌    | 55/98 [00:03<00:02, 17.23it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  57%|█████▋    | 56/98 [00:03<00:02, 17.31it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  58%|█████▊    | 57/98 [00:03<00:02, 17.35it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  59%|█████▉    | 58/98 [00:03<00:02, 17.39it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  60%|██████    | 59/98 [00:03<00:02, 17.50it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  61%|██████    | 60/98 [00:03<00:02, 16.69it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  62%|██████▏   | 61/98 [00:03<00:02, 16.76it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  63%|██████▎   | 62/98 [00:03<00:02, 16.81it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  64%|██████▍   | 63/98 [00:03<00:02, 16.94it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  65%|██████▌   | 64/98 [00:03<00:02, 16.97it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  66%|██████▋   | 65/98 [00:03<00:01, 17.01it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  67%|██████▋   | 66/98 [00:03<00:01, 17.12it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  68%|██████▊   | 67/98 [00:03<00:01, 17.16it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  69%|██████▉   | 68/98 [00:03<00:01, 17.27it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  70%|███████   | 69/98 [00:03<00:01, 17.31it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  71%|███████▏  | 70/98 [00:04<00:01, 17.41it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  72%|███████▏  | 71/98 [00:04<00:01, 16.73it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  73%|███████▎  | 72/98 [00:04<00:01, 16.84it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  74%|███████▍  | 73/98 [00:04<00:01, 16.94it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  76%|███████▌  | 74/98 [00:04<00:01, 17.00it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  77%|███████▋  | 75/98 [00:04<00:01, 17.09it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  78%|███████▊  | 76/98 [00:04<00:01, 17.19it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  79%|███████▊  | 77/98 [00:04<00:01, 17.23it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  80%|███████▉  | 78/98 [00:04<00:01, 17.33it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  81%|████████  | 79/98 [00:04<00:01, 17.39it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  82%|████████▏ | 80/98 [00:04<00:01, 17.35it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  83%|████████▎ | 81/98 [00:04<00:00, 17.37it/s, v_num=crps, train_loss_step=0.651, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  84%|████████▎ | 82/98 [00:04<00:00, 16.79it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  85%|████████▍ | 83/98 [00:04<00:00, 16.81it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  86%|████████▌ | 84/98 [00:04<00:00, 16.87it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  87%|████████▋ | 85/98 [00:05<00:00, 16.89it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  88%|████████▊ | 86/98 [00:05<00:00, 16.98it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  89%|████████▉ | 87/98 [00:05<00:00, 17.06it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  90%|████████▉ | 88/98 [00:05<00:00, 17.11it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  91%|█████████ | 89/98 [00:05<00:00, 17.16it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  92%|█████████▏| 90/98 [00:05<00:00, 17.24it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  93%|█████████▎| 91/98 [00:05<00:00, 17.26it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  94%|█████████▍| 92/98 [00:05<00:00, 17.28it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  95%|█████████▍| 93/98 [00:05<00:00, 16.79it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  96%|█████████▌| 94/98 [00:05<00:00, 16.87it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  97%|█████████▋| 95/98 [00:05<00:00, 16.88it/s, v_num=crps, train_loss_step=0.646, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  98%|█████████▊| 96/98 [00:05<00:00, 16.91it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.633]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 7:  99%|█████████▉| 97/98 [00:05<00:00, 16.97it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.633]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 8:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.628]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   1%|          | 1/98 [00:00<00:08, 11.95it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   2%|▏         | 2/98 [00:00<00:05, 16.89it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   3%|▎         | 3/98 [00:00<00:04, 19.99it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   4%|▍         | 4/98 [00:00<00:04, 21.88it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   5%|▌         | 5/98 [00:00<00:04, 21.44it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   6%|▌         | 6/98 [00:00<00:04, 22.22it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   7%|▋         | 7/98 [00:00<00:06, 14.41it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   8%|▊         | 8/98 [00:00<00:05, 15.12it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:   9%|▉         | 9/98 [00:00<00:05, 15.77it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  10%|█         | 10/98 [00:00<00:05, 16.56it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  11%|█         | 11/98 [00:00<00:05, 17.26it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  12%|█▏        | 12/98 [00:00<00:04, 17.38it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  13%|█▎        | 13/98 [00:00<00:04, 17.56it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  14%|█▍        | 14/98 [00:00<00:04, 17.56it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  15%|█▌        | 15/98 [00:00<00:04, 17.49it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  16%|█▋        | 16/98 [00:00<00:04, 17.84it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  17%|█▋        | 17/98 [00:00<00:04, 18.25it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  18%|█▊        | 18/98 [00:01<00:05, 15.73it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  19%|█▉        | 19/98 [00:01<00:04, 16.15it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  20%|██        | 20/98 [00:01<00:04, 16.55it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  21%|██▏       | 21/98 [00:01<00:04, 16.92it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  22%|██▏       | 22/98 [00:01<00:04, 17.22it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  23%|██▎       | 23/98 [00:01<00:04, 17.49it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  24%|██▍       | 24/98 [00:01<00:04, 17.79it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  26%|██▌       | 25/98 [00:01<00:04, 18.09it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  27%|██▋       | 26/98 [00:01<00:03, 18.35it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  28%|██▊       | 27/98 [00:01<00:03, 18.56it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  29%|██▊       | 28/98 [00:01<00:04, 16.58it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  30%|██▉       | 29/98 [00:01<00:04, 16.77it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  31%|███       | 30/98 [00:01<00:04, 16.82it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  32%|███▏      | 31/98 [00:01<00:03, 17.05it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  33%|███▎      | 32/98 [00:01<00:03, 17.29it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  34%|███▎      | 33/98 [00:01<00:03, 17.36it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  35%|███▍      | 34/98 [00:01<00:03, 17.40it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  36%|███▌      | 35/98 [00:02<00:03, 17.48it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  37%|███▋      | 36/98 [00:02<00:03, 17.58it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  38%|███▊      | 37/98 [00:02<00:03, 16.28it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  39%|███▉      | 38/98 [00:02<00:03, 16.43it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  40%|███▉      | 39/98 [00:02<00:03, 16.51it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  41%|████      | 40/98 [00:02<00:03, 16.57it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  42%|████▏     | 41/98 [00:02<00:03, 16.75it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  43%|████▎     | 42/98 [00:02<00:03, 16.92it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  44%|████▍     | 43/98 [00:02<00:03, 17.06it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  45%|████▍     | 44/98 [00:02<00:03, 17.10it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  46%|████▌     | 45/98 [00:02<00:03, 17.16it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  47%|████▋     | 46/98 [00:02<00:03, 17.28it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  48%|████▊     | 47/98 [00:02<00:02, 17.43it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  49%|████▉     | 48/98 [00:02<00:03, 16.53it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  50%|█████     | 49/98 [00:02<00:02, 16.70it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  51%|█████     | 50/98 [00:02<00:02, 16.86it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  52%|█████▏    | 51/98 [00:03<00:02, 16.89it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  53%|█████▎    | 52/98 [00:03<00:02, 16.96it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  54%|█████▍    | 53/98 [00:03<00:02, 17.11it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  55%|█████▌    | 54/98 [00:03<00:02, 17.19it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  56%|█████▌    | 55/98 [00:03<00:02, 17.33it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  57%|█████▋    | 56/98 [00:03<00:02, 17.37it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  58%|█████▊    | 57/98 [00:03<00:02, 17.51it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  59%|█████▉    | 58/98 [00:03<00:02, 16.72it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  60%|██████    | 59/98 [00:03<00:02, 16.85it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  61%|██████    | 60/98 [00:03<00:02, 16.86it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  62%|██████▏   | 61/98 [00:03<00:02, 16.99it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  63%|██████▎   | 62/98 [00:03<00:02, 17.04it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  64%|██████▍   | 63/98 [00:03<00:02, 17.10it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  65%|██████▌   | 64/98 [00:03<00:01, 17.22it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  66%|██████▋   | 65/98 [00:03<00:01, 17.34it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  67%|██████▋   | 66/98 [00:03<00:01, 17.45it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  68%|██████▊   | 67/98 [00:03<00:01, 17.56it/s, v_num=crps, train_loss_step=0.664, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  69%|██████▉   | 68/98 [00:03<00:01, 17.67it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  70%|███████   | 69/98 [00:04<00:01, 17.02it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  71%|███████▏  | 70/98 [00:04<00:01, 17.14it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  72%|███████▏  | 71/98 [00:04<00:01, 17.25it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  73%|███████▎  | 72/98 [00:04<00:01, 17.25it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  74%|███████▍  | 73/98 [00:04<00:01, 17.35it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  76%|███████▌  | 74/98 [00:04<00:01, 17.36it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  77%|███████▋  | 75/98 [00:04<00:01, 17.40it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  78%|███████▊  | 76/98 [00:04<00:01, 17.46it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  79%|███████▊  | 77/98 [00:04<00:01, 17.56it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  80%|███████▉  | 78/98 [00:04<00:01, 17.63it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  81%|████████  | 79/98 [00:04<00:01, 17.71it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  82%|████████▏ | 80/98 [00:04<00:01, 17.07it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  83%|████████▎ | 81/98 [00:04<00:00, 17.10it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  84%|████████▎ | 82/98 [00:04<00:00, 17.19it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  85%|████████▍ | 83/98 [00:04<00:00, 17.22it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  86%|████████▌ | 84/98 [00:04<00:00, 17.22it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  87%|████████▋ | 85/98 [00:04<00:00, 17.30it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  88%|████████▊ | 86/98 [00:04<00:00, 17.31it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  89%|████████▉ | 87/98 [00:05<00:00, 17.38it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  90%|████████▉ | 88/98 [00:05<00:00, 17.47it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  91%|█████████ | 89/98 [00:05<00:00, 17.49it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  92%|█████████▏| 90/98 [00:05<00:00, 17.57it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  93%|█████████▎| 91/98 [00:05<00:00, 17.07it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  94%|█████████▍| 92/98 [00:05<00:00, 17.14it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  95%|█████████▍| 93/98 [00:05<00:00, 17.22it/s, v_num=crps, train_loss_step=0.641, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  96%|█████████▌| 94/98 [00:05<00:00, 17.24it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  97%|█████████▋| 95/98 [00:05<00:00, 17.27it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  98%|█████████▊| 96/98 [00:05<00:00, 17.35it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.628]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 8:  99%|█████████▉| 97/98 [00:05<00:00, 17.42it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.628]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 9:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.650, train_loss_epoch=0.624]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   1%|          | 1/98 [00:00<00:05, 17.84it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   2%|▏         | 2/98 [00:00<00:04, 22.56it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   3%|▎         | 3/98 [00:00<00:03, 24.73it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   4%|▍         | 4/98 [00:00<00:03, 25.27it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   5%|▌         | 5/98 [00:00<00:03, 26.01it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   6%|▌         | 6/98 [00:00<00:06, 15.02it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   7%|▋         | 7/98 [00:00<00:05, 16.23it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   8%|▊         | 8/98 [00:00<00:05, 16.63it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:   9%|▉         | 9/98 [00:00<00:05, 17.53it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  10%|█         | 10/98 [00:00<00:04, 17.78it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  11%|█         | 11/98 [00:00<00:04, 18.45it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  12%|█▏        | 12/98 [00:00<00:04, 18.59it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  13%|█▎        | 13/98 [00:00<00:04, 19.13it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  14%|█▍        | 14/98 [00:00<00:04, 19.53it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  15%|█▌        | 15/98 [00:00<00:04, 20.02it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  16%|█▋        | 16/98 [00:00<00:04, 16.68it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  17%|█▋        | 17/98 [00:01<00:04, 16.99it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  18%|█▊        | 18/98 [00:01<00:04, 17.42it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  19%|█▉        | 19/98 [00:01<00:04, 17.82it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  20%|██        | 20/98 [00:01<00:04, 18.07it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  21%|██▏       | 21/98 [00:01<00:04, 18.07it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  22%|██▏       | 22/98 [00:01<00:04, 18.10it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  23%|██▎       | 23/98 [00:01<00:04, 18.17it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  24%|██▍       | 24/98 [00:01<00:04, 18.45it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  26%|██▌       | 25/98 [00:01<00:03, 18.67it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  27%|██▋       | 26/98 [00:01<00:03, 18.62it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  28%|██▊       | 27/98 [00:01<00:04, 16.72it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  29%|██▊       | 28/98 [00:01<00:04, 16.97it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  30%|██▉       | 29/98 [00:01<00:04, 16.92it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  31%|███       | 30/98 [00:01<00:03, 17.13it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  32%|███▏      | 31/98 [00:01<00:03, 17.36it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  33%|███▎      | 32/98 [00:01<00:03, 17.38it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  34%|███▎      | 33/98 [00:01<00:03, 17.58it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  35%|███▍      | 34/98 [00:01<00:03, 17.65it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  36%|███▌      | 35/98 [00:01<00:03, 17.71it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  37%|███▋      | 36/98 [00:02<00:03, 17.77it/s, v_num=crps, train_loss_step=0.636, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  38%|███▊      | 37/98 [00:02<00:03, 16.49it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  39%|███▉      | 38/98 [00:02<00:03, 16.58it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  40%|███▉      | 39/98 [00:02<00:03, 16.76it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  41%|████      | 40/98 [00:02<00:03, 16.86it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  42%|████▏     | 41/98 [00:02<00:03, 17.01it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  43%|████▎     | 42/98 [00:02<00:03, 17.17it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  44%|████▍     | 43/98 [00:02<00:03, 17.21it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  45%|████▍     | 44/98 [00:02<00:03, 17.25it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  46%|████▌     | 45/98 [00:02<00:03, 17.33it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  47%|████▋     | 46/98 [00:02<00:03, 16.27it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  48%|████▊     | 47/98 [00:02<00:03, 16.32it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  49%|████▉     | 48/98 [00:02<00:03, 16.37it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  50%|█████     | 49/98 [00:02<00:02, 16.51it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  51%|█████     | 50/98 [00:03<00:02, 16.65it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  52%|█████▏    | 51/98 [00:03<00:02, 16.71it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  53%|█████▎    | 52/98 [00:03<00:02, 16.85it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  54%|█████▍    | 53/98 [00:03<00:02, 16.99it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  55%|█████▌    | 54/98 [00:03<00:02, 17.13it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  56%|█████▌    | 55/98 [00:03<00:02, 17.26it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  57%|█████▋    | 56/98 [00:03<00:02, 17.33it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  58%|█████▊    | 57/98 [00:03<00:02, 16.57it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  59%|█████▉    | 58/98 [00:03<00:02, 16.70it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  60%|██████    | 59/98 [00:03<00:02, 16.73it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  61%|██████    | 60/98 [00:03<00:02, 16.84it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  62%|██████▏   | 61/98 [00:03<00:02, 16.96it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  63%|██████▎   | 62/98 [00:03<00:02, 16.94it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  64%|██████▍   | 63/98 [00:03<00:02, 17.03it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  65%|██████▌   | 64/98 [00:03<00:01, 17.15it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  66%|██████▋   | 65/98 [00:03<00:01, 17.22it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  67%|██████▋   | 66/98 [00:03<00:01, 17.33it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  68%|██████▊   | 67/98 [00:04<00:01, 16.68it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  69%|██████▉   | 68/98 [00:04<00:01, 16.79it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  70%|███████   | 69/98 [00:04<00:01, 16.81it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  71%|███████▏  | 70/98 [00:04<00:01, 16.86it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  72%|███████▏  | 71/98 [00:04<00:01, 16.96it/s, v_num=crps, train_loss_step=0.638, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  73%|███████▎  | 72/98 [00:04<00:01, 16.95it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  74%|███████▍  | 73/98 [00:04<00:01, 16.99it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  76%|███████▌  | 74/98 [00:04<00:01, 17.09it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  77%|███████▋  | 75/98 [00:04<00:01, 17.15it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  78%|███████▊  | 76/98 [00:04<00:01, 17.24it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  79%|███████▊  | 77/98 [00:04<00:01, 17.27it/s, v_num=crps, train_loss_step=0.639, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  80%|███████▉  | 78/98 [00:04<00:01, 16.70it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  81%|████████  | 79/98 [00:04<00:01, 16.74it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  82%|████████▏ | 80/98 [00:04<00:01, 16.80it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  83%|████████▎ | 81/98 [00:04<00:01, 16.88it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  84%|████████▎ | 82/98 [00:04<00:00, 16.94it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  85%|████████▍ | 83/98 [00:04<00:00, 16.97it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  86%|████████▌ | 84/98 [00:04<00:00, 17.04it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  87%|████████▋ | 85/98 [00:04<00:00, 17.06it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  88%|████████▊ | 86/98 [00:05<00:00, 17.14it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  89%|████████▉ | 87/98 [00:05<00:00, 17.21it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  90%|████████▉ | 88/98 [00:05<00:00, 17.24it/s, v_num=crps, train_loss_step=0.642, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  91%|█████████ | 89/98 [00:05<00:00, 16.74it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  92%|█████████▏| 90/98 [00:05<00:00, 16.82it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  93%|█████████▎| 91/98 [00:05<00:00, 16.90it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  94%|█████████▍| 92/98 [00:05<00:00, 16.93it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  95%|█████████▍| 93/98 [00:05<00:00, 17.02it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  96%|█████████▌| 94/98 [00:05<00:00, 17.07it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  97%|█████████▋| 95/98 [00:05<00:00, 17.11it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  98%|█████████▊| 96/98 [00:05<00:00, 17.18it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.624]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 9:  99%|█████████▉| 97/98 [00:05<00:00, 17.26it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.624]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 10:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.623]        torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   1%|          | 1/98 [00:00<00:05, 18.32it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   2%|▏         | 2/98 [00:00<00:04, 22.53it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   3%|▎         | 3/98 [00:00<00:04, 21.92it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   4%|▍         | 4/98 [00:00<00:08, 11.49it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   5%|▌         | 5/98 [00:00<00:07, 12.64it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   6%|▌         | 6/98 [00:00<00:07, 13.08it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   7%|▋         | 7/98 [00:00<00:06, 13.97it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   8%|▊         | 8/98 [00:00<00:06, 14.93it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:   9%|▉         | 9/98 [00:00<00:05, 15.79it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  10%|█         | 10/98 [00:00<00:05, 16.57it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  11%|█         | 11/98 [00:00<00:05, 17.24it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  12%|█▏        | 12/98 [00:00<00:04, 17.83it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  13%|█▎        | 13/98 [00:00<00:04, 18.24it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  14%|█▍        | 14/98 [00:00<00:04, 18.77it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  15%|█▌        | 15/98 [00:00<00:05, 15.68it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  16%|█▋        | 16/98 [00:00<00:05, 16.12it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  17%|█▋        | 17/98 [00:01<00:04, 16.60it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  18%|█▊        | 18/98 [00:01<00:04, 16.63it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  19%|█▉        | 19/98 [00:01<00:04, 16.85it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  20%|██        | 20/98 [00:01<00:04, 16.95it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  21%|██▏       | 21/98 [00:01<00:04, 17.10it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  22%|██▏       | 22/98 [00:01<00:04, 17.07it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  23%|██▎       | 23/98 [00:01<00:04, 17.05it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  24%|██▍       | 24/98 [00:01<00:04, 17.06it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  26%|██▌       | 25/98 [00:01<00:04, 17.07it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  27%|██▋       | 26/98 [00:01<00:04, 15.25it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  28%|██▊       | 27/98 [00:01<00:04, 15.54it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  29%|██▊       | 28/98 [00:01<00:04, 15.82it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  30%|██▉       | 29/98 [00:01<00:04, 16.04it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  31%|███       | 30/98 [00:01<00:04, 16.24it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  32%|███▏      | 31/98 [00:01<00:04, 16.47it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  33%|███▎      | 32/98 [00:01<00:03, 16.62it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  34%|███▎      | 33/98 [00:01<00:03, 16.85it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  35%|███▍      | 34/98 [00:01<00:03, 17.06it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  36%|███▌      | 35/98 [00:02<00:03, 17.23it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  37%|███▋      | 36/98 [00:02<00:03, 17.41it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  38%|███▊      | 37/98 [00:02<00:03, 16.20it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  39%|███▉      | 38/98 [00:02<00:03, 16.17it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  40%|███▉      | 39/98 [00:02<00:03, 16.27it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  41%|████      | 40/98 [00:02<00:03, 16.34it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  42%|████▏     | 41/98 [00:02<00:03, 16.51it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  43%|████▎     | 42/98 [00:02<00:03, 16.70it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  44%|████▍     | 43/98 [00:02<00:03, 16.74it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  45%|████▍     | 44/98 [00:02<00:03, 16.89it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  46%|████▌     | 45/98 [00:02<00:03, 17.07it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  47%|████▋     | 46/98 [00:02<00:03, 17.11it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  48%|████▊     | 47/98 [00:02<00:02, 17.16it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  49%|████▉     | 48/98 [00:02<00:03, 16.15it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  50%|█████     | 49/98 [00:03<00:03, 16.30it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  51%|█████     | 50/98 [00:03<00:02, 16.38it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  52%|█████▏    | 51/98 [00:03<00:02, 16.48it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  53%|█████▎    | 52/98 [00:03<00:02, 16.55it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  54%|█████▍    | 53/98 [00:03<00:02, 16.66it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  55%|█████▌    | 54/98 [00:03<00:02, 16.79it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  56%|█████▌    | 55/98 [00:03<00:02, 16.80it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  57%|█████▋    | 56/98 [00:03<00:02, 16.85it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  58%|█████▊    | 57/98 [00:03<00:02, 16.97it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  59%|█████▉    | 58/98 [00:03<00:02, 17.06it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  60%|██████    | 59/98 [00:03<00:02, 16.26it/s, v_num=crps, train_loss_step=0.643, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  61%|██████    | 60/98 [00:03<00:02, 16.39it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  62%|██████▏   | 61/98 [00:03<00:02, 16.50it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  63%|██████▎   | 62/98 [00:03<00:02, 16.53it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  64%|██████▍   | 63/98 [00:03<00:02, 16.65it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  65%|██████▌   | 64/98 [00:03<00:02, 16.77it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  66%|██████▋   | 65/98 [00:03<00:01, 16.88it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  67%|██████▋   | 66/98 [00:03<00:01, 16.99it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  68%|██████▊   | 67/98 [00:03<00:01, 16.99it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  69%|██████▉   | 68/98 [00:03<00:01, 17.10it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  70%|███████   | 69/98 [00:04<00:01, 17.13it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  71%|███████▏  | 70/98 [00:04<00:01, 16.48it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  72%|███████▏  | 71/98 [00:04<00:01, 16.58it/s, v_num=crps, train_loss_step=0.645, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  73%|███████▎  | 72/98 [00:04<00:01, 16.65it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  74%|███████▍  | 73/98 [00:04<00:01, 16.75it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  76%|███████▌  | 74/98 [00:04<00:01, 16.75it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  77%|███████▋  | 75/98 [00:04<00:01, 16.84it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  78%|███████▊  | 76/98 [00:04<00:01, 16.94it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  79%|███████▊  | 77/98 [00:04<00:01, 16.94it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  80%|███████▉  | 78/98 [00:04<00:01, 16.99it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  81%|████████  | 79/98 [00:04<00:01, 17.06it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  82%|████████▏ | 80/98 [00:04<00:01, 17.11it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  83%|████████▎ | 81/98 [00:04<00:01, 16.59it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  84%|████████▎ | 82/98 [00:04<00:00, 16.69it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  85%|████████▍ | 83/98 [00:04<00:00, 16.79it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  86%|████████▌ | 84/98 [00:04<00:00, 16.88it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  87%|████████▋ | 85/98 [00:05<00:00, 16.97it/s, v_num=crps, train_loss_step=0.637, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  88%|████████▊ | 86/98 [00:05<00:00, 17.02it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  89%|████████▉ | 87/98 [00:05<00:00, 17.11it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  90%|████████▉ | 88/98 [00:05<00:00, 17.14it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  91%|█████████ | 89/98 [00:05<00:00, 17.22it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  92%|█████████▏| 90/98 [00:05<00:00, 17.22it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  93%|█████████▎| 91/98 [00:05<00:00, 17.23it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  94%|█████████▍| 92/98 [00:05<00:00, 16.71it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  95%|█████████▍| 93/98 [00:05<00:00, 16.79it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  96%|█████████▌| 94/98 [00:05<00:00, 16.87it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  97%|█████████▋| 95/98 [00:05<00:00, 16.91it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  98%|█████████▊| 96/98 [00:05<00:00, 16.95it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.623]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 10:  99%|█████████▉| 97/98 [00:05<00:00, 16.96it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.623]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 11:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.653, train_loss_epoch=0.620]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   1%|          | 1/98 [00:00<00:05, 18.29it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   2%|▏         | 2/98 [00:00<00:04, 22.90it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   3%|▎         | 3/98 [00:00<00:03, 24.34it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   4%|▍         | 4/98 [00:00<00:04, 22.56it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   5%|▌         | 5/98 [00:00<00:07, 12.88it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   6%|▌         | 6/98 [00:00<00:06, 13.54it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   7%|▋         | 7/98 [00:00<00:06, 14.05it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   8%|▊         | 8/98 [00:00<00:06, 14.50it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:   9%|▉         | 9/98 [00:00<00:05, 15.29it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  10%|█         | 10/98 [00:00<00:05, 15.64it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  11%|█         | 11/98 [00:00<00:05, 16.34it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  12%|█▏        | 12/98 [00:00<00:05, 16.90it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  13%|█▎        | 13/98 [00:00<00:04, 17.15it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  14%|█▍        | 14/98 [00:00<00:04, 17.23it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  15%|█▌        | 15/98 [00:00<00:04, 17.63it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  16%|█▋        | 16/98 [00:01<00:05, 14.82it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  17%|█▋        | 17/98 [00:01<00:05, 15.31it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  18%|█▊        | 18/98 [00:01<00:05, 15.69it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  19%|█▉        | 19/98 [00:01<00:04, 15.87it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  20%|██        | 20/98 [00:01<00:04, 16.26it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  21%|██▏       | 21/98 [00:01<00:04, 16.63it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  22%|██▏       | 22/98 [00:01<00:04, 16.95it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  23%|██▎       | 23/98 [00:01<00:04, 17.22it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  24%|██▍       | 24/98 [00:01<00:04, 17.52it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  26%|██▌       | 25/98 [00:01<00:04, 17.67it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  27%|██▋       | 26/98 [00:01<00:03, 18.00it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  28%|██▊       | 27/98 [00:01<00:04, 16.19it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  29%|██▊       | 28/98 [00:01<00:04, 16.49it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  30%|██▉       | 29/98 [00:01<00:04, 16.75it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  31%|███       | 30/98 [00:01<00:03, 17.01it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  32%|███▏      | 31/98 [00:01<00:03, 17.27it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  33%|███▎      | 32/98 [00:01<00:03, 17.45it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  34%|███▎      | 33/98 [00:01<00:03, 17.65it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  35%|███▍      | 34/98 [00:01<00:03, 17.86it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  36%|███▌      | 35/98 [00:01<00:03, 18.09it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  37%|███▋      | 36/98 [00:01<00:03, 18.30it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  38%|███▊      | 37/98 [00:01<00:03, 18.51it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  39%|███▉      | 38/98 [00:02<00:03, 17.25it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  40%|███▉      | 39/98 [00:02<00:03, 17.43it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  41%|████      | 40/98 [00:02<00:03, 17.59it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  42%|████▏     | 41/98 [00:02<00:03, 17.64it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  43%|████▎     | 42/98 [00:02<00:03, 17.70it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  44%|████▍     | 43/98 [00:02<00:03, 17.86it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  45%|████▍     | 44/98 [00:02<00:02, 18.01it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  46%|████▌     | 45/98 [00:02<00:02, 18.10it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  47%|████▋     | 46/98 [00:02<00:02, 18.28it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  48%|████▊     | 47/98 [00:02<00:02, 18.45it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  49%|████▉     | 48/98 [00:02<00:02, 18.48it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  50%|█████     | 49/98 [00:02<00:02, 17.46it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  51%|█████     | 50/98 [00:02<00:02, 17.61it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  52%|█████▏    | 51/98 [00:02<00:02, 17.75it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  53%|█████▎    | 52/98 [00:02<00:02, 17.89it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  54%|█████▍    | 53/98 [00:02<00:02, 17.97it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  55%|█████▌    | 54/98 [00:02<00:02, 18.10it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  56%|█████▌    | 55/98 [00:03<00:02, 18.22it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  57%|█████▋    | 56/98 [00:03<00:02, 18.29it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  58%|█████▊    | 57/98 [00:03<00:02, 18.40it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  59%|█████▉    | 58/98 [00:03<00:02, 18.53it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  60%|██████    | 59/98 [00:03<00:02, 18.59it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  61%|██████    | 60/98 [00:03<00:02, 17.69it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  62%|██████▏   | 61/98 [00:03<00:02, 17.71it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  63%|██████▎   | 62/98 [00:03<00:02, 17.85it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  64%|██████▍   | 63/98 [00:03<00:01, 17.93it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  65%|██████▌   | 64/98 [00:03<00:01, 18.06it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  66%|██████▋   | 65/98 [00:03<00:01, 18.17it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  67%|██████▋   | 66/98 [00:03<00:01, 18.27it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  68%|██████▊   | 67/98 [00:03<00:01, 18.38it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  69%|██████▉   | 68/98 [00:03<00:01, 18.48it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  70%|███████   | 69/98 [00:03<00:01, 18.45it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  71%|███████▏  | 70/98 [00:03<00:01, 18.56it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  72%|███████▏  | 71/98 [00:03<00:01, 17.83it/s, v_num=crps, train_loss_step=0.632, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  73%|███████▎  | 72/98 [00:04<00:01, 17.93it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  74%|███████▍  | 73/98 [00:04<00:01, 17.90it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  76%|███████▌  | 74/98 [00:04<00:01, 17.98it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  77%|███████▋  | 75/98 [00:04<00:01, 18.08it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  78%|███████▊  | 76/98 [00:04<00:01, 18.10it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  79%|███████▊  | 77/98 [00:04<00:01, 18.17it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  80%|███████▉  | 78/98 [00:04<00:01, 18.26it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  81%|████████  | 79/98 [00:04<00:01, 18.26it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  82%|████████▏ | 80/98 [00:04<00:00, 18.32it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  83%|████████▎ | 81/98 [00:04<00:00, 18.40it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  84%|████████▎ | 82/98 [00:04<00:00, 17.77it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  85%|████████▍ | 83/98 [00:04<00:00, 17.79it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  86%|████████▌ | 84/98 [00:04<00:00, 17.88it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  87%|████████▋ | 85/98 [00:04<00:00, 17.93it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  88%|████████▊ | 86/98 [00:04<00:00, 18.00it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  89%|████████▉ | 87/98 [00:04<00:00, 18.08it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  90%|████████▉ | 88/98 [00:04<00:00, 18.10it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  91%|█████████ | 89/98 [00:04<00:00, 18.17it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  92%|█████████▏| 90/98 [00:04<00:00, 18.24it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  93%|█████████▎| 91/98 [00:04<00:00, 18.25it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  94%|█████████▍| 92/98 [00:05<00:00, 18.30it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  95%|█████████▍| 93/98 [00:05<00:00, 17.70it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  96%|█████████▌| 94/98 [00:05<00:00, 17.70it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  97%|█████████▋| 95/98 [00:05<00:00, 17.70it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  98%|█████████▊| 96/98 [00:05<00:00, 17.68it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.620]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 11:  99%|█████████▉| 97/98 [00:05<00:00, 17.72it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.620]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 12:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.615]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   1%|          | 1/98 [00:00<00:08, 10.85it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   2%|▏         | 2/98 [00:00<00:06, 15.83it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   3%|▎         | 3/98 [00:00<00:05, 18.57it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   4%|▍         | 4/98 [00:00<00:05, 18.67it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   5%|▌         | 5/98 [00:00<00:04, 18.71it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   6%|▌         | 6/98 [00:00<00:07, 12.59it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   7%|▋         | 7/98 [00:00<00:06, 13.61it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   8%|▊         | 8/98 [00:00<00:06, 13.97it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:   9%|▉         | 9/98 [00:00<00:06, 14.81it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  10%|█         | 10/98 [00:00<00:05, 15.58it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  11%|█         | 11/98 [00:00<00:05, 15.88it/s, v_num=crps, train_loss_step=0.634, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  12%|█▏        | 12/98 [00:00<00:05, 16.52it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  13%|█▎        | 13/98 [00:00<00:04, 17.10it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  14%|█▍        | 14/98 [00:00<00:04, 17.59it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  15%|█▌        | 15/98 [00:00<00:04, 18.10it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  16%|█▋        | 16/98 [00:00<00:04, 18.48it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  17%|█▋        | 17/98 [00:01<00:05, 15.58it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  18%|█▊        | 18/98 [00:01<00:05, 16.00it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  19%|█▉        | 19/98 [00:01<00:04, 16.20it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  20%|██        | 20/98 [00:01<00:04, 16.58it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  21%|██▏       | 21/98 [00:01<00:04, 16.52it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  22%|██▏       | 22/98 [00:01<00:04, 16.59it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  23%|██▎       | 23/98 [00:01<00:04, 16.76it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  24%|██▍       | 24/98 [00:01<00:04, 16.88it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  26%|██▌       | 25/98 [00:01<00:04, 17.14it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  27%|██▋       | 26/98 [00:01<00:04, 17.40it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  28%|██▊       | 27/98 [00:01<00:04, 17.58it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  29%|██▊       | 28/98 [00:01<00:04, 15.93it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  30%|██▉       | 29/98 [00:01<00:04, 16.05it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  31%|███       | 30/98 [00:01<00:04, 16.08it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  32%|███▏      | 31/98 [00:01<00:04, 16.19it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  33%|███▎      | 32/98 [00:01<00:04, 16.41it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  34%|███▎      | 33/98 [00:02<00:03, 16.49it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  35%|███▍      | 34/98 [00:02<00:03, 16.73it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  36%|███▌      | 35/98 [00:02<00:03, 16.94it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  37%|███▋      | 36/98 [00:02<00:03, 17.03it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  38%|███▊      | 37/98 [00:02<00:03, 17.20it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  39%|███▉      | 38/98 [00:02<00:03, 17.18it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  40%|███▉      | 39/98 [00:02<00:03, 16.01it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  41%|████      | 40/98 [00:02<00:03, 16.20it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  42%|████▏     | 41/98 [00:02<00:03, 16.38it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  43%|████▎     | 42/98 [00:02<00:03, 16.55it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  44%|████▍     | 43/98 [00:02<00:03, 16.73it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  45%|████▍     | 44/98 [00:02<00:03, 16.91it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  46%|████▌     | 45/98 [00:02<00:03, 17.07it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  47%|████▋     | 46/98 [00:02<00:03, 17.19it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  48%|████▊     | 47/98 [00:02<00:02, 17.27it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  49%|████▉     | 48/98 [00:02<00:02, 17.41it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  50%|█████     | 49/98 [00:02<00:02, 17.56it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  51%|█████     | 50/98 [00:03<00:02, 16.63it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  52%|█████▏    | 51/98 [00:03<00:02, 16.69it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  53%|█████▎    | 52/98 [00:03<00:02, 16.84it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  54%|█████▍    | 53/98 [00:03<00:02, 16.98it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  55%|█████▌    | 54/98 [00:03<00:02, 17.11it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  56%|█████▌    | 55/98 [00:03<00:02, 17.24it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  57%|█████▋    | 56/98 [00:03<00:02, 17.36it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  58%|█████▊    | 57/98 [00:03<00:02, 17.36it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  59%|█████▉    | 58/98 [00:03<00:02, 17.38it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  60%|██████    | 59/98 [00:03<00:02, 17.42it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  61%|██████    | 60/98 [00:03<00:02, 17.51it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  62%|██████▏   | 61/98 [00:03<00:02, 16.78it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  63%|██████▎   | 62/98 [00:03<00:02, 16.89it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  64%|██████▍   | 63/98 [00:03<00:02, 16.94it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  65%|██████▌   | 64/98 [00:03<00:01, 17.04it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  66%|██████▋   | 65/98 [00:03<00:01, 17.15it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  67%|██████▋   | 66/98 [00:03<00:01, 17.14it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  68%|██████▊   | 67/98 [00:03<00:01, 17.22it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  69%|██████▉   | 68/98 [00:03<00:01, 17.26it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  70%|███████   | 69/98 [00:04<00:01, 17.24it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  71%|███████▏  | 70/98 [00:04<00:01, 17.29it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  72%|███████▏  | 71/98 [00:04<00:01, 17.37it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  73%|███████▎  | 72/98 [00:04<00:01, 16.67it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  74%|███████▍  | 73/98 [00:04<00:01, 16.75it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  76%|███████▌  | 74/98 [00:04<00:01, 16.85it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  77%|███████▋  | 75/98 [00:04<00:01, 16.96it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  78%|███████▊  | 76/98 [00:04<00:01, 17.07it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  79%|███████▊  | 77/98 [00:04<00:01, 17.17it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  80%|███████▉  | 78/98 [00:04<00:01, 17.27it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  81%|████████  | 79/98 [00:04<00:01, 17.26it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  82%|████████▏ | 80/98 [00:04<00:01, 17.36it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  83%|████████▎ | 81/98 [00:04<00:00, 17.44it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  84%|████████▎ | 82/98 [00:04<00:00, 17.48it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  85%|████████▍ | 83/98 [00:04<00:00, 16.86it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  86%|████████▌ | 84/98 [00:04<00:00, 16.93it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  87%|████████▋ | 85/98 [00:04<00:00, 17.01it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  88%|████████▊ | 86/98 [00:05<00:00, 17.10it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  89%|████████▉ | 87/98 [00:05<00:00, 17.19it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  90%|████████▉ | 88/98 [00:05<00:00, 17.24it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  91%|█████████ | 89/98 [00:05<00:00, 17.29it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  92%|█████████▏| 90/98 [00:05<00:00, 17.37it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  93%|█████████▎| 91/98 [00:05<00:00, 17.45it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  94%|█████████▍| 92/98 [00:05<00:00, 17.46it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  95%|█████████▍| 93/98 [00:05<00:00, 17.54it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  96%|█████████▌| 94/98 [00:05<00:00, 17.06it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  97%|█████████▋| 95/98 [00:05<00:00, 17.15it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  98%|█████████▊| 96/98 [00:05<00:00, 17.22it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.615]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 12:  99%|█████████▉| 97/98 [00:05<00:00, 17.24it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.615]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 13:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.612]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   1%|          | 1/98 [00:00<00:05, 18.28it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   2%|▏         | 2/98 [00:00<00:04, 23.12it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   3%|▎         | 3/98 [00:00<00:03, 24.14it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   4%|▍         | 4/98 [00:00<00:03, 25.61it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   5%|▌         | 5/98 [00:00<00:03, 23.27it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   6%|▌         | 6/98 [00:00<00:03, 24.34it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   7%|▋         | 7/98 [00:00<00:06, 15.11it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   8%|▊         | 8/98 [00:00<00:05, 15.59it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:   9%|▉         | 9/98 [00:00<00:05, 15.98it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  10%|█         | 10/98 [00:00<00:05, 16.10it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  11%|█         | 11/98 [00:00<00:05, 16.59it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  12%|█▏        | 12/98 [00:00<00:04, 17.21it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  13%|█▎        | 13/98 [00:00<00:04, 17.78it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  14%|█▍        | 14/98 [00:00<00:04, 18.09it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  15%|█▌        | 15/98 [00:00<00:04, 18.58it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  16%|█▋        | 16/98 [00:00<00:04, 19.04it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  17%|█▋        | 17/98 [00:01<00:04, 16.24it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  18%|█▊        | 18/98 [00:01<00:04, 16.70it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  19%|█▉        | 19/98 [00:01<00:04, 17.14it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  20%|██        | 20/98 [00:01<00:04, 17.54it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  21%|██▏       | 21/98 [00:01<00:04, 17.57it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  22%|██▏       | 22/98 [00:01<00:04, 17.47it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  23%|██▎       | 23/98 [00:01<00:04, 17.61it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  24%|██▍       | 24/98 [00:01<00:04, 17.94it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  26%|██▌       | 25/98 [00:01<00:04, 18.23it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  27%|██▋       | 26/98 [00:01<00:03, 18.34it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  28%|██▊       | 27/98 [00:01<00:03, 18.45it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  29%|██▊       | 28/98 [00:01<00:04, 16.72it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  30%|██▉       | 29/98 [00:01<00:04, 17.00it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  31%|███       | 30/98 [00:01<00:03, 17.27it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  32%|███▏      | 31/98 [00:01<00:03, 17.53it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  33%|███▎      | 32/98 [00:01<00:03, 17.78it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  34%|███▎      | 33/98 [00:01<00:03, 17.86it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  35%|███▍      | 34/98 [00:01<00:03, 18.08it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  36%|███▌      | 35/98 [00:01<00:03, 18.27it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  37%|███▋      | 36/98 [00:01<00:03, 18.43it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  38%|███▊      | 37/98 [00:02<00:03, 18.46it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  39%|███▉      | 38/98 [00:02<00:03, 17.15it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  40%|███▉      | 39/98 [00:02<00:03, 17.22it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  41%|████      | 40/98 [00:02<00:03, 17.42it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  42%|████▏     | 41/98 [00:02<00:03, 17.58it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  43%|████▎     | 42/98 [00:02<00:03, 17.60it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  44%|████▍     | 43/98 [00:02<00:03, 17.55it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  45%|████▍     | 44/98 [00:02<00:03, 17.68it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  46%|████▌     | 45/98 [00:02<00:02, 17.71it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  47%|████▋     | 46/98 [00:02<00:02, 17.65it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  48%|████▊     | 47/98 [00:02<00:02, 17.66it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  49%|████▉     | 48/98 [00:02<00:02, 17.82it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  50%|█████     | 49/98 [00:02<00:02, 16.83it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  51%|█████     | 50/98 [00:02<00:02, 16.81it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  52%|█████▏    | 51/98 [00:03<00:02, 16.92it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  53%|█████▎    | 52/98 [00:03<00:02, 17.03it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  54%|█████▍    | 53/98 [00:03<00:02, 17.17it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  55%|█████▌    | 54/98 [00:03<00:02, 17.19it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  56%|█████▌    | 55/98 [00:03<00:02, 17.32it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  57%|█████▋    | 56/98 [00:03<00:02, 17.45it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  58%|█████▊    | 57/98 [00:03<00:02, 17.57it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  59%|█████▉    | 58/98 [00:03<00:02, 17.68it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  60%|██████    | 59/98 [00:03<00:02, 17.78it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  61%|██████    | 60/98 [00:03<00:02, 16.96it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  62%|██████▏   | 61/98 [00:03<00:02, 17.08it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  63%|██████▎   | 62/98 [00:03<00:02, 17.21it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  64%|██████▍   | 63/98 [00:03<00:02, 17.29it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  65%|██████▌   | 64/98 [00:03<00:01, 17.34it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  66%|██████▋   | 65/98 [00:03<00:01, 17.46it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  67%|██████▋   | 66/98 [00:03<00:01, 17.57it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  68%|██████▊   | 67/98 [00:03<00:01, 17.70it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  69%|██████▉   | 68/98 [00:03<00:01, 17.81it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  70%|███████   | 69/98 [00:03<00:01, 17.78it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  71%|███████▏  | 70/98 [00:03<00:01, 17.88it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  72%|███████▏  | 71/98 [00:04<00:01, 17.20it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  73%|███████▎  | 72/98 [00:04<00:01, 17.20it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  74%|███████▍  | 73/98 [00:04<00:01, 17.26it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  76%|███████▌  | 74/98 [00:04<00:01, 17.31it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  77%|███████▋  | 75/98 [00:04<00:01, 17.40it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  78%|███████▊  | 76/98 [00:04<00:01, 17.49it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  79%|███████▊  | 77/98 [00:04<00:01, 17.55it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  80%|███████▉  | 78/98 [00:04<00:01, 17.56it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  81%|████████  | 79/98 [00:04<00:01, 17.59it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  82%|████████▏ | 80/98 [00:04<00:01, 17.60it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  83%|████████▎ | 81/98 [00:04<00:00, 17.67it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  84%|████████▎ | 82/98 [00:04<00:00, 17.11it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  85%|████████▍ | 83/98 [00:04<00:00, 17.10it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  86%|████████▌ | 84/98 [00:04<00:00, 17.17it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  87%|████████▋ | 85/98 [00:04<00:00, 17.21it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  88%|████████▊ | 86/98 [00:04<00:00, 17.24it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  89%|████████▉ | 87/98 [00:05<00:00, 17.33it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  90%|████████▉ | 88/98 [00:05<00:00, 17.42it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  91%|█████████ | 89/98 [00:05<00:00, 17.49it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  92%|█████████▏| 90/98 [00:05<00:00, 17.56it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  93%|█████████▎| 91/98 [00:05<00:00, 17.64it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  94%|█████████▍| 92/98 [00:05<00:00, 17.72it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  95%|█████████▍| 93/98 [00:05<00:00, 17.21it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  96%|█████████▌| 94/98 [00:05<00:00, 17.25it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  97%|█████████▋| 95/98 [00:05<00:00, 17.28it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  98%|█████████▊| 96/98 [00:05<00:00, 17.27it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.612]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 13:  99%|█████████▉| 97/98 [00:05<00:00, 17.29it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.612]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 14:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.579, train_loss_epoch=0.611]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   1%|          | 1/98 [00:00<00:06, 14.42it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   2%|▏         | 2/98 [00:00<00:05, 16.89it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   3%|▎         | 3/98 [00:00<00:05, 16.60it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   4%|▍         | 4/98 [00:00<00:05, 18.19it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   5%|▌         | 5/98 [00:00<00:04, 19.76it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   6%|▌         | 6/98 [00:00<00:04, 20.90it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   7%|▋         | 7/98 [00:00<00:06, 13.93it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   8%|▊         | 8/98 [00:00<00:06, 14.76it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:   9%|▉         | 9/98 [00:00<00:05, 15.60it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  10%|█         | 10/98 [00:00<00:05, 15.90it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  11%|█         | 11/98 [00:00<00:05, 16.38it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  12%|█▏        | 12/98 [00:00<00:05, 16.84it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  13%|█▎        | 13/98 [00:00<00:04, 17.41it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  14%|█▍        | 14/98 [00:00<00:04, 17.89it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  15%|█▌        | 15/98 [00:00<00:04, 18.39it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  16%|█▋        | 16/98 [00:00<00:04, 18.87it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  17%|█▋        | 17/98 [00:00<00:04, 19.21it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  18%|█▊        | 18/98 [00:01<00:04, 16.48it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  19%|█▉        | 19/98 [00:01<00:04, 16.83it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  20%|██        | 20/98 [00:01<00:04, 16.93it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  21%|██▏       | 21/98 [00:01<00:04, 17.27it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  22%|██▏       | 22/98 [00:01<00:04, 17.38it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  23%|██▎       | 23/98 [00:01<00:04, 17.71it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  24%|██▍       | 24/98 [00:01<00:04, 17.99it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  26%|██▌       | 25/98 [00:01<00:04, 18.04it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  27%|██▋       | 26/98 [00:01<00:03, 18.32it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  28%|██▊       | 27/98 [00:01<00:03, 18.58it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  29%|██▊       | 28/98 [00:01<00:04, 16.66it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  30%|██▉       | 29/98 [00:01<00:04, 16.88it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  31%|███       | 30/98 [00:01<00:03, 17.11it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  32%|███▏      | 31/98 [00:01<00:03, 17.24it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  33%|███▎      | 32/98 [00:01<00:03, 17.34it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  34%|███▎      | 33/98 [00:01<00:03, 17.57it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  35%|███▍      | 34/98 [00:01<00:03, 17.78it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  36%|███▌      | 35/98 [00:01<00:03, 17.92it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  37%|███▋      | 36/98 [00:01<00:03, 18.12it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  38%|███▊      | 37/98 [00:02<00:03, 16.83it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  39%|███▉      | 38/98 [00:02<00:03, 17.04it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  40%|███▉      | 39/98 [00:02<00:03, 17.22it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  41%|████      | 40/98 [00:02<00:03, 17.17it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  42%|████▏     | 41/98 [00:02<00:03, 17.32it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  43%|████▎     | 42/98 [00:02<00:03, 17.40it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  44%|████▍     | 43/98 [00:02<00:03, 17.56it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  45%|████▍     | 44/98 [00:02<00:03, 17.65it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  46%|████▌     | 45/98 [00:02<00:02, 17.82it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  47%|████▋     | 46/98 [00:02<00:02, 17.87it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  48%|████▊     | 47/98 [00:02<00:02, 17.96it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  49%|████▉     | 48/98 [00:02<00:02, 17.01it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  50%|█████     | 49/98 [00:02<00:02, 17.16it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  51%|█████     | 50/98 [00:02<00:02, 17.30it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  52%|█████▏    | 51/98 [00:02<00:02, 17.45it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  53%|█████▎    | 52/98 [00:02<00:02, 17.58it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  54%|█████▍    | 53/98 [00:02<00:02, 17.69it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  55%|█████▌    | 54/98 [00:03<00:02, 17.82it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  56%|█████▌    | 55/98 [00:03<00:02, 17.93it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  57%|█████▋    | 56/98 [00:03<00:02, 17.96it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  58%|█████▊    | 57/98 [00:03<00:02, 17.98it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  59%|█████▉    | 58/98 [00:03<00:02, 17.17it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  60%|██████    | 59/98 [00:03<00:02, 17.29it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  61%|██████    | 60/98 [00:03<00:02, 17.28it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  62%|██████▏   | 61/98 [00:03<00:02, 17.41it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  63%|██████▎   | 62/98 [00:03<00:02, 17.54it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  64%|██████▍   | 63/98 [00:03<00:01, 17.66it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  65%|██████▌   | 64/98 [00:03<00:01, 17.65it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  66%|██████▋   | 65/98 [00:03<00:01, 17.76it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  67%|██████▋   | 66/98 [00:03<00:01, 17.76it/s, v_num=crps, train_loss_step=0.640, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  68%|██████▊   | 67/98 [00:03<00:01, 17.85it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  69%|██████▉   | 68/98 [00:03<00:01, 17.86it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  70%|███████   | 69/98 [00:04<00:01, 17.17it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  71%|███████▏  | 70/98 [00:04<00:01, 17.28it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  72%|███████▏  | 71/98 [00:04<00:01, 17.38it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  73%|███████▎  | 72/98 [00:04<00:01, 17.49it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  74%|███████▍  | 73/98 [00:04<00:01, 17.60it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  76%|███████▌  | 74/98 [00:04<00:01, 17.70it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  77%|███████▋  | 75/98 [00:04<00:01, 17.80it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  78%|███████▊  | 76/98 [00:04<00:01, 17.90it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  79%|███████▊  | 77/98 [00:04<00:01, 18.00it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  80%|███████▉  | 78/98 [00:04<00:01, 18.01it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  81%|████████  | 79/98 [00:04<00:01, 18.04it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  82%|████████▏ | 80/98 [00:04<00:01, 17.32it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  83%|████████▎ | 81/98 [00:04<00:00, 17.41it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  84%|████████▎ | 82/98 [00:04<00:00, 17.50it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  85%|████████▍ | 83/98 [00:04<00:00, 17.59it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  86%|████████▌ | 84/98 [00:04<00:00, 17.67it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  87%|████████▋ | 85/98 [00:04<00:00, 17.76it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  88%|████████▊ | 86/98 [00:04<00:00, 17.85it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  89%|████████▉ | 87/98 [00:04<00:00, 17.93it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  90%|████████▉ | 88/98 [00:04<00:00, 18.01it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  91%|█████████ | 89/98 [00:04<00:00, 18.09it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  92%|█████████▏| 90/98 [00:04<00:00, 18.17it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  93%|█████████▎| 91/98 [00:05<00:00, 17.63it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  94%|█████████▍| 92/98 [00:05<00:00, 17.62it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  95%|█████████▍| 93/98 [00:05<00:00, 17.70it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  96%|█████████▌| 94/98 [00:05<00:00, 17.78it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  97%|█████████▋| 95/98 [00:05<00:00, 17.87it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  98%|█████████▊| 96/98 [00:05<00:00, 17.95it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.611]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 14:  99%|█████████▉| 97/98 [00:05<00:00, 17.93it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.611]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 15:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.644, train_loss_epoch=0.610]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   1%|          | 1/98 [00:00<00:05, 17.42it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   2%|▏         | 2/98 [00:00<00:05, 19.05it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   3%|▎         | 3/98 [00:00<00:04, 19.72it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   4%|▍         | 4/98 [00:00<00:04, 21.58it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   5%|▌         | 5/98 [00:00<00:04, 22.89it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   6%|▌         | 6/98 [00:00<00:06, 14.06it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   7%|▋         | 7/98 [00:00<00:06, 14.77it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   8%|▊         | 8/98 [00:00<00:05, 15.85it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:   9%|▉         | 9/98 [00:00<00:05, 16.79it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  10%|█         | 10/98 [00:00<00:05, 17.28it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  11%|█         | 11/98 [00:00<00:04, 17.47it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  12%|█▏        | 12/98 [00:00<00:04, 18.17it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  13%|█▎        | 13/98 [00:00<00:04, 18.68it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  14%|█▍        | 14/98 [00:00<00:04, 19.24it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  15%|█▌        | 15/98 [00:00<00:04, 19.74it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  16%|█▋        | 16/98 [00:00<00:04, 16.49it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  17%|█▋        | 17/98 [00:01<00:04, 16.94it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  18%|█▊        | 18/98 [00:01<00:04, 17.34it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  19%|█▉        | 19/98 [00:01<00:04, 17.70it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  20%|██        | 20/98 [00:01<00:04, 18.06it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  21%|██▏       | 21/98 [00:01<00:04, 18.35it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  22%|██▏       | 22/98 [00:01<00:04, 18.65it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  23%|██▎       | 23/98 [00:01<00:03, 18.80it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  24%|██▍       | 24/98 [00:01<00:03, 18.99it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  26%|██▌       | 25/98 [00:01<00:03, 19.31it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  27%|██▋       | 26/98 [00:01<00:03, 19.61it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  28%|██▊       | 27/98 [00:01<00:04, 17.59it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  29%|██▊       | 28/98 [00:01<00:03, 17.78it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  30%|██▉       | 29/98 [00:01<00:03, 18.04it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  31%|███       | 30/98 [00:01<00:03, 18.32it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  32%|███▏      | 31/98 [00:01<00:03, 18.57it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  33%|███▎      | 32/98 [00:01<00:03, 18.80it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  34%|███▎      | 33/98 [00:01<00:03, 18.99it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  35%|███▍      | 34/98 [00:01<00:03, 19.21it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  36%|███▌      | 35/98 [00:01<00:03, 19.28it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  37%|███▋      | 36/98 [00:01<00:03, 19.32it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  38%|███▊      | 37/98 [00:02<00:03, 17.86it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  39%|███▉      | 38/98 [00:02<00:03, 18.04it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  40%|███▉      | 39/98 [00:02<00:03, 18.19it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  41%|████      | 40/98 [00:02<00:03, 18.29it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  42%|████▏     | 41/98 [00:02<00:03, 18.46it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  43%|████▎     | 42/98 [00:02<00:03, 18.58it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  44%|████▍     | 43/98 [00:02<00:02, 18.75it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  45%|████▍     | 44/98 [00:02<00:02, 18.92it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  46%|████▌     | 45/98 [00:02<00:02, 18.99it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  47%|████▋     | 46/98 [00:02<00:02, 17.76it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  48%|████▊     | 47/98 [00:02<00:02, 17.92it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  49%|████▉     | 48/98 [00:02<00:02, 18.08it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  50%|█████     | 49/98 [00:02<00:02, 18.22it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  51%|█████     | 50/98 [00:02<00:02, 18.25it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  52%|█████▏    | 51/98 [00:02<00:02, 18.38it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  53%|█████▎    | 52/98 [00:02<00:02, 18.52it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  54%|█████▍    | 53/98 [00:02<00:02, 18.65it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  55%|█████▌    | 54/98 [00:02<00:02, 18.76it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  56%|█████▌    | 55/98 [00:02<00:02, 18.80it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  57%|█████▋    | 56/98 [00:02<00:02, 18.92it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  58%|█████▊    | 57/98 [00:03<00:02, 18.02it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  59%|█████▉    | 58/98 [00:03<00:02, 18.15it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  60%|██████    | 59/98 [00:03<00:02, 18.28it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  61%|██████    | 60/98 [00:03<00:02, 18.31it/s, v_num=crps, train_loss_step=0.630, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  62%|██████▏   | 61/98 [00:03<00:02, 18.36it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  63%|██████▎   | 62/98 [00:03<00:01, 18.42it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  64%|██████▍   | 63/98 [00:03<00:01, 18.53it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  65%|██████▌   | 64/98 [00:03<00:01, 18.65it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  66%|██████▋   | 65/98 [00:03<00:01, 18.76it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  67%|██████▋   | 66/98 [00:03<00:01, 18.85it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  68%|██████▊   | 67/98 [00:03<00:01, 18.06it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  69%|██████▉   | 68/98 [00:03<00:01, 18.15it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  70%|███████   | 69/98 [00:03<00:01, 18.27it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  71%|███████▏  | 70/98 [00:03<00:01, 18.38it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  72%|███████▏  | 71/98 [00:03<00:01, 18.47it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  73%|███████▎  | 72/98 [00:03<00:01, 18.57it/s, v_num=crps, train_loss_step=0.627, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  74%|███████▍  | 73/98 [00:03<00:01, 18.55it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  76%|███████▌  | 74/98 [00:03<00:01, 18.64it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  77%|███████▋  | 75/98 [00:04<00:01, 18.72it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  78%|███████▊  | 76/98 [00:04<00:01, 18.80it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  79%|███████▊  | 77/98 [00:04<00:01, 18.82it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  80%|███████▉  | 78/98 [00:04<00:01, 18.15it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  81%|████████  | 79/98 [00:04<00:01, 18.24it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  82%|████████▏ | 80/98 [00:04<00:00, 18.30it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  83%|████████▎ | 81/98 [00:04<00:00, 18.33it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  84%|████████▎ | 82/98 [00:04<00:00, 18.35it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  85%|████████▍ | 83/98 [00:04<00:00, 18.36it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  86%|████████▌ | 84/98 [00:04<00:00, 18.35it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  87%|████████▋ | 85/98 [00:04<00:00, 18.42it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  88%|████████▊ | 86/98 [00:04<00:00, 18.43it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  89%|████████▉ | 87/98 [00:04<00:00, 18.43it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  90%|████████▉ | 88/98 [00:04<00:00, 18.50it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  91%|█████████ | 89/98 [00:04<00:00, 17.87it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  92%|█████████▏| 90/98 [00:05<00:00, 17.95it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  93%|█████████▎| 91/98 [00:05<00:00, 18.02it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  94%|█████████▍| 92/98 [00:05<00:00, 18.07it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  95%|█████████▍| 93/98 [00:05<00:00, 18.13it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  96%|█████████▌| 94/98 [00:05<00:00, 18.20it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  97%|█████████▋| 95/98 [00:05<00:00, 18.28it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  98%|█████████▊| 96/98 [00:05<00:00, 18.36it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.610]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 15:  99%|█████████▉| 97/98 [00:05<00:00, 18.44it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.610]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 16:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.608]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   1%|          | 1/98 [00:00<00:07, 12.42it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   2%|▏         | 2/98 [00:00<00:05, 17.26it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   3%|▎         | 3/98 [00:00<00:04, 20.02it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   4%|▍         | 4/98 [00:00<00:08, 10.63it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   5%|▌         | 5/98 [00:00<00:07, 11.70it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   6%|▌         | 6/98 [00:00<00:07, 13.02it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   7%|▋         | 7/98 [00:00<00:06, 13.76it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   8%|▊         | 8/98 [00:00<00:06, 14.35it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:   9%|▉         | 9/98 [00:00<00:06, 14.74it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  10%|█         | 10/98 [00:00<00:05, 15.56it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  11%|█         | 11/98 [00:00<00:05, 16.36it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  12%|█▏        | 12/98 [00:00<00:05, 17.00it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  13%|█▎        | 13/98 [00:00<00:04, 17.39it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  14%|█▍        | 14/98 [00:00<00:04, 17.91it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  15%|█▌        | 15/98 [00:01<00:05, 14.84it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  16%|█▋        | 16/98 [00:01<00:05, 15.32it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  17%|█▋        | 17/98 [00:01<00:05, 15.64it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  18%|█▊        | 18/98 [00:01<00:05, 15.79it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  19%|█▉        | 19/98 [00:01<00:04, 16.05it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  20%|██        | 20/98 [00:01<00:04, 16.38it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  21%|██▏       | 21/98 [00:01<00:04, 16.50it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  22%|██▏       | 22/98 [00:01<00:04, 16.86it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  23%|██▎       | 23/98 [00:01<00:04, 17.16it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  24%|██▍       | 24/98 [00:01<00:04, 17.41it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  26%|██▌       | 25/98 [00:01<00:04, 17.64it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  27%|██▋       | 26/98 [00:01<00:04, 15.63it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  28%|██▊       | 27/98 [00:01<00:04, 15.89it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  29%|██▊       | 28/98 [00:01<00:04, 15.97it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  30%|██▉       | 29/98 [00:01<00:04, 16.21it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  31%|███       | 30/98 [00:01<00:04, 16.36it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  32%|███▏      | 31/98 [00:01<00:04, 16.43it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  33%|███▎      | 32/98 [00:01<00:03, 16.57it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  34%|███▎      | 33/98 [00:01<00:03, 16.77it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  35%|███▍      | 34/98 [00:02<00:03, 16.95it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  36%|███▌      | 35/98 [00:02<00:03, 17.09it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  37%|███▋      | 36/98 [00:02<00:03, 17.13it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  38%|███▊      | 37/98 [00:02<00:03, 15.84it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  39%|███▉      | 38/98 [00:02<00:03, 16.03it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  40%|███▉      | 39/98 [00:02<00:03, 16.11it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  41%|████      | 40/98 [00:02<00:03, 16.25it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  42%|████▏     | 41/98 [00:02<00:03, 16.39it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  43%|████▎     | 42/98 [00:02<00:03, 16.51it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  44%|████▍     | 43/98 [00:02<00:03, 16.62it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  45%|████▍     | 44/98 [00:02<00:03, 16.73it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  46%|████▌     | 45/98 [00:02<00:03, 16.86it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  47%|████▋     | 46/98 [00:02<00:03, 17.02it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  48%|████▊     | 47/98 [00:02<00:02, 17.19it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  49%|████▉     | 48/98 [00:02<00:03, 16.23it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  50%|█████     | 49/98 [00:03<00:03, 16.26it/s, v_num=crps, train_loss_step=0.580, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  51%|█████     | 50/98 [00:03<00:02, 16.40it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  52%|█████▏    | 51/98 [00:03<00:02, 16.52it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  53%|█████▎    | 52/98 [00:03<00:02, 16.57it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  54%|█████▍    | 53/98 [00:03<00:02, 16.70it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  55%|█████▌    | 54/98 [00:03<00:02, 16.81it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  56%|█████▌    | 55/98 [00:03<00:02, 16.92it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  57%|█████▋    | 56/98 [00:03<00:02, 17.00it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  58%|█████▊    | 57/98 [00:03<00:02, 17.10it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  59%|█████▉    | 58/98 [00:03<00:02, 17.15it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  60%|██████    | 59/98 [00:03<00:02, 16.33it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  61%|██████    | 60/98 [00:03<00:02, 16.44it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  62%|██████▏   | 61/98 [00:03<00:02, 16.50it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  63%|██████▎   | 62/98 [00:03<00:02, 16.62it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  64%|██████▍   | 63/98 [00:03<00:02, 16.73it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  65%|██████▌   | 64/98 [00:03<00:02, 16.83it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  66%|██████▋   | 65/98 [00:03<00:01, 16.90it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  67%|██████▋   | 66/98 [00:03<00:01, 17.01it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  68%|██████▊   | 67/98 [00:03<00:01, 17.09it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  69%|██████▉   | 68/98 [00:03<00:01, 17.17it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  70%|███████   | 69/98 [00:03<00:01, 17.26it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  71%|███████▏  | 70/98 [00:04<00:01, 16.46it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  72%|███████▏  | 71/98 [00:04<00:01, 16.56it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  73%|███████▎  | 72/98 [00:04<00:01, 16.59it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  74%|███████▍  | 73/98 [00:04<00:01, 16.61it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  76%|███████▌  | 74/98 [00:04<00:01, 16.68it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  77%|███████▋  | 75/98 [00:04<00:01, 16.75it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  78%|███████▊  | 76/98 [00:04<00:01, 16.82it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  79%|███████▊  | 77/98 [00:04<00:01, 16.90it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  80%|███████▉  | 78/98 [00:04<00:01, 16.97it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  81%|████████  | 79/98 [00:04<00:01, 17.04it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  82%|████████▏ | 80/98 [00:04<00:01, 17.12it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  83%|████████▎ | 81/98 [00:04<00:01, 16.48it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  84%|████████▎ | 82/98 [00:04<00:00, 16.52it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  85%|████████▍ | 83/98 [00:04<00:00, 16.61it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  86%|████████▌ | 84/98 [00:05<00:00, 16.69it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  87%|████████▋ | 85/98 [00:05<00:00, 16.71it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  88%|████████▊ | 86/98 [00:05<00:00, 16.73it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  89%|████████▉ | 87/98 [00:05<00:00, 16.80it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  90%|████████▉ | 88/98 [00:05<00:00, 16.82it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  91%|█████████ | 89/98 [00:05<00:00, 16.89it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  92%|█████████▏| 90/98 [00:05<00:00, 16.96it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  93%|█████████▎| 91/98 [00:05<00:00, 17.02it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  94%|█████████▍| 92/98 [00:05<00:00, 16.47it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  95%|█████████▍| 93/98 [00:05<00:00, 16.55it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  96%|█████████▌| 94/98 [00:05<00:00, 16.57it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  97%|█████████▋| 95/98 [00:05<00:00, 16.64it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  98%|█████████▊| 96/98 [00:05<00:00, 16.66it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.608]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 16:  99%|█████████▉| 97/98 [00:05<00:00, 16.72it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.608]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 17:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.577, train_loss_epoch=0.604]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   1%|          | 1/98 [00:00<00:05, 16.21it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   2%|▏         | 2/98 [00:00<00:04, 20.27it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   3%|▎         | 3/98 [00:00<00:04, 21.94it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   4%|▍         | 4/98 [00:00<00:04, 22.46it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   5%|▌         | 5/98 [00:00<00:07, 12.29it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   6%|▌         | 6/98 [00:00<00:06, 13.60it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   7%|▋         | 7/98 [00:00<00:06, 14.66it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   8%|▊         | 8/98 [00:00<00:05, 15.56it/s, v_num=crps, train_loss_step=0.583, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:   9%|▉         | 9/98 [00:00<00:05, 15.90it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  10%|█         | 10/98 [00:00<00:05, 16.48it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  11%|█         | 11/98 [00:00<00:05, 16.68it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  12%|█▏        | 12/98 [00:00<00:05, 17.12it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  13%|█▎        | 13/98 [00:00<00:04, 17.59it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  14%|█▍        | 14/98 [00:00<00:04, 17.75it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  15%|█▌        | 15/98 [00:00<00:04, 18.19it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  16%|█▋        | 16/98 [00:01<00:05, 15.14it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  17%|█▋        | 17/98 [00:01<00:05, 15.55it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  18%|█▊        | 18/98 [00:01<00:05, 15.95it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  19%|█▉        | 19/98 [00:01<00:04, 16.25it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  20%|██        | 20/98 [00:01<00:04, 16.62it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  21%|██▏       | 21/98 [00:01<00:04, 16.88it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  22%|██▏       | 22/98 [00:01<00:04, 17.20it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  23%|██▎       | 23/98 [00:01<00:04, 17.50it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  24%|██▍       | 24/98 [00:01<00:04, 17.77it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  26%|██▌       | 25/98 [00:01<00:04, 18.00it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  27%|██▋       | 26/98 [00:01<00:03, 18.20it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  28%|██▊       | 27/98 [00:01<00:04, 16.12it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  29%|██▊       | 28/98 [00:01<00:04, 16.29it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  30%|██▉       | 29/98 [00:01<00:04, 16.53it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  31%|███       | 30/98 [00:01<00:04, 16.75it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  32%|███▏      | 31/98 [00:01<00:03, 16.95it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  33%|███▎      | 32/98 [00:01<00:03, 17.01it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  34%|███▎      | 33/98 [00:01<00:03, 17.21it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  35%|███▍      | 34/98 [00:01<00:03, 17.40it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  36%|███▌      | 35/98 [00:01<00:03, 17.61it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  37%|███▋      | 36/98 [00:02<00:03, 17.83it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  38%|███▊      | 37/98 [00:02<00:03, 18.03it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  39%|███▉      | 38/98 [00:02<00:03, 16.70it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  40%|███▉      | 39/98 [00:02<00:03, 16.86it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  41%|████      | 40/98 [00:02<00:03, 16.89it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  42%|████▏     | 41/98 [00:02<00:03, 17.06it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  43%|████▎     | 42/98 [00:02<00:03, 17.18it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  44%|████▍     | 43/98 [00:02<00:03, 17.28it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  45%|████▍     | 44/98 [00:02<00:03, 17.44it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  46%|████▌     | 45/98 [00:02<00:03, 17.45it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  47%|████▋     | 46/98 [00:02<00:02, 17.58it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  48%|████▊     | 47/98 [00:02<00:02, 17.69it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  49%|████▉     | 48/98 [00:02<00:02, 17.77it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  50%|█████     | 49/98 [00:02<00:02, 16.70it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  51%|█████     | 50/98 [00:02<00:02, 16.74it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  52%|█████▏    | 51/98 [00:03<00:02, 16.82it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  53%|█████▎    | 52/98 [00:03<00:02, 16.95it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  54%|█████▍    | 53/98 [00:03<00:02, 17.08it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  55%|█████▌    | 54/98 [00:03<00:02, 17.17it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  56%|█████▌    | 55/98 [00:03<00:02, 17.21it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  57%|█████▋    | 56/98 [00:03<00:02, 17.24it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  58%|█████▊    | 57/98 [00:03<00:02, 17.36it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  59%|█████▉    | 58/98 [00:03<00:02, 17.46it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  60%|██████    | 59/98 [00:03<00:02, 17.58it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  61%|██████    | 60/98 [00:03<00:02, 16.77it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  62%|██████▏   | 61/98 [00:03<00:02, 16.88it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  63%|██████▎   | 62/98 [00:03<00:02, 16.96it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  64%|██████▍   | 63/98 [00:03<00:02, 17.03it/s, v_num=crps, train_loss_step=0.623, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  65%|██████▌   | 64/98 [00:03<00:01, 17.13it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  66%|██████▋   | 65/98 [00:03<00:01, 17.23it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  67%|██████▋   | 66/98 [00:03<00:01, 17.26it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  68%|██████▊   | 67/98 [00:03<00:01, 17.35it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  69%|██████▉   | 68/98 [00:03<00:01, 17.43it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  70%|███████   | 69/98 [00:03<00:01, 17.51it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  71%|███████▏  | 70/98 [00:03<00:01, 17.59it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  72%|███████▏  | 71/98 [00:04<00:01, 16.90it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  73%|███████▎  | 72/98 [00:04<00:01, 16.93it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  74%|███████▍  | 73/98 [00:04<00:01, 17.03it/s, v_num=crps, train_loss_step=0.628, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  76%|███████▌  | 74/98 [00:04<00:01, 17.07it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  77%|███████▋  | 75/98 [00:04<00:01, 17.10it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  78%|███████▊  | 76/98 [00:04<00:01, 17.18it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  79%|███████▊  | 77/98 [00:04<00:01, 17.26it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  80%|███████▉  | 78/98 [00:04<00:01, 17.35it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  81%|████████  | 79/98 [00:04<00:01, 17.41it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  82%|████████▏ | 80/98 [00:04<00:01, 17.43it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  83%|████████▎ | 81/98 [00:04<00:00, 17.52it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  84%|████████▎ | 82/98 [00:04<00:00, 16.92it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  85%|████████▍ | 83/98 [00:04<00:00, 17.00it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  86%|████████▌ | 84/98 [00:04<00:00, 17.08it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  87%|████████▋ | 85/98 [00:04<00:00, 17.13it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  88%|████████▊ | 86/98 [00:05<00:00, 17.17it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  89%|████████▉ | 87/98 [00:05<00:00, 17.25it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  90%|████████▉ | 88/98 [00:05<00:00, 17.29it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  91%|█████████ | 89/98 [00:05<00:00, 17.38it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  92%|█████████▏| 90/98 [00:05<00:00, 17.45it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  93%|█████████▎| 91/98 [00:05<00:00, 17.52it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  94%|█████████▍| 92/98 [00:05<00:00, 17.59it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  95%|█████████▍| 93/98 [00:05<00:00, 17.05it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  96%|█████████▌| 94/98 [00:05<00:00, 17.12it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  97%|█████████▋| 95/98 [00:05<00:00, 17.20it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  98%|█████████▊| 96/98 [00:05<00:00, 17.26it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.604]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 17:  99%|█████████▉| 97/98 [00:05<00:00, 17.33it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.604]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 18:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.606]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   1%|          | 1/98 [00:00<00:06, 13.96it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   2%|▏         | 2/98 [00:00<00:05, 18.56it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   3%|▎         | 3/98 [00:00<00:04, 21.14it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   4%|▍         | 4/98 [00:00<00:04, 22.46it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   5%|▌         | 5/98 [00:00<00:04, 22.41it/s, v_num=crps, train_loss_step=0.625, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   6%|▌         | 6/98 [00:00<00:06, 13.33it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   7%|▋         | 7/98 [00:00<00:06, 13.62it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   8%|▊         | 8/98 [00:00<00:06, 14.55it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:   9%|▉         | 9/98 [00:00<00:05, 15.42it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  10%|█         | 10/98 [00:00<00:05, 15.71it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  11%|█         | 11/98 [00:00<00:05, 15.96it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  12%|█▏        | 12/98 [00:00<00:05, 16.52it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  13%|█▎        | 13/98 [00:00<00:04, 17.04it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  14%|█▍        | 14/98 [00:00<00:04, 17.52it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  15%|█▌        | 15/98 [00:00<00:04, 17.52it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  16%|█▋        | 16/98 [00:00<00:04, 17.94it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  17%|█▋        | 17/98 [00:01<00:05, 15.28it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  18%|█▊        | 18/98 [00:01<00:05, 15.70it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  19%|█▉        | 19/98 [00:01<00:04, 16.11it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  20%|██        | 20/98 [00:01<00:04, 16.47it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  21%|██▏       | 21/98 [00:01<00:04, 16.62it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  22%|██▏       | 22/98 [00:01<00:04, 16.95it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  23%|██▎       | 23/98 [00:01<00:04, 17.26it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  24%|██▍       | 24/98 [00:01<00:04, 17.54it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  26%|██▌       | 25/98 [00:01<00:04, 17.81it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  27%|██▋       | 26/98 [00:01<00:03, 18.04it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  28%|██▊       | 27/98 [00:01<00:03, 18.29it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  29%|██▊       | 28/98 [00:01<00:04, 16.48it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  30%|██▉       | 29/98 [00:01<00:04, 16.73it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  31%|███       | 30/98 [00:01<00:04, 16.95it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  32%|███▏      | 31/98 [00:01<00:03, 17.01it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  33%|███▎      | 32/98 [00:01<00:03, 17.25it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  34%|███▎      | 33/98 [00:01<00:03, 17.46it/s, v_num=crps, train_loss_step=0.629, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  35%|███▍      | 34/98 [00:01<00:03, 17.66it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  36%|███▌      | 35/98 [00:01<00:03, 17.82it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  37%|███▋      | 36/98 [00:01<00:03, 18.02it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  38%|███▊      | 37/98 [00:02<00:03, 18.19it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  39%|███▉      | 38/98 [00:02<00:03, 18.35it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  40%|███▉      | 39/98 [00:02<00:03, 16.99it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  41%|████      | 40/98 [00:02<00:03, 17.16it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  42%|████▏     | 41/98 [00:02<00:03, 17.31it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  43%|████▎     | 42/98 [00:02<00:03, 17.45it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  44%|████▍     | 43/98 [00:02<00:03, 17.40it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  45%|████▍     | 44/98 [00:02<00:03, 17.48it/s, v_num=crps, train_loss_step=0.581, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  46%|████▌     | 45/98 [00:02<00:03, 17.62it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  47%|████▋     | 46/98 [00:02<00:02, 17.66it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  48%|████▊     | 47/98 [00:02<00:02, 17.80it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  49%|████▉     | 48/98 [00:02<00:02, 17.88it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  50%|█████     | 49/98 [00:02<00:02, 17.95it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  51%|█████     | 50/98 [00:02<00:02, 16.85it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  52%|█████▏    | 51/98 [00:03<00:02, 16.90it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  53%|█████▎    | 52/98 [00:03<00:02, 16.95it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  54%|█████▍    | 53/98 [00:03<00:02, 17.08it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  55%|█████▌    | 54/98 [00:03<00:02, 17.10it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  56%|█████▌    | 55/98 [00:03<00:02, 17.17it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  57%|█████▋    | 56/98 [00:03<00:02, 17.27it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  58%|█████▊    | 57/98 [00:03<00:02, 17.28it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  59%|█████▉    | 58/98 [00:03<00:02, 17.40it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  60%|██████    | 59/98 [00:03<00:02, 17.52it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  61%|██████    | 60/98 [00:03<00:02, 17.63it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  62%|██████▏   | 61/98 [00:03<00:02, 16.82it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  63%|██████▎   | 62/98 [00:03<00:02, 16.94it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  64%|██████▍   | 63/98 [00:03<00:02, 17.03it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  65%|██████▌   | 64/98 [00:03<00:01, 17.09it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  66%|██████▋   | 65/98 [00:03<00:01, 17.19it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  67%|██████▋   | 66/98 [00:03<00:01, 17.20it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  68%|██████▊   | 67/98 [00:03<00:01, 17.30it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  69%|██████▉   | 68/98 [00:03<00:01, 17.40it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  70%|███████   | 69/98 [00:03<00:01, 17.49it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  71%|███████▏  | 70/98 [00:03<00:01, 17.58it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  72%|███████▏  | 71/98 [00:04<00:01, 17.62it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  73%|███████▎  | 72/98 [00:04<00:01, 16.93it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  74%|███████▍  | 73/98 [00:04<00:01, 17.03it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  76%|███████▌  | 74/98 [00:04<00:01, 17.05it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  77%|███████▋  | 75/98 [00:04<00:01, 17.14it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  78%|███████▊  | 76/98 [00:04<00:01, 17.19it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  79%|███████▊  | 77/98 [00:04<00:01, 17.26it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  80%|███████▉  | 78/98 [00:04<00:01, 17.32it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  81%|████████  | 79/98 [00:04<00:01, 17.41it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  82%|████████▏ | 80/98 [00:04<00:01, 17.50it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  83%|████████▎ | 81/98 [00:04<00:00, 17.57it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  84%|████████▎ | 82/98 [00:04<00:00, 17.66it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  85%|████████▍ | 83/98 [00:04<00:00, 17.05it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  86%|████████▌ | 84/98 [00:04<00:00, 17.14it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  87%|████████▋ | 85/98 [00:04<00:00, 17.21it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  88%|████████▊ | 86/98 [00:04<00:00, 17.28it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  89%|████████▉ | 87/98 [00:05<00:00, 17.36it/s, v_num=crps, train_loss_step=0.620, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  90%|████████▉ | 88/98 [00:05<00:00, 17.43it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  91%|█████████ | 89/98 [00:05<00:00, 17.50it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  92%|█████████▏| 90/98 [00:05<00:00, 17.57it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  93%|█████████▎| 91/98 [00:05<00:00, 17.64it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  94%|█████████▍| 92/98 [00:05<00:00, 17.66it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  95%|█████████▍| 93/98 [00:05<00:00, 17.68it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  96%|█████████▌| 94/98 [00:05<00:00, 17.16it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  97%|█████████▋| 95/98 [00:05<00:00, 17.22it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  98%|█████████▊| 96/98 [00:05<00:00, 17.24it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.606]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 18:  99%|█████████▉| 97/98 [00:05<00:00, 17.31it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.606]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 19:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.603]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   1%|          | 1/98 [00:00<00:06, 13.93it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   2%|▏         | 2/98 [00:00<00:05, 17.07it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   3%|▎         | 3/98 [00:00<00:05, 18.41it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   4%|▍         | 4/98 [00:00<00:04, 19.46it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   5%|▌         | 5/98 [00:00<00:04, 20.96it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   6%|▌         | 6/98 [00:00<00:04, 21.84it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   7%|▋         | 7/98 [00:00<00:06, 14.12it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   8%|▊         | 8/98 [00:00<00:05, 15.06it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:   9%|▉         | 9/98 [00:00<00:05, 15.42it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  10%|█         | 10/98 [00:00<00:05, 16.13it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  11%|█         | 11/98 [00:00<00:05, 16.73it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  12%|█▏        | 12/98 [00:00<00:05, 17.08it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  13%|█▎        | 13/98 [00:00<00:04, 17.52it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  14%|█▍        | 14/98 [00:00<00:04, 17.97it/s, v_num=crps, train_loss_step=0.578, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  15%|█▌        | 15/98 [00:00<00:04, 18.39it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  16%|█▋        | 16/98 [00:00<00:04, 18.68it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  17%|█▋        | 17/98 [00:01<00:05, 15.63it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  18%|█▊        | 18/98 [00:01<00:05, 15.99it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  19%|█▉        | 19/98 [00:01<00:04, 16.34it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  20%|██        | 20/98 [00:01<00:04, 16.71it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  21%|██▏       | 21/98 [00:01<00:04, 17.04it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  22%|██▏       | 22/98 [00:01<00:04, 17.37it/s, v_num=crps, train_loss_step=0.583, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  23%|██▎       | 23/98 [00:01<00:04, 17.66it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  24%|██▍       | 24/98 [00:01<00:04, 17.89it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  26%|██▌       | 25/98 [00:01<00:04, 18.18it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  27%|██▋       | 26/98 [00:01<00:03, 18.47it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  28%|██▊       | 27/98 [00:01<00:03, 18.69it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  29%|██▊       | 28/98 [00:01<00:04, 16.75it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  30%|██▉       | 29/98 [00:01<00:04, 16.88it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  31%|███       | 30/98 [00:01<00:03, 17.12it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  32%|███▏      | 31/98 [00:01<00:03, 17.35it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  33%|███▎      | 32/98 [00:01<00:03, 17.42it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  34%|███▎      | 33/98 [00:01<00:03, 17.63it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  35%|███▍      | 34/98 [00:01<00:03, 17.80it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  36%|███▌      | 35/98 [00:01<00:03, 17.95it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  37%|███▋      | 36/98 [00:01<00:03, 18.09it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  38%|███▊      | 37/98 [00:02<00:03, 18.28it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  39%|███▉      | 38/98 [00:02<00:03, 16.87it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  40%|███▉      | 39/98 [00:02<00:03, 17.05it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  41%|████      | 40/98 [00:02<00:03, 17.22it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  42%|████▏     | 41/98 [00:02<00:03, 17.24it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  43%|████▎     | 42/98 [00:02<00:03, 17.37it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  44%|████▍     | 43/98 [00:02<00:03, 17.51it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  45%|████▍     | 44/98 [00:02<00:03, 17.63it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  46%|████▌     | 45/98 [00:02<00:03, 17.65it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  47%|████▋     | 46/98 [00:02<00:02, 17.78it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  48%|████▊     | 47/98 [00:02<00:02, 17.84it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  49%|████▉     | 48/98 [00:02<00:02, 17.95it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  50%|█████     | 49/98 [00:02<00:02, 16.91it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  51%|█████     | 50/98 [00:02<00:02, 17.05it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  52%|█████▏    | 51/98 [00:02<00:02, 17.10it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  53%|█████▎    | 52/98 [00:03<00:02, 17.19it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  54%|█████▍    | 53/98 [00:03<00:02, 17.32it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  55%|█████▌    | 54/98 [00:03<00:02, 17.36it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  56%|█████▌    | 55/98 [00:03<00:02, 17.49it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  57%|█████▋    | 56/98 [00:03<00:02, 17.61it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  58%|█████▊    | 57/98 [00:03<00:02, 17.73it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  59%|█████▉    | 58/98 [00:03<00:02, 17.74it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  60%|██████    | 59/98 [00:03<00:02, 17.80it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  61%|██████    | 60/98 [00:03<00:02, 16.91it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  62%|██████▏   | 61/98 [00:03<00:02, 17.02it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  63%|██████▎   | 62/98 [00:03<00:02, 17.09it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  64%|██████▍   | 63/98 [00:03<00:02, 17.19it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  65%|██████▌   | 64/98 [00:03<00:01, 17.29it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  66%|██████▋   | 65/98 [00:03<00:01, 17.40it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  67%|██████▋   | 66/98 [00:03<00:01, 17.49it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  68%|██████▊   | 67/98 [00:03<00:01, 17.55it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  69%|██████▉   | 68/98 [00:03<00:01, 17.65it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  70%|███████   | 69/98 [00:03<00:01, 17.74it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  71%|███████▏  | 70/98 [00:03<00:01, 17.84it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  72%|███████▏  | 71/98 [00:04<00:01, 17.10it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  73%|███████▎  | 72/98 [00:04<00:01, 17.13it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  74%|███████▍  | 73/98 [00:04<00:01, 17.16it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  76%|███████▌  | 74/98 [00:04<00:01, 17.19it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  77%|███████▋  | 75/98 [00:04<00:01, 17.28it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  78%|███████▊  | 76/98 [00:04<00:01, 17.38it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  79%|███████▊  | 77/98 [00:04<00:01, 17.46it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  80%|███████▉  | 78/98 [00:04<00:01, 17.56it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  81%|████████  | 79/98 [00:04<00:01, 17.64it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  82%|████████▏ | 80/98 [00:04<00:01, 17.73it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  83%|████████▎ | 81/98 [00:04<00:00, 17.81it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  84%|████████▎ | 82/98 [00:04<00:00, 17.19it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  85%|████████▍ | 83/98 [00:04<00:00, 17.20it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  86%|████████▌ | 84/98 [00:04<00:00, 17.29it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  87%|████████▋ | 85/98 [00:04<00:00, 17.37it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  88%|████████▊ | 86/98 [00:04<00:00, 17.42it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  89%|████████▉ | 87/98 [00:04<00:00, 17.48it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  90%|████████▉ | 88/98 [00:05<00:00, 17.49it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  91%|█████████ | 89/98 [00:05<00:00, 17.54it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  92%|█████████▏| 90/98 [00:05<00:00, 17.61it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  93%|█████████▎| 91/98 [00:05<00:00, 17.68it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  94%|█████████▍| 92/98 [00:05<00:00, 17.74it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  95%|█████████▍| 93/98 [00:05<00:00, 17.19it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  96%|█████████▌| 94/98 [00:05<00:00, 17.27it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  97%|█████████▋| 95/98 [00:05<00:00, 17.33it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  98%|█████████▊| 96/98 [00:05<00:00, 17.39it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.603]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 19:  99%|█████████▉| 97/98 [00:05<00:00, 17.45it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.603]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 20:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.599]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   1%|          | 1/98 [00:00<00:06, 15.02it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   2%|▏         | 2/98 [00:00<00:05, 18.01it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   3%|▎         | 3/98 [00:00<00:04, 20.36it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   4%|▍         | 4/98 [00:00<00:04, 21.30it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   5%|▌         | 5/98 [00:00<00:04, 21.97it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   6%|▌         | 6/98 [00:00<00:04, 22.64it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   7%|▋         | 7/98 [00:00<00:06, 13.86it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   8%|▊         | 8/98 [00:00<00:06, 14.81it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:   9%|▉         | 9/98 [00:00<00:05, 15.64it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  10%|█         | 10/98 [00:00<00:05, 16.35it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  11%|█         | 11/98 [00:00<00:05, 16.92it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  12%|█▏        | 12/98 [00:00<00:04, 17.51it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  13%|█▎        | 13/98 [00:00<00:04, 18.01it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  14%|█▍        | 14/98 [00:00<00:04, 18.45it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  15%|█▌        | 15/98 [00:00<00:04, 18.86it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  16%|█▋        | 16/98 [00:00<00:04, 19.25it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  17%|█▋        | 17/98 [00:00<00:04, 19.43it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  18%|█▊        | 18/98 [00:01<00:04, 16.34it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  19%|█▉        | 19/98 [00:01<00:04, 16.71it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  20%|██        | 20/98 [00:01<00:04, 16.93it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  21%|██▏       | 21/98 [00:01<00:04, 17.00it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  22%|██▏       | 22/98 [00:01<00:04, 17.32it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  23%|██▎       | 23/98 [00:01<00:04, 17.58it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  24%|██▍       | 24/98 [00:01<00:04, 17.75it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  26%|██▌       | 25/98 [00:01<00:04, 17.84it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  27%|██▋       | 26/98 [00:01<00:03, 18.07it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  28%|██▊       | 27/98 [00:01<00:03, 18.34it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  29%|██▊       | 28/98 [00:01<00:04, 16.54it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  30%|██▉       | 29/98 [00:01<00:04, 16.81it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  31%|███       | 30/98 [00:01<00:03, 17.07it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  32%|███▏      | 31/98 [00:01<00:03, 17.29it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  33%|███▎      | 32/98 [00:01<00:03, 17.31it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  34%|███▎      | 33/98 [00:01<00:03, 17.39it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  35%|███▍      | 34/98 [00:01<00:03, 17.52it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  36%|███▌      | 35/98 [00:01<00:03, 17.72it/s, v_num=crps, train_loss_step=0.631, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  37%|███▋      | 36/98 [00:02<00:03, 17.91it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  38%|███▊      | 37/98 [00:02<00:03, 16.58it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  39%|███▉      | 38/98 [00:02<00:03, 16.77it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  40%|███▉      | 39/98 [00:02<00:03, 16.96it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  41%|████      | 40/98 [00:02<00:03, 17.12it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  42%|████▏     | 41/98 [00:02<00:03, 17.16it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  43%|████▎     | 42/98 [00:02<00:03, 17.20it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  44%|████▍     | 43/98 [00:02<00:03, 17.22it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  45%|████▍     | 44/98 [00:02<00:03, 17.30it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  46%|████▌     | 45/98 [00:02<00:03, 17.45it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  47%|████▋     | 46/98 [00:02<00:02, 17.59it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  48%|████▊     | 47/98 [00:02<00:02, 17.71it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  49%|████▉     | 48/98 [00:02<00:02, 16.71it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  50%|█████     | 49/98 [00:02<00:02, 16.83it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  51%|█████     | 50/98 [00:02<00:02, 16.90it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  52%|█████▏    | 51/98 [00:03<00:02, 16.97it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  53%|█████▎    | 52/98 [00:03<00:02, 17.06it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  54%|█████▍    | 53/98 [00:03<00:02, 17.19it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  55%|█████▌    | 54/98 [00:03<00:02, 17.24it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  56%|█████▌    | 55/98 [00:03<00:02, 17.28it/s, v_num=crps, train_loss_step=0.577, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  57%|█████▋    | 56/98 [00:03<00:02, 17.41it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  58%|█████▊    | 57/98 [00:03<00:02, 17.53it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  59%|█████▉    | 58/98 [00:03<00:02, 16.68it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  60%|██████    | 59/98 [00:03<00:02, 16.72it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  61%|██████    | 60/98 [00:03<00:02, 16.72it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  62%|██████▏   | 61/98 [00:03<00:02, 16.77it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  63%|██████▎   | 62/98 [00:03<00:02, 16.88it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  64%|██████▍   | 63/98 [00:03<00:02, 16.96it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  65%|██████▌   | 64/98 [00:03<00:01, 17.07it/s, v_num=crps, train_loss_step=0.578, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  66%|██████▋   | 65/98 [00:03<00:01, 17.17it/s, v_num=crps, train_loss_step=0.580, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  67%|██████▋   | 66/98 [00:03<00:01, 17.21it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  68%|██████▊   | 67/98 [00:03<00:01, 17.30it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  69%|██████▉   | 68/98 [00:03<00:01, 17.41it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  70%|███████   | 69/98 [00:04<00:01, 16.71it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  71%|███████▏  | 70/98 [00:04<00:01, 16.82it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  72%|███████▏  | 71/98 [00:04<00:01, 16.89it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  73%|███████▎  | 72/98 [00:04<00:01, 16.96it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  74%|███████▍  | 73/98 [00:04<00:01, 17.05it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  76%|███████▌  | 74/98 [00:04<00:01, 17.13it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  77%|███████▋  | 75/98 [00:04<00:01, 17.21it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  78%|███████▊  | 76/98 [00:04<00:01, 17.27it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  79%|███████▊  | 77/98 [00:04<00:01, 17.34it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  80%|███████▉  | 78/98 [00:04<00:01, 17.41it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  81%|████████  | 79/98 [00:04<00:01, 17.49it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  82%|████████▏ | 80/98 [00:04<00:01, 16.88it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  83%|████████▎ | 81/98 [00:04<00:01, 16.96it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  84%|████████▎ | 82/98 [00:04<00:00, 16.99it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  85%|████████▍ | 83/98 [00:04<00:00, 17.02it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  86%|████████▌ | 84/98 [00:04<00:00, 17.10it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  87%|████████▋ | 85/98 [00:04<00:00, 17.12it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  88%|████████▊ | 86/98 [00:05<00:00, 17.16it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  89%|████████▉ | 87/98 [00:05<00:00, 17.25it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  90%|████████▉ | 88/98 [00:05<00:00, 17.32it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  91%|█████████ | 89/98 [00:05<00:00, 17.38it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  92%|█████████▏| 90/98 [00:05<00:00, 17.45it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  93%|█████████▎| 91/98 [00:05<00:00, 16.86it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  94%|█████████▍| 92/98 [00:05<00:00, 16.93it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  95%|█████████▍| 93/98 [00:05<00:00, 17.00it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  96%|█████████▌| 94/98 [00:05<00:00, 17.03it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  97%|█████████▋| 95/98 [00:05<00:00, 17.11it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  98%|█████████▊| 96/98 [00:05<00:00, 17.18it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 20:  99%|█████████▉| 97/98 [00:05<00:00, 17.25it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.599]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 21:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.600]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   1%|          | 1/98 [00:00<00:05, 16.43it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   2%|▏         | 2/98 [00:00<00:04, 19.35it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   3%|▎         | 3/98 [00:00<00:04, 21.80it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   4%|▍         | 4/98 [00:00<00:04, 23.37it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   5%|▌         | 5/98 [00:00<00:03, 24.20it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   6%|▌         | 6/98 [00:00<00:06, 13.70it/s, v_num=crps, train_loss_step=0.581, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   7%|▋         | 7/98 [00:00<00:06, 14.85it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   8%|▊         | 8/98 [00:00<00:05, 15.46it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:   9%|▉         | 9/98 [00:00<00:05, 15.71it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  10%|█         | 10/98 [00:00<00:05, 16.52it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  11%|█         | 11/98 [00:00<00:05, 17.10it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  12%|█▏        | 12/98 [00:00<00:04, 17.26it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  13%|█▎        | 13/98 [00:00<00:04, 17.60it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  14%|█▍        | 14/98 [00:00<00:04, 18.00it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  15%|█▌        | 15/98 [00:00<00:04, 18.38it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  16%|█▋        | 16/98 [00:01<00:05, 15.09it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  17%|█▋        | 17/98 [00:01<00:05, 15.24it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  18%|█▊        | 18/98 [00:01<00:05, 15.35it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  19%|█▉        | 19/98 [00:01<00:05, 15.53it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  20%|██        | 20/98 [00:01<00:04, 15.88it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  21%|██▏       | 21/98 [00:01<00:04, 16.19it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  22%|██▏       | 22/98 [00:01<00:04, 16.28it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  23%|██▎       | 23/98 [00:01<00:04, 16.56it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  24%|██▍       | 24/98 [00:01<00:04, 16.85it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  26%|██▌       | 25/98 [00:01<00:04, 17.13it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  27%|██▋       | 26/98 [00:01<00:04, 17.40it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  28%|██▊       | 27/98 [00:01<00:04, 15.74it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  29%|██▊       | 28/98 [00:01<00:04, 15.97it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  30%|██▉       | 29/98 [00:01<00:04, 16.21it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  31%|███       | 30/98 [00:01<00:04, 16.43it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  32%|███▏      | 31/98 [00:01<00:04, 16.49it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  33%|███▎      | 32/98 [00:01<00:03, 16.67it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  34%|███▎      | 33/98 [00:01<00:03, 16.73it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  35%|███▍      | 34/98 [00:02<00:03, 16.82it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  36%|███▌      | 35/98 [00:02<00:03, 16.97it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  37%|███▋      | 36/98 [00:02<00:03, 17.16it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  38%|███▊      | 37/98 [00:02<00:03, 15.98it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  39%|███▉      | 38/98 [00:02<00:03, 16.17it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  40%|███▉      | 39/98 [00:02<00:03, 16.35it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  41%|████      | 40/98 [00:02<00:03, 16.47it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  42%|████▏     | 41/98 [00:02<00:03, 16.55it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  43%|████▎     | 42/98 [00:02<00:03, 16.69it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  44%|████▍     | 43/98 [00:02<00:03, 16.74it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  45%|████▍     | 44/98 [00:02<00:03, 16.82it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  46%|████▌     | 45/98 [00:02<00:03, 16.95it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  47%|████▋     | 46/98 [00:02<00:03, 15.98it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  48%|████▊     | 47/98 [00:02<00:03, 16.14it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  49%|████▉     | 48/98 [00:02<00:03, 16.19it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  50%|█████     | 49/98 [00:03<00:03, 16.32it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  51%|█████     | 50/98 [00:03<00:02, 16.46it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  52%|█████▏    | 51/98 [00:03<00:02, 16.56it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  53%|█████▎    | 52/98 [00:03<00:02, 16.61it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  54%|█████▍    | 53/98 [00:03<00:02, 16.70it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  55%|█████▌    | 54/98 [00:03<00:02, 16.82it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  56%|█████▌    | 55/98 [00:03<00:02, 16.85it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  57%|█████▋    | 56/98 [00:03<00:02, 16.97it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  58%|█████▊    | 57/98 [00:03<00:02, 16.18it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  59%|█████▉    | 58/98 [00:03<00:02, 16.29it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  60%|██████    | 59/98 [00:03<00:02, 16.33it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  61%|██████    | 60/98 [00:03<00:02, 16.45it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  62%|██████▏   | 61/98 [00:03<00:02, 16.48it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  63%|██████▎   | 62/98 [00:03<00:02, 16.59it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  64%|██████▍   | 63/98 [00:03<00:02, 16.68it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  65%|██████▌   | 64/98 [00:03<00:02, 16.70it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  66%|██████▋   | 65/98 [00:03<00:01, 16.80it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  67%|██████▋   | 66/98 [00:03<00:01, 16.89it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  68%|██████▊   | 67/98 [00:04<00:01, 16.14it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  69%|██████▉   | 68/98 [00:04<00:01, 16.24it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  70%|███████   | 69/98 [00:04<00:01, 16.34it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  71%|███████▏  | 70/98 [00:04<00:01, 16.38it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  72%|███████▏  | 71/98 [00:04<00:01, 16.47it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  73%|███████▎  | 72/98 [00:04<00:01, 16.53it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  74%|███████▍  | 73/98 [00:04<00:01, 16.62it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  76%|███████▌  | 74/98 [00:04<00:01, 16.68it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  77%|███████▋  | 75/98 [00:04<00:01, 16.71it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  78%|███████▊  | 76/98 [00:04<00:01, 16.80it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  79%|███████▊  | 77/98 [00:04<00:01, 16.88it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  80%|███████▉  | 78/98 [00:04<00:01, 16.30it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  81%|████████  | 79/98 [00:04<00:01, 16.39it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  82%|████████▏ | 80/98 [00:04<00:01, 16.46it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  83%|████████▎ | 81/98 [00:04<00:01, 16.56it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  84%|████████▎ | 82/98 [00:04<00:00, 16.64it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  85%|████████▍ | 83/98 [00:04<00:00, 16.66it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  86%|████████▌ | 84/98 [00:05<00:00, 16.74it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  87%|████████▋ | 85/98 [00:05<00:00, 16.81it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  88%|████████▊ | 86/98 [00:05<00:00, 16.88it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  89%|████████▉ | 87/98 [00:05<00:00, 16.97it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  90%|████████▉ | 88/98 [00:05<00:00, 16.99it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  91%|█████████ | 89/98 [00:05<00:00, 16.46it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  92%|█████████▏| 90/98 [00:05<00:00, 16.49it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  93%|█████████▎| 91/98 [00:05<00:00, 16.56it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  94%|█████████▍| 92/98 [00:05<00:00, 16.58it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  95%|█████████▍| 93/98 [00:05<00:00, 16.65it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  96%|█████████▌| 94/98 [00:05<00:00, 16.73it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  97%|█████████▋| 95/98 [00:05<00:00, 16.75it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  98%|█████████▊| 96/98 [00:05<00:00, 16.79it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 21:  99%|█████████▉| 97/98 [00:05<00:00, 16.86it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.600]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 22:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.633, train_loss_epoch=0.599]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   1%|          | 1/98 [00:00<00:06, 15.71it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   2%|▏         | 2/98 [00:00<00:04, 20.18it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   3%|▎         | 3/98 [00:00<00:04, 22.46it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   4%|▍         | 4/98 [00:00<00:08, 11.28it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   5%|▌         | 5/98 [00:00<00:07, 12.85it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   6%|▌         | 6/98 [00:00<00:06, 14.10it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   7%|▋         | 7/98 [00:00<00:06, 14.99it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   8%|▊         | 8/98 [00:00<00:05, 16.03it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:   9%|▉         | 9/98 [00:00<00:05, 16.74it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  10%|█         | 10/98 [00:00<00:05, 17.17it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  11%|█         | 11/98 [00:00<00:05, 17.36it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  12%|█▏        | 12/98 [00:00<00:04, 17.62it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  13%|█▎        | 13/98 [00:00<00:04, 18.02it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  14%|█▍        | 14/98 [00:00<00:04, 18.47it/s, v_num=crps, train_loss_step=0.579, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  15%|█▌        | 15/98 [00:00<00:05, 15.24it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  16%|█▋        | 16/98 [00:01<00:05, 15.70it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  17%|█▋        | 17/98 [00:01<00:05, 16.09it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  18%|█▊        | 18/98 [00:01<00:04, 16.26it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  19%|█▉        | 19/98 [00:01<00:04, 16.42it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  20%|██        | 20/98 [00:01<00:04, 16.54it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  21%|██▏       | 21/98 [00:01<00:04, 16.88it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  22%|██▏       | 22/98 [00:01<00:04, 17.13it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  23%|██▎       | 23/98 [00:01<00:04, 17.39it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  24%|██▍       | 24/98 [00:01<00:04, 17.62it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  26%|██▌       | 25/98 [00:01<00:04, 17.87it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  27%|██▋       | 26/98 [00:01<00:04, 16.03it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  28%|██▊       | 27/98 [00:01<00:04, 16.29it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  29%|██▊       | 28/98 [00:01<00:04, 16.39it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  30%|██▉       | 29/98 [00:01<00:04, 16.62it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  31%|███       | 30/98 [00:01<00:04, 16.86it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  32%|███▏      | 31/98 [00:01<00:03, 17.06it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  33%|███▎      | 32/98 [00:01<00:03, 17.26it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  34%|███▎      | 33/98 [00:01<00:03, 17.47it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  35%|███▍      | 34/98 [00:01<00:03, 17.67it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  36%|███▌      | 35/98 [00:01<00:03, 17.84it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  37%|███▋      | 36/98 [00:02<00:03, 17.95it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  38%|███▊      | 37/98 [00:02<00:03, 16.61it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  39%|███▉      | 38/98 [00:02<00:03, 16.76it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  40%|███▉      | 39/98 [00:02<00:03, 16.81it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  41%|████      | 40/98 [00:02<00:03, 16.99it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  42%|████▏     | 41/98 [00:02<00:03, 17.12it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  43%|████▎     | 42/98 [00:02<00:03, 17.26it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  44%|████▍     | 43/98 [00:02<00:03, 17.40it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  45%|████▍     | 44/98 [00:02<00:03, 17.53it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  46%|████▌     | 45/98 [00:02<00:02, 17.68it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  47%|████▋     | 46/98 [00:02<00:02, 17.83it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  48%|████▊     | 47/98 [00:02<00:02, 17.95it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  49%|████▉     | 48/98 [00:02<00:02, 16.90it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  50%|█████     | 49/98 [00:02<00:02, 17.04it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  51%|█████     | 50/98 [00:02<00:02, 17.16it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  52%|█████▏    | 51/98 [00:02<00:02, 17.20it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  53%|█████▎    | 52/98 [00:03<00:02, 17.33it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  54%|█████▍    | 53/98 [00:03<00:02, 17.36it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  55%|█████▌    | 54/98 [00:03<00:02, 17.45it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  56%|█████▌    | 55/98 [00:03<00:02, 17.42it/s, v_num=crps, train_loss_step=0.635, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  57%|█████▋    | 56/98 [00:03<00:02, 17.53it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  58%|█████▊    | 57/98 [00:03<00:02, 17.65it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  59%|█████▉    | 58/98 [00:03<00:02, 17.78it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  60%|██████    | 59/98 [00:03<00:02, 16.94it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  61%|██████    | 60/98 [00:03<00:02, 17.05it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  62%|██████▏   | 61/98 [00:03<00:02, 17.17it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  63%|██████▎   | 62/98 [00:03<00:02, 17.23it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  64%|██████▍   | 63/98 [00:03<00:02, 17.33it/s, v_num=crps, train_loss_step=0.579, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  65%|██████▌   | 64/98 [00:03<00:01, 17.42it/s, v_num=crps, train_loss_step=0.618, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  66%|██████▋   | 65/98 [00:03<00:01, 17.48it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  67%|██████▋   | 66/98 [00:03<00:01, 17.57it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  68%|██████▊   | 67/98 [00:03<00:01, 17.66it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  69%|██████▉   | 68/98 [00:03<00:01, 17.76it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  70%|███████   | 69/98 [00:03<00:01, 17.84it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  71%|███████▏  | 70/98 [00:04<00:01, 17.06it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  72%|███████▏  | 71/98 [00:04<00:01, 17.16it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  73%|███████▎  | 72/98 [00:04<00:01, 17.21it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  74%|███████▍  | 73/98 [00:04<00:01, 17.30it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  76%|███████▌  | 74/98 [00:04<00:01, 17.33it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  77%|███████▋  | 75/98 [00:04<00:01, 17.35it/s, v_num=crps, train_loss_step=0.621, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  78%|███████▊  | 76/98 [00:04<00:01, 17.44it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  79%|███████▊  | 77/98 [00:04<00:01, 17.52it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  80%|███████▉  | 78/98 [00:04<00:01, 17.60it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  81%|████████  | 79/98 [00:04<00:01, 17.68it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  82%|████████▏ | 80/98 [00:04<00:01, 17.77it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  83%|████████▎ | 81/98 [00:04<00:00, 17.14it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  84%|████████▎ | 82/98 [00:04<00:00, 17.22it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  85%|████████▍ | 83/98 [00:04<00:00, 17.30it/s, v_num=crps, train_loss_step=0.583, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  86%|████████▌ | 84/98 [00:04<00:00, 17.32it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  87%|████████▋ | 85/98 [00:04<00:00, 17.40it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  88%|████████▊ | 86/98 [00:04<00:00, 17.42it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  89%|████████▉ | 87/98 [00:04<00:00, 17.47it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  90%|████████▉ | 88/98 [00:05<00:00, 17.54it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  91%|█████████ | 89/98 [00:05<00:00, 17.62it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  92%|█████████▏| 90/98 [00:05<00:00, 17.70it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  93%|█████████▎| 91/98 [00:05<00:00, 17.79it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  94%|█████████▍| 92/98 [00:05<00:00, 17.23it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  95%|█████████▍| 93/98 [00:05<00:00, 17.26it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  96%|█████████▌| 94/98 [00:05<00:00, 17.31it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  97%|█████████▋| 95/98 [00:05<00:00, 17.37it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  98%|█████████▊| 96/98 [00:05<00:00, 17.42it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.599]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 22:  99%|█████████▉| 97/98 [00:05<00:00, 17.43it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.599]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 23:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   1%|          | 1/98 [00:00<00:06, 14.11it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   2%|▏         | 2/98 [00:00<00:05, 18.55it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   3%|▎         | 3/98 [00:00<00:04, 20.80it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   4%|▍         | 4/98 [00:00<00:04, 21.49it/s, v_num=crps, train_loss_step=0.577, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   5%|▌         | 5/98 [00:00<00:07, 12.17it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   6%|▌         | 6/98 [00:00<00:07, 12.99it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   7%|▋         | 7/98 [00:00<00:06, 14.03it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   8%|▊         | 8/98 [00:00<00:06, 14.97it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:   9%|▉         | 9/98 [00:00<00:05, 15.81it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  10%|█         | 10/98 [00:00<00:05, 16.08it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  11%|█         | 11/98 [00:00<00:05, 16.74it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  12%|█▏        | 12/98 [00:00<00:04, 17.38it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  13%|█▎        | 13/98 [00:00<00:04, 17.98it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  14%|█▍        | 14/98 [00:00<00:04, 18.48it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  15%|█▌        | 15/98 [00:00<00:04, 18.97it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  16%|█▋        | 16/98 [00:01<00:05, 15.80it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  17%|█▋        | 17/98 [00:01<00:05, 16.13it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  18%|█▊        | 18/98 [00:01<00:04, 16.36it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  19%|█▉        | 19/98 [00:01<00:04, 16.73it/s, v_num=crps, train_loss_step=0.568, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  20%|██        | 20/98 [00:01<00:04, 17.10it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  21%|██▏       | 21/98 [00:01<00:04, 17.38it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  22%|██▏       | 22/98 [00:01<00:04, 17.71it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  23%|██▎       | 23/98 [00:01<00:04, 18.00it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  24%|██▍       | 24/98 [00:01<00:04, 18.27it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  26%|██▌       | 25/98 [00:01<00:03, 18.48it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  27%|██▋       | 26/98 [00:01<00:03, 18.67it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  28%|██▊       | 27/98 [00:01<00:04, 16.48it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  29%|██▊       | 28/98 [00:01<00:04, 16.68it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  30%|██▉       | 29/98 [00:01<00:04, 16.91it/s, v_num=crps, train_loss_step=0.574, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  31%|███       | 30/98 [00:01<00:04, 16.93it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  32%|███▏      | 31/98 [00:01<00:03, 17.14it/s, v_num=crps, train_loss_step=0.580, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  33%|███▎      | 32/98 [00:01<00:03, 17.26it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  34%|███▎      | 33/98 [00:01<00:03, 17.47it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  35%|███▍      | 34/98 [00:01<00:03, 17.48it/s, v_num=crps, train_loss_step=0.578, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  36%|███▌      | 35/98 [00:01<00:03, 17.66it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  37%|███▋      | 36/98 [00:02<00:03, 17.79it/s, v_num=crps, train_loss_step=0.581, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  38%|███▊      | 37/98 [00:02<00:03, 17.85it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  39%|███▉      | 38/98 [00:02<00:03, 16.57it/s, v_num=crps, train_loss_step=0.611, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  40%|███▉      | 39/98 [00:02<00:03, 16.65it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  41%|████      | 40/98 [00:02<00:03, 16.84it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  42%|████▏     | 41/98 [00:02<00:03, 17.00it/s, v_num=crps, train_loss_step=0.613, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  43%|████▎     | 42/98 [00:02<00:03, 17.17it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  44%|████▍     | 43/98 [00:02<00:03, 17.32it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  45%|████▍     | 44/98 [00:02<00:03, 17.46it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  46%|████▌     | 45/98 [00:02<00:03, 17.58it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  47%|████▋     | 46/98 [00:02<00:02, 17.71it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  48%|████▊     | 47/98 [00:02<00:02, 17.84it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  49%|████▉     | 48/98 [00:02<00:02, 17.90it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  50%|█████     | 49/98 [00:02<00:02, 16.86it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  51%|█████     | 50/98 [00:02<00:02, 17.01it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  52%|█████▏    | 51/98 [00:02<00:02, 17.16it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  53%|█████▎    | 52/98 [00:03<00:02, 17.30it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  54%|█████▍    | 53/98 [00:03<00:02, 17.35it/s, v_num=crps, train_loss_step=0.581, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  55%|█████▌    | 54/98 [00:03<00:02, 17.47it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  56%|█████▌    | 55/98 [00:03<00:02, 17.58it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  57%|█████▋    | 56/98 [00:03<00:02, 17.67it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  58%|█████▊    | 57/98 [00:03<00:02, 17.67it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  59%|█████▉    | 58/98 [00:03<00:02, 17.76it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  60%|██████    | 59/98 [00:03<00:02, 17.76it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  61%|██████    | 60/98 [00:03<00:02, 16.94it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  62%|██████▏   | 61/98 [00:03<00:02, 17.06it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  63%|██████▎   | 62/98 [00:03<00:02, 17.16it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  64%|██████▍   | 63/98 [00:03<00:02, 17.25it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  65%|██████▌   | 64/98 [00:03<00:01, 17.28it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  66%|██████▋   | 65/98 [00:03<00:01, 17.39it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  67%|██████▋   | 66/98 [00:03<00:01, 17.49it/s, v_num=crps, train_loss_step=0.580, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  68%|██████▊   | 67/98 [00:03<00:01, 17.46it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  69%|██████▉   | 68/98 [00:03<00:01, 17.56it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  70%|███████   | 69/98 [00:03<00:01, 17.62it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  71%|███████▏  | 70/98 [00:03<00:01, 17.71it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  72%|███████▏  | 71/98 [00:04<00:01, 17.03it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  73%|███████▎  | 72/98 [00:04<00:01, 17.13it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  74%|███████▍  | 73/98 [00:04<00:01, 17.14it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  76%|███████▌  | 74/98 [00:04<00:01, 17.23it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  77%|███████▋  | 75/98 [00:04<00:01, 17.27it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  78%|███████▊  | 76/98 [00:04<00:01, 17.34it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  79%|███████▊  | 77/98 [00:04<00:01, 17.36it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  80%|███████▉  | 78/98 [00:04<00:01, 17.45it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  81%|████████  | 79/98 [00:04<00:01, 17.52it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  82%|████████▏ | 80/98 [00:04<00:01, 17.60it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  83%|████████▎ | 81/98 [00:04<00:00, 17.68it/s, v_num=crps, train_loss_step=0.614, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  84%|████████▎ | 82/98 [00:04<00:00, 17.06it/s, v_num=crps, train_loss_step=0.573, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  85%|████████▍ | 83/98 [00:04<00:00, 17.05it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  86%|████████▌ | 84/98 [00:04<00:00, 17.11it/s, v_num=crps, train_loss_step=0.622, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  87%|████████▋ | 85/98 [00:04<00:00, 17.18it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  88%|████████▊ | 86/98 [00:05<00:00, 17.19it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  89%|████████▉ | 87/98 [00:05<00:00, 17.20it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  90%|████████▉ | 88/98 [00:05<00:00, 17.22it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  91%|█████████ | 89/98 [00:05<00:00, 17.30it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  92%|█████████▏| 90/98 [00:05<00:00, 17.38it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  93%|█████████▎| 91/98 [00:05<00:00, 17.47it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  94%|█████████▍| 92/98 [00:05<00:00, 17.54it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  95%|█████████▍| 93/98 [00:05<00:00, 16.96it/s, v_num=crps, train_loss_step=0.619, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  96%|█████████▌| 94/98 [00:05<00:00, 17.03it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  97%|█████████▋| 95/98 [00:05<00:00, 17.10it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  98%|█████████▊| 96/98 [00:05<00:00, 17.14it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.600]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 23:  99%|█████████▉| 97/98 [00:05<00:00, 17.16it/s, v_num=crps, train_loss_step=0.581, train_loss_epoch=0.600]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 24:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.596]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   1%|          | 1/98 [00:00<00:06, 16.02it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   2%|▏         | 2/98 [00:00<00:04, 20.16it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   3%|▎         | 3/98 [00:00<00:04, 21.79it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   4%|▍         | 4/98 [00:00<00:04, 22.95it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   5%|▌         | 5/98 [00:00<00:03, 23.71it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   6%|▌         | 6/98 [00:00<00:06, 13.73it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   7%|▋         | 7/98 [00:00<00:06, 14.27it/s, v_num=crps, train_loss_step=0.579, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   8%|▊         | 8/98 [00:00<00:05, 15.16it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:   9%|▉         | 9/98 [00:00<00:05, 15.67it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  10%|█         | 10/98 [00:00<00:05, 15.82it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  11%|█         | 11/98 [00:00<00:05, 16.43it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  12%|█▏        | 12/98 [00:00<00:05, 16.66it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  13%|█▎        | 13/98 [00:00<00:04, 17.21it/s, v_num=crps, train_loss_step=0.578, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  14%|█▍        | 14/98 [00:00<00:04, 17.70it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  15%|█▌        | 15/98 [00:00<00:04, 18.10it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  16%|█▋        | 16/98 [00:00<00:04, 18.43it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  17%|█▋        | 17/98 [00:01<00:05, 15.10it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  18%|█▊        | 18/98 [00:01<00:05, 15.22it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  19%|█▉        | 19/98 [00:01<00:05, 15.57it/s, v_num=crps, train_loss_step=0.580, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  20%|██        | 20/98 [00:01<00:04, 15.88it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  21%|██▏       | 21/98 [00:01<00:04, 16.20it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  22%|██▏       | 22/98 [00:01<00:04, 16.49it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  23%|██▎       | 23/98 [00:01<00:04, 16.67it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  24%|██▍       | 24/98 [00:01<00:04, 16.75it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  26%|██▌       | 25/98 [00:01<00:04, 16.86it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  27%|██▋       | 26/98 [00:01<00:04, 17.13it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  28%|██▊       | 27/98 [00:01<00:04, 17.28it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  29%|██▊       | 28/98 [00:01<00:04, 15.80it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  30%|██▉       | 29/98 [00:01<00:04, 15.87it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  31%|███       | 30/98 [00:01<00:04, 15.90it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  32%|███▏      | 31/98 [00:01<00:04, 16.15it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  33%|███▎      | 32/98 [00:01<00:04, 16.40it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  34%|███▎      | 33/98 [00:01<00:03, 16.56it/s, v_num=crps, train_loss_step=0.582, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  35%|███▍      | 34/98 [00:02<00:03, 16.66it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  36%|███▌      | 35/98 [00:02<00:03, 16.86it/s, v_num=crps, train_loss_step=0.586, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  37%|███▋      | 36/98 [00:02<00:03, 17.00it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  38%|███▊      | 37/98 [00:02<00:03, 17.19it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  39%|███▉      | 38/98 [00:02<00:03, 17.29it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  40%|███▉      | 39/98 [00:02<00:03, 16.12it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  41%|████      | 40/98 [00:02<00:03, 16.15it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  42%|████▏     | 41/98 [00:02<00:03, 16.22it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  43%|████▎     | 42/98 [00:02<00:03, 16.38it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  44%|████▍     | 43/98 [00:02<00:03, 16.54it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  45%|████▍     | 44/98 [00:02<00:03, 16.70it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  46%|████▌     | 45/98 [00:02<00:03, 16.85it/s, v_num=crps, train_loss_step=0.616, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  47%|████▋     | 46/98 [00:02<00:03, 16.99it/s, v_num=crps, train_loss_step=0.583, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  48%|████▊     | 47/98 [00:02<00:02, 17.14it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  49%|████▉     | 48/98 [00:02<00:02, 17.11it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  50%|█████     | 49/98 [00:02<00:02, 17.12it/s, v_num=crps, train_loss_step=0.582, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  51%|█████     | 50/98 [00:03<00:02, 16.28it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  52%|█████▏    | 51/98 [00:03<00:02, 16.43it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  53%|█████▎    | 52/98 [00:03<00:02, 16.56it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  54%|█████▍    | 53/98 [00:03<00:02, 16.58it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  55%|█████▌    | 54/98 [00:03<00:02, 16.72it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  56%|█████▌    | 55/98 [00:03<00:02, 16.77it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  57%|█████▋    | 56/98 [00:03<00:02, 16.87it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  58%|█████▊    | 57/98 [00:03<00:02, 16.95it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  59%|█████▉    | 58/98 [00:03<00:02, 17.01it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  60%|██████    | 59/98 [00:03<00:02, 17.14it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  61%|██████    | 60/98 [00:03<00:02, 17.26it/s, v_num=crps, train_loss_step=0.583, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  62%|██████▏   | 61/98 [00:03<00:02, 16.54it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  63%|██████▎   | 62/98 [00:03<00:02, 16.63it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  64%|██████▍   | 63/98 [00:03<00:02, 16.74it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  65%|██████▌   | 64/98 [00:03<00:02, 16.86it/s, v_num=crps, train_loss_step=0.594, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  66%|██████▋   | 65/98 [00:03<00:01, 16.97it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  67%|██████▋   | 66/98 [00:03<00:01, 17.08it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  68%|██████▊   | 67/98 [00:03<00:01, 17.19it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  69%|██████▉   | 68/98 [00:03<00:01, 17.29it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  70%|███████   | 69/98 [00:03<00:01, 17.31it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  71%|███████▏  | 70/98 [00:04<00:01, 17.41it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  72%|███████▏  | 71/98 [00:04<00:01, 17.51it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  73%|███████▎  | 72/98 [00:04<00:01, 16.88it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  74%|███████▍  | 73/98 [00:04<00:01, 16.92it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  76%|███████▌  | 74/98 [00:04<00:01, 17.02it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  77%|███████▋  | 75/98 [00:04<00:01, 17.07it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  78%|███████▊  | 76/98 [00:04<00:01, 17.09it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  79%|███████▊  | 77/98 [00:04<00:01, 17.19it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  80%|███████▉  | 78/98 [00:04<00:01, 17.26it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  81%|████████  | 79/98 [00:04<00:01, 17.34it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  82%|████████▏ | 80/98 [00:04<00:01, 17.36it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  83%|████████▎ | 81/98 [00:04<00:00, 17.45it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  84%|████████▎ | 82/98 [00:04<00:00, 17.50it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  85%|████████▍ | 83/98 [00:04<00:00, 16.96it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  86%|████████▌ | 84/98 [00:04<00:00, 17.04it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  87%|████████▋ | 85/98 [00:04<00:00, 17.11it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  88%|████████▊ | 86/98 [00:05<00:00, 17.20it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  89%|████████▉ | 87/98 [00:05<00:00, 17.28it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  90%|████████▉ | 88/98 [00:05<00:00, 17.30it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  91%|█████████ | 89/98 [00:05<00:00, 17.34it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  92%|█████████▏| 90/98 [00:05<00:00, 17.43it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  93%|█████████▎| 91/98 [00:05<00:00, 17.49it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  94%|█████████▍| 92/98 [00:05<00:00, 17.55it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  95%|█████████▍| 93/98 [00:05<00:00, 17.60it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  96%|█████████▌| 94/98 [00:05<00:00, 17.07it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  97%|█████████▋| 95/98 [00:05<00:00, 17.10it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  98%|█████████▊| 96/98 [00:05<00:00, 17.13it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 24:  99%|█████████▉| 97/98 [00:05<00:00, 17.20it/s, v_num=crps, train_loss_step=0.626, train_loss_epoch=0.596]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 25:   0%|          | 0/98 [00:00<?, ?it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.596]         torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   1%|          | 1/98 [00:00<00:06, 16.14it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   2%|▏         | 2/98 [00:00<00:04, 20.97it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   3%|▎         | 3/98 [00:00<00:04, 20.08it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   4%|▍         | 4/98 [00:00<00:04, 21.73it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   5%|▌         | 5/98 [00:00<00:04, 22.69it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   6%|▌         | 6/98 [00:00<00:03, 23.18it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   7%|▋         | 7/98 [00:00<00:06, 14.83it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   8%|▊         | 8/98 [00:00<00:05, 15.34it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:   9%|▉         | 9/98 [00:00<00:05, 16.23it/s, v_num=crps, train_loss_step=0.576, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  10%|█         | 10/98 [00:00<00:05, 16.85it/s, v_num=crps, train_loss_step=0.582, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  11%|█         | 11/98 [00:00<00:04, 17.40it/s, v_num=crps, train_loss_step=0.578, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  12%|█▏        | 12/98 [00:00<00:04, 18.02it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  13%|█▎        | 13/98 [00:00<00:04, 18.65it/s, v_num=crps, train_loss_step=0.582, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  14%|█▍        | 14/98 [00:00<00:04, 18.64it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  15%|█▌        | 15/98 [00:00<00:04, 19.02it/s, v_num=crps, train_loss_step=0.612, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  16%|█▋        | 16/98 [00:00<00:04, 19.41it/s, v_num=crps, train_loss_step=0.580, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  17%|█▋        | 17/98 [00:01<00:04, 16.29it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  18%|█▊        | 18/98 [00:01<00:04, 16.76it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  19%|█▉        | 19/98 [00:01<00:04, 17.15it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  20%|██        | 20/98 [00:01<00:04, 17.20it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  21%|██▏       | 21/98 [00:01<00:04, 17.38it/s, v_num=crps, train_loss_step=0.606, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  22%|██▏       | 22/98 [00:01<00:04, 17.64it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  23%|██▎       | 23/98 [00:01<00:04, 17.73it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  24%|██▍       | 24/98 [00:01<00:04, 18.02it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  26%|██▌       | 25/98 [00:01<00:04, 18.07it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  27%|██▋       | 26/98 [00:01<00:03, 18.34it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  28%|██▊       | 27/98 [00:01<00:03, 18.43it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  29%|██▊       | 28/98 [00:01<00:04, 16.69it/s, v_num=crps, train_loss_step=0.583, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  30%|██▉       | 29/98 [00:01<00:04, 16.96it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  31%|███       | 30/98 [00:01<00:03, 17.20it/s, v_num=crps, train_loss_step=0.608, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  32%|███▏      | 31/98 [00:01<00:03, 17.44it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  33%|███▎      | 32/98 [00:01<00:03, 17.67it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  34%|███▎      | 33/98 [00:01<00:03, 17.76it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  35%|███▍      | 34/98 [00:01<00:03, 17.84it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  36%|███▌      | 35/98 [00:01<00:03, 18.05it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  37%|███▋      | 36/98 [00:01<00:03, 18.26it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  38%|███▊      | 37/98 [00:02<00:03, 18.34it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  39%|███▉      | 38/98 [00:02<00:03, 17.05it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  40%|███▉      | 39/98 [00:02<00:03, 17.06it/s, v_num=crps, train_loss_step=0.609, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  41%|████      | 40/98 [00:02<00:03, 17.13it/s, v_num=crps, train_loss_step=0.582, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  42%|████▏     | 41/98 [00:02<00:03, 17.19it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  43%|████▎     | 42/98 [00:02<00:03, 17.35it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  44%|████▍     | 43/98 [00:02<00:03, 17.39it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  45%|████▍     | 44/98 [00:02<00:03, 17.55it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  46%|████▌     | 45/98 [00:02<00:02, 17.70it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  47%|████▋     | 46/98 [00:02<00:02, 17.86it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  48%|████▊     | 47/98 [00:02<00:02, 18.00it/s, v_num=crps, train_loss_step=0.575, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  49%|████▉     | 48/98 [00:02<00:02, 18.03it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  50%|█████     | 49/98 [00:02<00:02, 17.02it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  51%|█████     | 50/98 [00:02<00:02, 17.16it/s, v_num=crps, train_loss_step=0.617, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  52%|█████▏    | 51/98 [00:02<00:02, 17.29it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  53%|█████▎    | 52/98 [00:02<00:02, 17.43it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  54%|█████▍    | 53/98 [00:03<00:02, 17.48it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  55%|█████▌    | 54/98 [00:03<00:02, 17.61it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  56%|█████▌    | 55/98 [00:03<00:02, 17.74it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  57%|█████▋    | 56/98 [00:03<00:02, 17.76it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  58%|█████▊    | 57/98 [00:03<00:02, 17.85it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  59%|█████▉    | 58/98 [00:03<00:02, 17.88it/s, v_num=crps, train_loss_step=0.607, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  60%|██████    | 59/98 [00:03<00:02, 17.92it/s, v_num=crps, train_loss_step=0.597, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  61%|██████    | 60/98 [00:03<00:02, 17.09it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  62%|██████▏   | 61/98 [00:03<00:02, 17.21it/s, v_num=crps, train_loss_step=0.605, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  63%|██████▎   | 62/98 [00:03<00:02, 17.24it/s, v_num=crps, train_loss_step=0.596, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  64%|██████▍   | 63/98 [00:03<00:02, 17.29it/s, v_num=crps, train_loss_step=0.598, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  65%|██████▌   | 64/98 [00:03<00:01, 17.39it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  66%|██████▋   | 65/98 [00:03<00:01, 17.50it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  67%|██████▋   | 66/98 [00:03<00:01, 17.60it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  68%|██████▊   | 67/98 [00:03<00:01, 17.70it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  69%|██████▉   | 68/98 [00:03<00:01, 17.80it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  70%|███████   | 69/98 [00:03<00:01, 17.91it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  71%|███████▏  | 70/98 [00:03<00:01, 18.00it/s, v_num=crps, train_loss_step=0.603, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  72%|███████▏  | 71/98 [00:04<00:01, 17.31it/s, v_num=crps, train_loss_step=0.602, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  73%|███████▎  | 72/98 [00:04<00:01, 17.31it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  74%|███████▍  | 73/98 [00:04<00:01, 17.34it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  76%|███████▌  | 74/98 [00:04<00:01, 17.43it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  77%|███████▋  | 75/98 [00:04<00:01, 17.46it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  78%|███████▊  | 76/98 [00:04<00:01, 17.50it/s, v_num=crps, train_loss_step=0.584, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  79%|███████▊  | 77/98 [00:04<00:01, 17.54it/s, v_num=crps, train_loss_step=0.587, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  80%|███████▉  | 78/98 [00:04<00:01, 17.63it/s, v_num=crps, train_loss_step=0.610, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  81%|████████  | 79/98 [00:04<00:01, 17.72it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  82%|████████▏ | 80/98 [00:04<00:01, 17.81it/s, v_num=crps, train_loss_step=0.593, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  83%|████████▎ | 81/98 [00:04<00:00, 17.85it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  84%|████████▎ | 82/98 [00:04<00:00, 17.21it/s, v_num=crps, train_loss_step=0.578, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  85%|████████▍ | 83/98 [00:04<00:00, 17.25it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  86%|████████▌ | 84/98 [00:04<00:00, 17.28it/s, v_num=crps, train_loss_step=0.615, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  87%|████████▋ | 85/98 [00:04<00:00, 17.36it/s, v_num=crps, train_loss_step=0.601, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  88%|████████▊ | 86/98 [00:04<00:00, 17.39it/s, v_num=crps, train_loss_step=0.604, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  89%|████████▉ | 87/98 [00:04<00:00, 17.47it/s, v_num=crps, train_loss_step=0.585, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  90%|████████▉ | 88/98 [00:05<00:00, 17.54it/s, v_num=crps, train_loss_step=0.599, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  91%|█████████ | 89/98 [00:05<00:00, 17.56it/s, v_num=crps, train_loss_step=0.579, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  92%|█████████▏| 90/98 [00:05<00:00, 17.62it/s, v_num=crps, train_loss_step=0.600, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  93%|█████████▎| 91/98 [00:05<00:00, 17.59it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  94%|█████████▍| 92/98 [00:05<00:00, 17.66it/s, v_num=crps, train_loss_step=0.590, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  95%|█████████▍| 93/98 [00:05<00:00, 17.11it/s, v_num=crps, train_loss_step=0.589, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  96%|█████████▌| 94/98 [00:05<00:00, 17.14it/s, v_num=crps, train_loss_step=0.595, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  97%|█████████▋| 95/98 [00:05<00:00, 17.17it/s, v_num=crps, train_loss_step=0.588, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  98%|█████████▊| 96/98 [00:05<00:00, 17.25it/s, v_num=crps, train_loss_step=0.591, train_loss_epoch=0.596]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Epoch 25:  99%|█████████▉| 97/98 [00:05<00:00, 17.32it/s, v_num=crps, train_loss_step=0.592, train_loss_epoch=0.596]torch.Size([1554, 256])\n",
      "torch.Size([1554, 256])\n",
      "Epoch 25: 100%|██████████| 98/98 [00:05<00:00, 17.35it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.596]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=26` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 98/98 [00:05<00:00, 17.33it/s, v_num=crps, train_loss_step=0.624, train_loss_epoch=0.596]\n",
      "Final MSE Loss: tensor(0.6243)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▄▃▃▃▂▃▂▃▄▂▂▂▂▂▂▂▂▂▁▁▁▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>train_loss_epoch</td><td>0.59555</td></tr><tr><td>train_loss_step</td><td>0.59957</td></tr><tr><td>trainer/global_step</td><td>2547</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h_crps</strong> at: <a href='https://wandb.ai/leachen_thesis/reproduction/runs/training_run_24h_crps' target=\"_blank\">https://wandb.ai/leachen_thesis/reproduction/runs/training_run_24h_crps</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/reproduction' target=\"_blank\">https://wandb.ai/leachen_thesis/reproduction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_195843-training_run_24h_crps/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T19:01:58.132249Z",
     "start_time": "2025-03-06T19:01:57.433710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# eval (aber wo ist validate?)\n",
    "test_rf_dataset = TensorDataset(torch.Tensor(test_rf[0].to_numpy()), torch.Tensor(y_scaler.transform(test_rf[1][[\"t2m\"]])))\n",
    "test_rf_loader = DataLoader(test_rf_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "test_f_dataset = TensorDataset(torch.Tensor(test_f[0].to_numpy()), torch.Tensor(y_scaler.transform(test_f[1][[\"t2m\"]])))\n",
    "test_f_loader = DataLoader(test_f_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    log_every_n_steps=1, accelerator=\"gpu\", enable_progress_bar=True, enable_model_summary=False\n",
    ")\n",
    "preds_list = []\n",
    "\n",
    "preds = trainer.predict(model=mydrn, dataloaders=test_rf_loader)\n",
    "preds = torch.cat(preds, dim=0)\n",
    "# Reverse transform of the y_scaler (only on the mean)\n",
    "preds[:, 0] = torch.Tensor(y_scaler.inverse_transform(preds[:, 0].view(-1, 1))).flatten()\n",
    "preds_list.append(preds)\n",
    "\n",
    "targets = test_rf[1]\n",
    "targets = torch.Tensor(targets.t2m.values)\n",
    "\n",
    "stacked = torch.stack(preds_list)\n",
    "final_preds = torch.mean(stacked, dim=0)\n",
    "\n",
    "res = mydrn.loss_fn.crps(final_preds, targets)\n",
    "print(\"#############################################\")\n",
    "print(\"#############################################\")\n",
    "print(f\"final crps: {res.item()}\")\n",
    "print(\"#############################################\")\n",
    "print(\"#############################################\")"
   ],
   "id": "809c398e0bc9d694",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/19 [00:00<?, ?it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:   5%|▌         | 1/19 [00:00<00:00, 371.51it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  11%|█         | 2/19 [00:00<00:00, 93.72it/s] torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  16%|█▌        | 3/19 [00:00<00:00, 75.02it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  21%|██        | 4/19 [00:00<00:00, 68.57it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  26%|██▋       | 5/19 [00:00<00:00, 64.49it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  32%|███▏      | 6/19 [00:00<00:00, 62.66it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  37%|███▋      | 7/19 [00:00<00:00, 60.81it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  42%|████▏     | 8/19 [00:00<00:00, 24.76it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  47%|████▋     | 9/19 [00:00<00:00, 26.27it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  53%|█████▎    | 10/19 [00:00<00:00, 27.67it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  58%|█████▊    | 11/19 [00:00<00:00, 28.91it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  63%|██████▎   | 12/19 [00:00<00:00, 30.06it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  68%|██████▊   | 13/19 [00:00<00:00, 30.42it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  74%|███████▎  | 14/19 [00:00<00:00, 29.66it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  79%|███████▉  | 15/19 [00:00<00:00, 29.89it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  84%|████████▍ | 16/19 [00:00<00:00, 30.74it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  89%|████████▉ | 17/19 [00:00<00:00, 31.52it/s]torch.Size([4096, 256])\n",
      "torch.Size([4096, 256])\n",
      "Predicting DataLoader 0:  95%|█████████▍| 18/19 [00:00<00:00, 32.18it/s]torch.Size([3175, 256])\n",
      "torch.Size([3175, 256])\n",
      "Predicting DataLoader 0: 100%|██████████| 19/19 [00:00<00:00, 32.84it/s]\n",
      "#############################################\n",
      "#############################################\n",
      "final crps: 0.6234711408615112\n",
      "#############################################\n",
      "#############################################\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DRN for 72h leadtime",
   "id": "7511e79cc9e01be2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dataloader and preprocessing\n",
    "# NN object, train, test"
   ],
   "id": "303e3d78f98ff75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DRN for 120h leadtime",
   "id": "3220170569e83b0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dataloader and preprocessing\n",
    "# NN object, train, test"
   ],
   "id": "c5245e04a49a2dd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MyDRN without wandb and without saving",
   "id": "a44e0f7c4f14e32f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T00:54:14.513273Z",
     "start_time": "2025-03-01T00:51:34.099860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MyDRN train without wandb without saving\n",
    "\n",
    "y_scaler = StandardScaler(with_std=False)\n",
    "y_scaler = y_scaler.fit(train[1][[\"t2m\"]])\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.Tensor(train[0].to_numpy()), torch.Tensor(y_scaler.transform(train[1][[\"t2m\"]]))\n",
    ")\n",
    "\n",
    "#from params.json best_24h\n",
    "batch_size = 2048\n",
    "hidden_size=128\n",
    "lr=0.0002\n",
    "max_epochs=31\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "embed_dim = 20\n",
    "in_feat = train[0].shape[1] + embed_dim - 1\n",
    "\n",
    "mydrn = MyDRN(\n",
    "    hidden_size=hidden_size,\n",
    "    embedding_dim=embed_dim,\n",
    "    in_feat=in_feat,\n",
    "    optimizer_class=AdamW,\n",
    "    optimizer_params=dict(lr=lr),\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    # dirpath=SAVEPATH, filename=f\"run_{args.id}\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=50,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True,\n",
    "    callbacks=checkpoint_callback,\n",
    ")\n",
    "\n",
    "trainer.fit(model=mydrn, train_dataloaders=train_loader)\n"
   ],
   "id": "934d8d83f8e0536b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/drn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | embedding  | EmbedStations | 2.4 K  | train\n",
      "1 | linear     | Linear        | 10.9 K | train\n",
      "2 | relu       | ReLU          | 0      | train\n",
      "3 | linear_t2m | Linear        | 129    | train\n",
      "4 | loss       | MSELoss       | 0      | train\n",
      "-----------------------------------------------------\n",
      "13.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.4 K    Total params\n",
      "0.054     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 5/195 [00:00<00:05, 32.69it/s, v_num=28, train_loss_step=42.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([2048])) that is different to the input size (torch.Size([2048, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 5/195 [00:00<00:05, 34.61it/s, v_num=28, train_loss_step=41.90, train_loss_epoch=41.20]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([1554])) that is different to the input size (torch.Size([1554, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 195/195 [00:05<00:00, 37.23it/s, v_num=28, train_loss_step=39.70, train_loss_epoch=41.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=31` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 195/195 [00:05<00:00, 37.21it/s, v_num=28, train_loss_step=39.70, train_loss_epoch=41.20]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DRN with given DRN",
   "id": "fb626043627b8f87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T10:44:53.834541Z",
     "start_time": "2025-02-25T10:42:25.653661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with given models - funktioniert fuer summary statistics, aber nicht ohne? => woran liegt das?\n",
    "DIRECTORY = os.getcwd()\n",
    "JSONPATH = os.path.join(DIRECTORY, \"trained_models/drn_24h/params.json\")\n",
    "SAVEPATH = os.path.join(DIRECTORY, \"trained_models/drn_24h/models\")\n",
    "\n",
    "with open(JSONPATH, \"r\") as f:\n",
    "    print(f\"[INFO] Loading {JSONPATH}\")\n",
    "    args_dict = json.load(f)\n",
    "\n",
    "with wandb.init(\n",
    "    project=\"multigraph\",\n",
    "    # id=f\"training_run_drn_{args_dict['leadtime']}_{args.id}\",\n",
    "    id = f\"training_run_{args_dict['leadtime']}\",\n",
    "    config=args_dict,\n",
    "    tags=[\"final_training\"],\n",
    "):\n",
    "    config=wandb.config\n",
    "    dataframes = load_dataframes(mode=\"train\", leadtime=config.leadtime)\n",
    "    dataframes = summary_statistics(dataframes)\n",
    "    dataframes.pop(\"stations\")\n",
    "\n",
    "    # print(list(dataframes.values()))\n",
    "    for df in dataframes.values():\n",
    "        print(type(df))\n",
    "\n",
    "    for X, y in dataframes.values():\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "        y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train, valid_test = normalize_features(\n",
    "        training_data=dataframes[\"train\"], valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]]\n",
    "    )\n",
    "\n",
    "    print(f\"dataframes['train']: {dataframes['train']}\")\n",
    "    print(f\"train: {train}\")\n",
    "\n",
    "    train = drop_nans(train)\n",
    "\n",
    "    y_scaler = StandardScaler(with_std=False)\n",
    "    y_scaler = y_scaler.fit(train[1][[\"t2m\"]])\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.Tensor(train[0].to_numpy()), torch.Tensor(y_scaler.transform(train[1][[\"t2m\"]]))\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    embed_dim = 20 # why 20? => embed stations - instead of station_id - map into a latent vector space\n",
    "    in_channels = train[0].shape[1] + embed_dim - 1\n",
    "\n",
    "    drn = DRN(\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels=config.hidden_channels,\n",
    "        embedding_dim=embed_dim,\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config.lr),\n",
    "    )\n",
    "    wandb_logger = WandbLogger(project=\"multigraph\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        # dirpath=SAVEPATH, filename=f\"run_{args.id}\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config.max_epochs,\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "    trainer.fit(model=drn, train_dataloaders=train_loader)\n"
   ],
   "id": "ea6cdae3efed6f40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/ltchen/gnnpp/trained_models/drn_24h/params.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250225_114225-training_run_24h</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h' target=\"_blank\">training_run_24h</a></strong> to <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "[INFO] Normalizing features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/trained_models/drn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name              | Type          | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | embedding         | EmbedStations | 2.4 K  | train\n",
      "1 | linear            | ModuleList    | 21.8 K | train\n",
      "2 | last_linear_mu    | Linear        | 257    | train\n",
      "3 | last_linear_sigma | Linear        | 257    | train\n",
      "4 | relu              | ReLU          | 0      | train\n",
      "5 | softplus          | Softplus      | 0      | train\n",
      "6 | loss_fn           | NormalCRPS    | 0      | train\n",
      "------------------------------------------------------------\n",
      "24.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.7 K    Total params\n",
      "0.099     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframes['train']: (        station_id  model_orography  station_altitude  station_latitude  \\\n",
      "0                0        -0.738289         -0.764101          1.382904   \n",
      "1                1        -0.737002         -0.778600          1.016052   \n",
      "2                2        -0.731851         -0.733171          1.571141   \n",
      "3                3        -0.728793         -0.765712          1.661951   \n",
      "4                4        -0.724769         -0.761846          0.884948   \n",
      "...            ...              ...               ...               ...   \n",
      "420651         117         0.914135          0.298485         -2.911765   \n",
      "420652         118         1.443053          0.598123         -1.881973   \n",
      "420653         119         2.338639          0.646451         -2.021799   \n",
      "420654         120         4.799571          3.994016         -2.028314   \n",
      "420655         121         5.913903          4.345205         -2.201382   \n",
      "\n",
      "        station_longitude  cape_mean  cape_std   sd_mean    sd_std  stl1_mean  \\\n",
      "0               -0.895456  -0.162404 -0.211540 -0.138945 -0.130389  -0.065441   \n",
      "1               -0.891240  -0.164696 -0.233030 -0.138945 -0.130389  -0.465046   \n",
      "2               -0.829873  -0.181057 -0.231899 -0.138945 -0.130389  -0.105207   \n",
      "3               -0.630782  -0.186269 -0.245221 -0.138945 -0.130389  -0.069467   \n",
      "4               -0.708545  -0.161323 -0.233911 -0.138945 -0.130389  -0.526710   \n",
      "...                   ...        ...       ...       ...       ...        ...   \n",
      "420651          -1.659809  -0.194591 -0.269107 -0.138930 -0.130201  -0.492037   \n",
      "420652           1.430446  -0.163949 -0.223208  0.032781  0.187163  -1.013463   \n",
      "420653           1.362001  -0.102331 -0.162280  0.395475  0.354853  -1.218398   \n",
      "420654           1.636564  -0.096942 -0.130522  4.413006  6.996919  -1.389498   \n",
      "420655           1.636304   0.030651  0.044717  6.780401  8.101624  -1.560089   \n",
      "\n",
      "        ...    q_mean     q_std    u_mean     u_std    v_mean     v_std  \\\n",
      "0       ... -0.114795  1.470589 -1.416661  0.670551  1.931902  1.831306   \n",
      "1       ...  0.433324  0.358571 -0.746920  5.432942  1.666245  2.520527   \n",
      "2       ... -0.505220  1.064439 -1.522950 -0.090761  1.836820  2.540884   \n",
      "3       ... -0.754990  0.193510 -1.566283 -0.304501  1.628440  1.460403   \n",
      "4       ...  0.398675  0.609186 -0.647017  5.686270  1.696099  3.035443   \n",
      "...     ...       ...       ...       ...       ...       ...       ...   \n",
      "420651  ... -1.016872 -0.799413  0.360431 -1.581705 -0.965468 -0.314380   \n",
      "420652  ...  0.058197 -0.856260  0.196157 -0.088442 -0.267489 -1.145218   \n",
      "420653  ...  0.047738 -0.957247  0.136901 -0.865069 -0.395362 -1.303312   \n",
      "420654  ...  0.075580 -1.053509  0.060473 -0.875901 -0.419308 -1.240052   \n",
      "420655  ...  0.052665 -0.968504 -0.181117 -0.672254 -0.557093 -1.209932   \n",
      "\n",
      "          t_mean     t_std   cos_doy       sin_doy  \n",
      "0      -0.801722  0.618363  0.999407  3.442161e-02  \n",
      "1      -0.757580  1.563501  0.999407  3.442161e-02  \n",
      "2      -0.771376  0.765197  0.999407  3.442161e-02  \n",
      "3      -0.745605  0.401920  0.999407  3.442161e-02  \n",
      "4      -0.772579  0.788204  0.999407  3.442161e-02  \n",
      "...          ...       ...       ...           ...  \n",
      "420651 -0.445756 -0.222885  1.000000  6.432491e-16  \n",
      "420652 -0.731970 -1.510291  1.000000  6.432491e-16  \n",
      "420653 -0.684412 -1.302932  1.000000  6.432491e-16  \n",
      "420654 -0.665653 -1.386536  1.000000  6.432491e-16  \n",
      "420655 -0.630435 -1.469852  1.000000  6.432491e-16  \n",
      "\n",
      "[420656 rows x 65 columns],              time  station_id     t2m\n",
      "0      1997-01-02           0  277.75\n",
      "1      1997-01-02           1  279.55\n",
      "2      1997-01-02           2  276.45\n",
      "3      1997-01-02           3  275.75\n",
      "4      1997-01-02           4  279.35\n",
      "...           ...         ...     ...\n",
      "420651 2013-12-31         117  281.35\n",
      "420652 2013-12-31         118  279.35\n",
      "420653 2013-12-31         119  278.25\n",
      "420654 2013-12-31         120  273.15\n",
      "420655 2013-12-31         121  272.65\n",
      "\n",
      "[420656 rows x 3 columns])\n",
      "train: (        station_id  model_orography  station_altitude  station_latitude  \\\n",
      "0                0        -0.738289         -0.764101          1.382904   \n",
      "1                1        -0.737002         -0.778600          1.016052   \n",
      "2                2        -0.731851         -0.733171          1.571141   \n",
      "3                3        -0.728793         -0.765712          1.661951   \n",
      "4                4        -0.724769         -0.761846          0.884948   \n",
      "...            ...              ...               ...               ...   \n",
      "420651         117         0.914135          0.298485         -2.911765   \n",
      "420652         118         1.443053          0.598123         -1.881973   \n",
      "420653         119         2.338639          0.646451         -2.021799   \n",
      "420654         120         4.799571          3.994016         -2.028314   \n",
      "420655         121         5.913903          4.345205         -2.201382   \n",
      "\n",
      "        station_longitude  cape_mean  cape_std   sd_mean    sd_std  stl1_mean  \\\n",
      "0               -0.895456  -0.162404 -0.211540 -0.138945 -0.130389  -0.065441   \n",
      "1               -0.891240  -0.164696 -0.233030 -0.138945 -0.130389  -0.465046   \n",
      "2               -0.829873  -0.181057 -0.231899 -0.138945 -0.130389  -0.105207   \n",
      "3               -0.630782  -0.186269 -0.245221 -0.138945 -0.130389  -0.069467   \n",
      "4               -0.708545  -0.161323 -0.233911 -0.138945 -0.130389  -0.526710   \n",
      "...                   ...        ...       ...       ...       ...        ...   \n",
      "420651          -1.659809  -0.194591 -0.269107 -0.138930 -0.130201  -0.492037   \n",
      "420652           1.430446  -0.163949 -0.223208  0.032781  0.187163  -1.013463   \n",
      "420653           1.362001  -0.102331 -0.162280  0.395475  0.354853  -1.218398   \n",
      "420654           1.636564  -0.096942 -0.130522  4.413006  6.996919  -1.389498   \n",
      "420655           1.636304   0.030651  0.044717  6.780401  8.101624  -1.560089   \n",
      "\n",
      "        ...    q_mean     q_std    u_mean     u_std    v_mean     v_std  \\\n",
      "0       ... -0.114795  1.470589 -1.416661  0.670551  1.931902  1.831306   \n",
      "1       ...  0.433324  0.358571 -0.746920  5.432942  1.666245  2.520527   \n",
      "2       ... -0.505220  1.064439 -1.522950 -0.090761  1.836820  2.540884   \n",
      "3       ... -0.754990  0.193510 -1.566283 -0.304501  1.628440  1.460403   \n",
      "4       ...  0.398675  0.609186 -0.647017  5.686270  1.696099  3.035443   \n",
      "...     ...       ...       ...       ...       ...       ...       ...   \n",
      "420651  ... -1.016872 -0.799413  0.360431 -1.581705 -0.965468 -0.314380   \n",
      "420652  ...  0.058197 -0.856260  0.196157 -0.088442 -0.267489 -1.145218   \n",
      "420653  ...  0.047738 -0.957247  0.136901 -0.865069 -0.395362 -1.303312   \n",
      "420654  ...  0.075580 -1.053509  0.060473 -0.875901 -0.419308 -1.240052   \n",
      "420655  ...  0.052665 -0.968504 -0.181117 -0.672254 -0.557093 -1.209932   \n",
      "\n",
      "          t_mean     t_std   cos_doy       sin_doy  \n",
      "0      -0.801722  0.618363  0.999407  3.442161e-02  \n",
      "1      -0.757580  1.563501  0.999407  3.442161e-02  \n",
      "2      -0.771376  0.765197  0.999407  3.442161e-02  \n",
      "3      -0.745605  0.401920  0.999407  3.442161e-02  \n",
      "4      -0.772579  0.788204  0.999407  3.442161e-02  \n",
      "...          ...       ...       ...           ...  \n",
      "420651 -0.445756 -0.222885  1.000000  6.432491e-16  \n",
      "420652 -0.731970 -1.510291  1.000000  6.432491e-16  \n",
      "420653 -0.684412 -1.302932  1.000000  6.432491e-16  \n",
      "420654 -0.665653 -1.386536  1.000000  6.432491e-16  \n",
      "420655 -0.630435 -1.469852  1.000000  6.432491e-16  \n",
      "\n",
      "[420656 rows x 65 columns],              time  station_id     t2m\n",
      "0      1997-01-02           0  277.75\n",
      "1      1997-01-02           1  279.55\n",
      "2      1997-01-02           2  276.45\n",
      "3      1997-01-02           3  275.75\n",
      "4      1997-01-02           4  279.35\n",
      "...           ...         ...     ...\n",
      "420651 2013-12-31         117  281.35\n",
      "420652 2013-12-31         118  279.35\n",
      "420653 2013-12-31         119  278.25\n",
      "420654 2013-12-31         120  273.15\n",
      "420655 2013-12-31         121  272.65\n",
      "\n",
      "[420656 rows x 3 columns])\n",
      "Epoch 0:   0%|          | 0/52582 [12:45<?, ?it/s]it/s, v_num=_24h, train_loss_step=4.930]\n",
      "Epoch 25: 100%|██████████| 98/98 [00:05<00:00, 17.94it/s, v_num=_24h, train_loss_step=0.580, train_loss_epoch=0.597]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=26` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 98/98 [00:05<00:00, 17.92it/s, v_num=_24h, train_loss_step=0.580, train_loss_epoch=0.597]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▄▃▃▃▂▃▃▂▃▂▂▂▂▃▂▂▂▂▂▂▃▂▂▂▂▂▁▁▂▁▂▂▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>train_loss_epoch</td><td>0.59687</td></tr><tr><td>train_loss_step</td><td>0.58027</td></tr><tr><td>trainer/global_step</td><td>2547</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h</strong> at: <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250225_114225-training_run_24h/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T21:46:57.285357Z",
     "start_time": "2025-03-01T21:46:57.027801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ],
   "id": "ec3a3aae4f779f81",
   "outputs": [],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
