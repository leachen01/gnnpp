{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GNNs",
   "id": "1b2003274c1cd59b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GNNs with StatQuest",
   "id": "df87b9ce9383f46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T19:50:41.634339Z",
     "start_time": "2025-03-18T19:50:41.629057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.utilities.types import OptimizerLRScheduler\n",
    "from torch.optim import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pytorch_lightning as L\n",
    "from torch.utils.data import DataLoader\n"
   ],
   "id": "c0c1ee9389756fb0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BasicNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n"
   ],
   "id": "af292ac09ef93b1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create optimiizer\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# for loop for gradient descent\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for iteration in range(len(inputs)):\n",
    "        input_i = inputs[iteration]\n",
    "        label_i = labels[iteration]\n",
    "\n",
    "        output_i = model(input_i)\n",
    "        loss = (output_i - labels_i)**2\n",
    "        loss.backward()\n",
    "        total_loss += float(loss)\n",
    "\n",
    "    if total_loss < 0.0001:\n",
    "        print(\"num steps: \", epoch)\n",
    "        break\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad() # without this, would add new derivative to the derivatives of the previous loop\n",
    "print(f\"total loss: {total_loss}, final bias: \")"
   ],
   "id": "1a2e7078160deb23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BasicLight(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super.__init__()\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "\n",
    "        #new!\n",
    "        self.learning_rate = 0.01\n",
    "    def forward(self, input)\n",
    "        input_to_top_relu = input * self.w00 + self.b00\n",
    "        #...\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return SGD(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_i, label_i = batch\n",
    "        output_i = self.forward(input_i)\n",
    "        loss = (output_i - label_i)**2\n",
    "        return loss\n"
   ],
   "id": "efbf13b16d68439e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# wrap training data in dataloader!\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset)\n",
    "#easier access for batches, possibility to shuffle data each epoch, easy for small fraction of data for debugging"
   ],
   "id": "b809f22332eef4d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = BasicLight()\n",
    "trainer = L.Trainer(max_epochs=34)\n",
    "trainer.fit(model, dataloader) # automatically calls zero_grad, backward, optimizer.step; then calls training_step again!"
   ],
   "id": "70403575fec7f5f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# gpu accelerator",
   "id": "1e7f7e3d28bce3d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GNN with Planetoid - translate into Lightning",
   "id": "66e49e70a1515c85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:47:42.435232Z",
     "start_time": "2025-03-18T18:47:41.797241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pytorch_lightning as L"
   ],
   "id": "3bc5ff97b3f7a9e8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:47:52.627984Z",
     "start_time": "2025-03-18T18:47:52.599334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = Planetoid(root=\"tutorial1\", name=\"Cora\")\n",
    "train_loader = DataLoader(dataset, batch_size=15, shuffle=True)\n",
    "print(len(dataset))\n",
    "print(dataset.data.num_nodes)\n",
    "print(dataset.num_node_features)\n",
    "print(dataset.data)\n",
    "print(dataset.data.y)\n",
    "data = dataset[0]"
   ],
   "id": "8697d72261a8853a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2708\n",
      "1433\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "tensor([3, 4, 4,  ..., 3, 3, 3])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T20:03:24.766773Z",
     "start_time": "2025-03-18T20:03:24.735870Z"
    }
   },
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T20:03:27.281269Z",
     "start_time": "2025-03-18T20:03:26.359876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ],
   "id": "e4942301cbfdbbd0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T20:03:28.076932Z",
     "start_time": "2025-03-18T20:03:28.060941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ],
   "id": "5d86a05fd51c103b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7910\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Lightning approach\n",
    "- optimizes learning rate\n",
    "- simplifies the training loops\n",
    "- TPU and GPU approach\n",
    "\n",
    "Possibilities to change: DataModule (instead of lists use Datasets?)"
   ],
   "id": "abd863dd02f4a683"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LightNN(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, output, y = self._common_step(batch, batch_idx)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, output, y = self._common_step(batch, batch_idx)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, output, y = self._common_step(batch, batch_idx)\n",
    "        return loss\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self.forward(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        return loss, output, y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "4a8ed2ddae3b1ac6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = BasicLight()\n",
    "trainer = L.Trainer(model, max_epochs=34)"
   ],
   "id": "4da6c94d1f456c5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
