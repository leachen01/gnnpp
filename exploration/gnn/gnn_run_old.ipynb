{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:56:17.482105Z",
     "start_time": "2025-04-15T01:56:13.803651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%cd /home/ltchen/gnnpp\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torch_geometric\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.utils import scatter\n",
    "from torch.nn import Linear, ModuleList, ReLU\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.optim import AdamW\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from models.loss import NormalCRPS\n",
    "from models.model_utils import MakePositive, EmbedStations\n",
    "from models.graphensemble.multigraph import *\n",
    "from utils.data import (\n",
    "    load_dataframes,\n",
    "    load_distances,\n",
    "    normalize_features_and_create_graphs,\n",
    "    rm_edges,\n",
    "    summary_statistics,\n",
    ")\n",
    "from exploration.graph_creation import *"
   ],
   "id": "7a72cc47a3f90c32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:56:17.494867Z",
     "start_time": "2025-04-15T01:56:17.489351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "SAVEPATH = os.path.join(DIRECTORY, \"explored_models/gnn_24h/models\")\n",
    "JSONPATH = os.path.join(DIRECTORY, \"trained_models/best_24h/params.json\")"
   ],
   "id": "f9b587b1ca8953b6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:56:17.610761Z",
     "start_time": "2025-04-15T01:56:17.604309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(JSONPATH, \"r\") as f:\n",
    "    print(f\"[INFO] Loading {JSONPATH}\")\n",
    "    args_dict = json.load(f)\n",
    "config = args_dict\n",
    "print(config)\n",
    "print(config['lr'])\n",
    "print(config['max_dist'])\n",
    "print(type(config))\n",
    "print(type(config['lr']))\n",
    "print(type(config['gnn_hidden']))\n",
    "'''{\"batch_size\":8,\n",
    "\"gnn_hidden\":265,\n",
    "\"gnn_layers\":2,\n",
    "\"heads\":8,\n",
    "\"lr\":0.0002,\n",
    "\"max_dist\":100,\n",
    "\"max_epochs\": 31}'''"
   ],
   "id": "a21cd6960e3d25fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/ltchen/gnnpp/trained_models/best_24h/params.json\n",
      "{'batch_size': 8, 'gnn_hidden': 265, 'gnn_layers': 2, 'heads': 8, 'lr': 0.0002, 'max_dist': 100, 'max_epochs': 31}\n",
      "0.0002\n",
      "100\n",
      "<class 'dict'>\n",
      "<class 'float'>\n",
      "<class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"batch_size\":8,\\n\"gnn_hidden\":265,\\n\"gnn_layers\":2,\\n\"heads\":8,\\n\"lr\":0.0002,\\n\"max_dist\":100,\\n\"max_epochs\": 31}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:56:24.944405Z",
     "start_time": "2025-04-15T01:56:19.578203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load graph only for rf\n",
    "dataframes = load_dataframes(mode=\"eval\", leadtime= \"24h\")\n",
    "dataframes = summary_statistics(dataframes)\n",
    "dist = load_distances(dataframes[\"stations\"])\n"
   ],
   "id": "c9e52c29f737905a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n",
      "[INFO] Loading distances from file...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GNN Architecture",
   "id": "102eda0f19a9c8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:56:24.967452Z",
     "start_time": "2025-04-15T01:56:24.950236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gnn architecture\n",
    "class DeepSetAggregator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(DeepSetAggregator, self).__init__()\n",
    "\n",
    "        self.input = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        self.hidden1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.hidden2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.output = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, index):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        # print(f\"Input: {x.shape}\")\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        # print(f\"Hidden1: {x.shape}\")\n",
    "        x = scatter(x, index, dim=0, reduce=\"mean\")\n",
    "        # print(f\"scatter: {x.shape}\")\n",
    "        # print(f\"index: {index}\")\n",
    "        self.hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        # print(f\"Hidden2: {x.shape}\")\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResGnn(torch.nn.Module):\n",
    "    def __init__(self, edge_dim: int, in_channels: int, out_channels: int, num_layers: int, hidden_channels: int, heads: int):\n",
    "        super(ResGnn, self).__init__()\n",
    "        assert num_layers > 0, \"num_layers must be > 0.\"\n",
    "\n",
    "        # Create Layers\n",
    "        self.convolutions = ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convolutions.append(\n",
    "                GATv2Conv(-1, hidden_channels, heads=heads, edge_dim=edge_dim, add_self_loops=True, fill_value=0.01)\n",
    "            )\n",
    "        self.lin = Linear(hidden_channels * heads, out_channels)\n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.float()\n",
    "        edge_attr = edge_attr.float()\n",
    "        for i, conv in enumerate(self.convolutions):\n",
    "            if i == 0:\n",
    "                # First Layer\n",
    "                x = conv(x, edge_index, edge_attr)\n",
    "                x = self.relu(x)\n",
    "            else:\n",
    "                x = x + self.relu(conv(x, edge_index, edge_attr))  # Residual Layers\n",
    "\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attention(\n",
    "        self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Runs a forward Pass for the given graph only though the ResGNN layer.\n",
    "        NOTE: the data that is given to this method must first pass through the layers before this layer in the Graph\n",
    "\n",
    "        :param torch.Tensor x: Tensor of Node Features (NxD)\n",
    "        :param torch.Tensor edge_index: Tensor of Edges (2xE)\n",
    "        :param torch.Tensor edge_attr: Edge Attributes (ExNum_Attr)\n",
    "        :return x, edge_index_attention, attention_weights: Tensor of Node Features (NxD), Tensor of Edges with\n",
    "        self loops (2xE), Tensor of Attention per edge (ExNum_Heads)\n",
    "        \"\"\"\n",
    "        x = x.float()\n",
    "        edge_attr = edge_attr.float()\n",
    "\n",
    "        # Pass Data though Layer to get the Attention\n",
    "        attention_list = []\n",
    "        # Note: edge_index_attention has to be added since we have self loops now\n",
    "        edge_index_attention, attention_weights = None, None\n",
    "\n",
    "        for i, conv in enumerate(\n",
    "            self.convolutions,\n",
    "        ):\n",
    "            if i == 0:\n",
    "                # First Layer\n",
    "                x, (edge_index_attention, attention_weights) = conv(\n",
    "                    x, edge_index, edge_attr, return_attention_weights=True\n",
    "                )\n",
    "                # print(\"attention_weights:\")\n",
    "                # print(attention_weights)\n",
    "                # print(\"edge_index_attention\")\n",
    "                # print(edge_index_attention)\n",
    "                # print(f\"attention_weights.shape{attention_weights.shape}\")\n",
    "                # print(f\"type(attention_weights){type(attention_weights)}\")\n",
    "                attention_list.append(attention_weights)\n",
    "                x = self.relu(x)\n",
    "                x = self.norm(x)\n",
    "            else:\n",
    "                x_conv, (edge_index_attention, attention_weights) = conv(\n",
    "                    x, edge_index, edge_attr, return_attention_weights=True\n",
    "                )\n",
    "                attention_list.append(attention_weights)\n",
    "                x = x + self.relu(x_conv)  # Residual Layers\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Attention weights of first layer\n",
    "        attention_weights = attention_weights.mean(dim=1)\n",
    "        # print(\"attention_weights.mean(dim=1)\")\n",
    "        # print(attention_weights)\n",
    "        # print(attention_weights.shape)\n",
    "\n",
    "        return x, edge_index_attention, attention_weights, attention_list\n",
    "\n",
    "# gnn architecture\n",
    "class ThisMultigraph(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        edge_dim,\n",
    "        in_channels,\n",
    "        hidden_channels_gnn,\n",
    "        out_channels_gnn,\n",
    "        num_layers_gnn,\n",
    "        heads,\n",
    "        hidden_channels_deepset,\n",
    "        optimizer_class,\n",
    "        optimizer_params,\n",
    "    ):\n",
    "        super(ThisMultigraph, self).__init__()\n",
    "\n",
    "        self.encoder = EmbedStations(num_stations_max=122, embedding_dim=embedding_dim)\n",
    "\n",
    "        self.conv = ResGnn(\n",
    "            edge_dim=edge_dim,\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels_gnn,\n",
    "            out_channels=out_channels_gnn,\n",
    "            num_layers=num_layers_gnn,\n",
    "            heads=heads,\n",
    "        )\n",
    "\n",
    "        self.aggr = DeepSetAggregator(\n",
    "            in_channels=out_channels_gnn, hidden_channels=hidden_channels_deepset, out_channels=2\n",
    "        )\n",
    "\n",
    "        self.postprocess = MakePositive()\n",
    "        self.loss_fn = NormalCRPS()\n",
    "\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch_id, node_idx = data.x, data.edge_index, data.edge_attr, data.batch, data.n_idx\n",
    "        node_idx = node_idx + batch_id * 122  # add batch_id to node_idx to get unique node indices\n",
    "        x = self.encoder(x)\n",
    "        x = self.conv(x, edge_index, edge_attr)\n",
    "        x = self.aggr(x, node_idx)\n",
    "        x = self.postprocess(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=1\n",
    "        )  # The batch size is not actually 1 but the loss is already averaged over the batch\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.parameters(), **self.optimizer_params)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        return loss\n",
    "\n",
    "    def initialize(self, dataloader):\n",
    "        batch = next(iter(dataloader))\n",
    "        self.validation_step(batch, 0)"
   ],
   "id": "4b0c09236490cd26",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check DeepSetAggregator and ResGNN outside of Multigraph",
   "id": "b25f56cbcc8e7dcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:58:26.276082Z",
     "start_time": "2025-04-15T01:58:06.359644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    training_data=dataframes[\"train\"],\n",
    "    valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    mat=dist,\n",
    "    max_dist=config['max_dist'],\n",
    ")\n",
    "graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "graphs_test = graphs_test_rf\n",
    "\n",
    "# print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n",
    "\n",
    "print(\"[INFO] Creating data loaders...\")\n",
    "train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "print(\"[INFO] Creating model...\")\n",
    "emb_dim=20\n",
    "in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1\n"
   ],
   "id": "eb207df0bf6978e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "[INFO] Creating graph data...\n",
      "[INFO] Creating data loaders...\n",
      "[INFO] Creating model...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:58:26.326732Z",
     "start_time": "2025-04-15T01:58:26.323107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_dim=emb_dim\n",
    "in_channels=in_channels\n",
    "hidden_channels_gnn=config['gnn_hidden']\n",
    "out_channels_gnn=config['gnn_hidden']\n",
    "num_layers_gnn=config['gnn_hidden']\n",
    "heads=config['heads']\n",
    "hidden_channels_deepset=config['gnn_hidden']\n",
    "optimizer_class=AdamW\n",
    "optimizer_params=dict(lr=config['lr'])\n"
   ],
   "id": "b977193b0cc8f5a6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train GNN",
   "id": "d2a71ee480a1bedb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:27:29.628774Z",
     "start_time": "2025-04-14T19:27:25.953206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train gnn\n",
    "# build a graph with wandb => create multigraph - without summmary_statistics and no edges removed\n",
    "with wandb.init(\n",
    "    project=\"multigraph\", id=f\"training_run_24h_2\", config=args_dict, tags=[\"final_training\"]\n",
    "):\n",
    "    config = wandb.config\n",
    "    #print(\"[INFO] Starting sweep with config: \", config)\n",
    "\n",
    "    # graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    #     training_data=dataframes[\"train\"],\n",
    "    #     valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    #     mat=dist,\n",
    "    #     max_dist=config['max_dist'],\n",
    "    # )\n",
    "    # graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "    # graphs_test = graphs_test_rf\n",
    "\n",
    "    # print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n",
    "\n",
    "    # print(\"[INFO] Creating data loaders...\")\n",
    "    # train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    # print(\"[INFO] Creating model...\")\n",
    "    # emb_dim=20\n",
    "    # in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1 #(36 + 20 - 1) = 55\n",
    "\n",
    "    multigraph = ThisMultigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph)\n",
    "\n",
    "    # understand what this is\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch  # .to(\"cuda\")\n",
    "    multigraph  # .to(\"cuda\")\n",
    "    multigraph.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"multigraph\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    # print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph, train_dataloaders=train_loader)\n",
    "wandb.finish()"
   ],
   "id": "38ba57bc26ec34e8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mleachen\u001B[0m (\u001B[33mleachen_thesis\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250414_212726-training_run_24h_2</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_2' target=\"_blank\">training_run_24h_2</a></strong> to <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_2' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_2</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1596851/2006439172.py\", line 29, in <module>\n",
      "    multigraph = ThisMultigraph(\n",
      "TypeError: ThisMultigraph.__init__() missing 1 required positional argument: 'edge_dim'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h_2</strong> at: <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_2' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_2</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_212726-training_run_24h_2/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "ThisMultigraph.__init__() missing 1 required positional argument: 'edge_dim'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 29\u001B[0m\n\u001B[1;32m      6\u001B[0m config \u001B[38;5;241m=\u001B[39m wandb\u001B[38;5;241m.\u001B[39mconfig\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#print(\"[INFO] Starting sweep with config: \", config)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# graphs_train_rf, tests = normalize_features_and_create_graphs(\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# emb_dim=20\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1 #(36 + 20 - 1) = 55\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m multigraph \u001B[38;5;241m=\u001B[39m \u001B[43mThisMultigraph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43memb_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_channels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_channels_gnn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgnn_hidden\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m    \u001B[49m\u001B[43mout_channels_gnn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgnn_hidden\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_layers_gnn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgnn_layers\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mheads\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_channels_deepset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgnn_hidden\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAdamW\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m torch\u001B[38;5;241m.\u001B[39mcompile(multigraph)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# understand what this is\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: ThisMultigraph.__init__() missing 1 required positional argument: 'edge_dim'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T23:22:30.120578Z",
     "start_time": "2025-04-13T23:15:18.614908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with wandb.init(\n",
    "    project=\"multigraph\", id=f\"training_run_24h_4\", config=args_dict, tags=[\"final_training\"], reinit=True\n",
    "):\n",
    "    config = wandb.config\n",
    "    edge_dim = 1\n",
    "    #print(\"[INFO] Starting sweep with config: \", config)\n",
    "\n",
    "    # graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    #     training_data=dataframes[\"train\"],\n",
    "    #     valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    #     mat=dist,\n",
    "    #     max_dist=config['max_dist'],\n",
    "    # )\n",
    "    # graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "    # graphs_test = graphs_test_rf\n",
    "\n",
    "    # print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n",
    "\n",
    "    # print(\"[INFO] Creating data loaders...\")\n",
    "    # train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    # print(\"[INFO] Creating model...\")\n",
    "    # emb_dim=20\n",
    "    # in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1 #(36 + 20 - 1) = 55\n",
    "\n",
    "    multigraph2 = Multigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph2)\n",
    "\n",
    "    # understand what this is\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch  # .to(\"cuda\")\n",
    "    multigraph2  # .to(\"cuda\")\n",
    "    multigraph2.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"multigraph\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    # print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph2, train_dataloaders=train_loader)\n",
    "wandb.finish()"
   ],
   "id": "cc5ea43f19dec856",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250414_011518-training_run_24h_4</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4' target=\"_blank\">training_run_24h_4</a></strong> to <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/gnn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.571    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:13<00:00, 31.66it/s, v_num=4h_4, train_loss_step=0.510, train_loss_epoch=0.515]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=31` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:13<00:00, 31.65it/s, v_num=4h_4, train_loss_step=0.510, train_loss_epoch=0.515]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▇▃▄▅▅▃▄▃▄▄▄▃▂▂▃▃▃▃▃▅▅▃▂▃▄▄▂▂▃▂▁▁▁▁▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_loss_epoch</td><td>0.51528</td></tr><tr><td>train_loss_step</td><td>0.51018</td></tr><tr><td>trainer/global_step</td><td>13360</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h_4</strong> at: <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_011518-training_run_24h_4/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:57:02.717440Z",
     "start_time": "2025-04-15T01:56:34.286564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l_graphs_train_rf, l_tests = normalize_features_and_create_graphs1(df_train=dataframes['train'], df_valid_test=[dataframes['test_rf'], dataframes['test_f']], station_df=dataframes['stations'], attributes=[\"geo\"], edges=[(\"geo\", 100)], sum_stats = True)\n",
    "l_graphs_test_rf, l_graphs_test_f = l_tests\n",
    "l_graphs_test = l_graphs_test_rf\n",
    "\n",
    "l_train_loader = DataLoader(l_graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "print(l_graphs_train_rf[0].num_edge_features)"
   ],
   "id": "55c030c8b9f1733a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n",
      "transform 2\n",
      "[INFO] Converting temperature values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3448/3448 [00:16<00:00, 207.67it/s]\n",
      "100%|██████████| 732/732 [00:02<00:00, 281.24it/s]\n",
      "100%|██████████| 730/730 [00:02<00:00, 264.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:57:02.727771Z",
     "start_time": "2025-04-15T01:57:02.722665Z"
    }
   },
   "cell_type": "code",
   "source": "l_graphs_train_rf[0].y",
   "id": "4b07e8bab02b0a41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.6000,  6.4000,  3.3000,  2.6000,  6.2000,  3.3000,  4.3000,  2.1000,\n",
       "         3.1000,  4.8000,  1.2000,  3.1000,  2.1000,  1.1000,  3.4000, -0.5000,\n",
       "         2.5000,  8.9000,  8.7000,     nan,  8.3000,  8.8000,  8.3000,  6.9000,\n",
       "         7.9000,  6.7000,  7.4000,  6.1000,  8.6000,  5.8000,  5.7000, -4.6000,\n",
       "        -3.2000, -4.6000,     nan, -2.0000,  5.6000,  5.9000, -1.5000,  2.7000,\n",
       "         7.8000,  2.7000,  2.9000,  0.9000, -1.2000,  2.4000, -3.7000,  0.4000,\n",
       "        -2.4000,  1.3000, -0.2000, -0.1000,  2.1000,  4.3000,  5.1000,  6.7000,\n",
       "        -3.3000,  1.6000,  2.4000,  0.0000, -1.0000, -0.1000,     nan,  5.1000,\n",
       "         0.3000,  3.5000,  6.0000,  1.1000, -5.2000,  1.7000,  3.9000,  3.0000,\n",
       "         5.4000,  6.8000,     nan, -3.2000,  4.2000,  0.4000, -1.2000,  1.6000,\n",
       "         5.2000,  9.6000,  8.8000,  8.5000,  9.1000,  8.4000,  8.3000,  8.8000,\n",
       "         8.9000,  8.7000,  7.6000,  6.9000,  8.7000,  7.8000,  6.7000,  6.3000,\n",
       "         7.4000,  7.1000,  8.2000,  8.0000,  6.7000,  4.5000,  8.5000,  7.4000,\n",
       "         7.5000,  6.1000,  5.2000,  3.8000,  4.5000,  5.6000,  8.6000,  8.0000,\n",
       "         7.0000,  6.2000,  5.9000,  5.7000,  5.8000,  6.3000,  4.2000,  3.2000,\n",
       "        -0.8000, -0.7000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T02:06:07.747931Z",
     "start_time": "2025-04-15T01:58:31.455616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with wandb.init(\n",
    "    project=\"multigraph\", id=f\"training_run_24h_10\", config=args_dict, tags=[\"final_training\"], reinit=True\n",
    "):\n",
    "    config = wandb.config\n",
    "    edge_dim = l_graphs_train_rf[0].num_edge_features\n",
    "    #print(\"[INFO] Starting sweep with config: \", config)\n",
    "\n",
    "    # graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    #     training_data=dataframes[\"train\"],\n",
    "    #     valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    #     mat=dist,\n",
    "    #     max_dist=config['max_dist'],\n",
    "    # )\n",
    "    # graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "    # graphs_test = graphs_test_rf\n",
    "\n",
    "    # print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n",
    "\n",
    "    # print(\"[INFO] Creating data loaders...\")\n",
    "    # train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    # print(\"[INFO] Creating model...\")\n",
    "    # emb_dim=20\n",
    "    # in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1 #(36 + 20 - 1) = 55\n",
    "\n",
    "    multigraph3 = Multigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph3)\n",
    "\n",
    "    # understand what this is\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch  # .to(\"cuda\")\n",
    "    # multigraph3  # .to(\"cuda\")\n",
    "    multigraph3.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"multigraph\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    # print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph3, train_dataloaders=l_train_loader)\n",
    "wandb.finish()"
   ],
   "id": "2e45cf05cf1cc24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250415_035831-training_run_24h_10</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10' target=\"_blank\">training_run_24h_10</a></strong> to <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/gnn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.571    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:15<00:00, 28.58it/s, v_num=h_10, train_loss_step=0.473, train_loss_epoch=0.486]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=31` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:15<00:00, 28.01it/s, v_num=h_10, train_loss_step=0.473, train_loss_epoch=0.486]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▆▇▄▆▅▄▅▅▂▅▃▄▂▃▃▃▂▃▃▃▄▃▂▁▁▂▂▁▂▂▂▃▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_loss_epoch</td><td>0.48608</td></tr><tr><td>train_loss_step</td><td>0.47318</td></tr><tr><td>trainer/global_step</td><td>13360</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h_10</strong> at: <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250415_035831-training_run_24h_10/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T23:12:31.769535Z",
     "start_time": "2025-04-13T23:12:27.218993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate gnn\n",
    "test_loader = DataLoader(graphs_test, batch_size=1, shuffle=False)\n",
    "\n",
    "# multigraph.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "# trainer = L.Trainer(log_every_n_steps=1, accelerator=\"gpu\", devices=1, enable_progress_bar=True)\n",
    "preds_list = []\n",
    "preds = trainer.predict(model=multigraph, dataloaders=[test_loader])\n"
   ],
   "id": "649e4aadb19512f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 732/732 [00:04<00:00, 163.12it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:59:03.460154Z",
     "start_time": "2025-04-03T17:59:03.414629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds = [prediction.reshape(1, 122, 2).mean(axis=0) for prediction in preds] #ACHTUNG - reshape(1, 122, 2) mit 1 statt 5!\n",
    "preds = torch.cat(preds, dim=0)\n",
    "preds_list.append(preds)\n",
    "\n",
    "targets = dataframes[\"test_rf\"][1]\n",
    "targets = torch.tensor(targets.t2m.values) - 273.15\n",
    "\n",
    "stacked = torch.stack(preds_list)\n",
    "final_preds = torch.mean(stacked, dim=0)\n",
    "\n",
    "res = multigraph.loss_fn.crps(final_preds, targets)\n",
    "print(\"#############################################\")\n",
    "print(\"#############################################\")\n",
    "print(f\"final crps: {res.item()}\")\n",
    "print(\"#############################################\")\n",
    "print(\"#############################################\")\n"
   ],
   "id": "2525dcc85239cc4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "#############################################\n",
      "final crps: 0.6189641812120212\n",
      "#############################################\n",
      "#############################################\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:58:22.905772Z",
     "start_time": "2025-04-03T17:58:22.896280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for prediction in preds:\n",
    "    print(prediction.shape)"
   ],
   "id": "65de3e43231fce44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T03:00:22.392550Z",
     "start_time": "2025-03-11T03:00:22.105868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "3315937a70662a07",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
