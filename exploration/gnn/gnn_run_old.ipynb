{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:00:39.140852Z",
     "start_time": "2025-05-20T18:00:35.822742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%cd /home/ltchen/gnnpp\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torch_geometric\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.utils import scatter\n",
    "from torch.nn import Linear, ModuleList, ReLU\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.optim import AdamW\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from models.loss import NormalCRPS\n",
    "from models.model_utils import MakePositive, EmbedStations\n",
    "from models.graphensemble.multigraph import *\n",
    "from utils.data import (\n",
    "    load_dataframes,\n",
    "    load_distances,\n",
    "    normalize_features_and_create_graphs,\n",
    "    rm_edges,\n",
    "    summary_statistics,\n",
    ")\n",
    "from exploration.graph_creation import *"
   ],
   "id": "7a72cc47a3f90c32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:00:39.168151Z",
     "start_time": "2025-05-20T18:00:39.164119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "SAVEPATH = os.path.join(DIRECTORY, \"explored_models/gnn_24h/models\")\n",
    "JSONPATH = os.path.join(DIRECTORY, \"trained_models/no_ensemble_24h/params.json\")"
   ],
   "id": "f9b587b1ca8953b6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:00:39.316846Z",
     "start_time": "2025-05-20T18:00:39.300333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(JSONPATH, \"r\") as f:\n",
    "    print(f\"[INFO] Loading {JSONPATH}\")\n",
    "    args_dict = json.load(f)\n",
    "config = args_dict\n",
    "print(config)\n",
    "print(config['lr'])\n",
    "print(config['max_dist'])\n",
    "print(type(config))\n",
    "print(type(config['lr']))\n",
    "print(type(config['gnn_hidden']))\n",
    "'''{\"batch_size\":8,\n",
    "\"gnn_hidden\":265,\n",
    "\"gnn_layers\":2,\n",
    "\"heads\":8,\n",
    "\"lr\":0.0002,\n",
    "\"max_dist\":100,\n",
    "\"max_epochs\": 31}'''"
   ],
   "id": "a21cd6960e3d25fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/ltchen/gnnpp/trained_models/no_ensemble_24h/params.json\n",
      "{'batch_size': 8, 'gnn_hidden': 256, 'gnn_layers': 1, 'heads': 8, 'lr': 0.0001, 'max_dist': 50, 'max_epochs': 23, 'remove_edges': 'False', 'only_summary': 'True'}\n",
      "0.0001\n",
      "50\n",
      "<class 'dict'>\n",
      "<class 'float'>\n",
      "<class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"batch_size\":8,\\n\"gnn_hidden\":265,\\n\"gnn_layers\":2,\\n\"heads\":8,\\n\"lr\":0.0002,\\n\"max_dist\":100,\\n\"max_epochs\": 31}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:00:45.919613Z",
     "start_time": "2025-05-20T18:00:40.792060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load graph only for rf\n",
    "dataframes = load_dataframes(leadtime= \"24h\")\n",
    "dataframes = summary_statistics(dataframes)\n",
    "dist = load_distances(dataframes[\"stations\"])\n"
   ],
   "id": "c9e52c29f737905a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for valid\n",
      "[INFO] Calculating summary statistics for test_rf\n",
      "[INFO] Calculating summary statistics for test_f\n",
      "[INFO] Loading distances from file...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T20:35:27.383247Z",
     "start_time": "2025-05-20T20:35:27.348848Z"
    }
   },
   "cell_type": "code",
   "source": "dataframes['valid']",
   "id": "d00ccb2232c8e84b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(             time  station_id  model_orography  station_altitude  \\\n",
       " 0      2010-01-01           0        -1.706008               1.2   \n",
       " 1      2010-01-01           1        -1.298122              -3.3   \n",
       " 2      2010-01-01           2         0.333424              10.8   \n",
       " 3      2010-01-01           3         1.302155               0.7   \n",
       " 4      2010-01-01           4         2.576800               1.9   \n",
       " ...           ...         ...              ...               ...   \n",
       " 100315 2013-12-31         115       521.714299             331.0   \n",
       " 100316 2013-12-31         116       689.253673             424.0   \n",
       " 100317 2013-12-31         117       972.938723             439.0   \n",
       " 100318 2013-12-31         118      1752.460782            1478.0   \n",
       " 100319 2013-12-31         119      2105.435549            1587.0   \n",
       " \n",
       "         station_latitude  station_longitude  cape_mean   cape_std  \\\n",
       " 0              52.928000           4.781000  18.895952  17.770164   \n",
       " 1              52.318000           4.790000   7.626776   9.146333   \n",
       " 2              53.241000           4.921000  26.177202  18.602741   \n",
       " 3              53.392000           5.346000  24.958807  15.335708   \n",
       " 4              52.100000           5.180000   9.027344  11.750383   \n",
       " ...                  ...                ...        ...        ...   \n",
       " 100315         45.786833           3.149333   0.003196   0.010600   \n",
       " 100316         47.499168           9.746111   2.700639   2.020160   \n",
       " 100317         47.266666           9.600000   8.125000   4.687785   \n",
       " 100318         47.255833          10.186111   8.599432   6.078244   \n",
       " 100319         46.968056          10.185555  19.831676  13.750692   \n",
       " \n",
       "              sd_mean        sd_std  ...       z_std    q_mean     q_std  \\\n",
       " 0       0.000000e+00  0.000000e+00  ...  233.720965  0.000923  0.000163   \n",
       " 1       1.712279e-05  2.254129e-05  ...  223.497956  0.001203  0.000194   \n",
       " 2       0.000000e+00  0.000000e+00  ...  221.081788  0.000929  0.000132   \n",
       " 3       0.000000e+00  0.000000e+00  ...  209.020909  0.000938  0.000120   \n",
       " 4       4.304539e-05  6.093826e-05  ...  207.410195  0.001481  0.000302   \n",
       " ...              ...           ...  ...         ...       ...       ...   \n",
       " 100315  3.467907e-07  4.313154e-07  ...   33.157288  0.000649  0.000127   \n",
       " 100316  3.792589e-03  7.249709e-04  ...   33.167545  0.002231  0.000112   \n",
       " 100317  1.180272e-02  1.107808e-03  ...   32.975823  0.002215  0.000086   \n",
       " 100318  1.005302e-01  1.627163e-02  ...   32.577671  0.002256  0.000061   \n",
       " 100319  1.528143e-01  1.879367e-02  ...   33.428761  0.002223  0.000083   \n",
       " \n",
       "            u_mean     u_std    v_mean     v_std      t_mean     t_std  number  \n",
       " 0       28.048859  1.122280  1.460502  1.437740  269.243042  0.543918       0  \n",
       " 1       30.103636  0.685859  4.431560  2.099280  270.130096  0.588064       0  \n",
       " 2       27.992128  1.004022  1.759774  1.499166  269.391785  0.499688       0  \n",
       " 3       27.682737  1.369541  2.040846  1.303867  269.461945  0.476202       0  \n",
       " 4       29.005890  1.543887  6.011993  2.875477  270.914642  0.554913       0  \n",
       " ...           ...       ...       ...       ...         ...       ...     ...  \n",
       " 100315   9.224357  0.292724 -7.000638  1.001597  274.138367  0.445861       0  \n",
       " 100316   7.812868  1.157045 -1.724448  0.532421  272.338287  0.141937       0  \n",
       " 100317   7.303724  0.707523 -2.691068  0.443145  272.637390  0.190889       0  \n",
       " 100318   6.647030  0.701253 -2.872087  0.478869  272.755371  0.171153       0  \n",
       " 100319   4.571213  0.819127 -3.913635  0.495877  272.976868  0.151484       0  \n",
       " \n",
       " [100320 rows x 65 columns],\n",
       "              time  station_id     t2m\n",
       " 313440 2010-01-01           0  280.75\n",
       " 313441 2010-01-01           1  280.85\n",
       " 313442 2010-01-01           2  280.65\n",
       " 313443 2010-01-01           3  280.05\n",
       " 313444 2010-01-01           4  281.75\n",
       " ...           ...         ...     ...\n",
       " 413755 2013-12-31         115  281.35\n",
       " 413756 2013-12-31         116  279.35\n",
       " 413757 2013-12-31         117  278.25\n",
       " 413758 2013-12-31         118  273.15\n",
       " 413759 2013-12-31         119  272.65\n",
       " \n",
       " [100320 rows x 3 columns])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:34:18.467205Z",
     "start_time": "2025-05-19T23:34:18.064601Z"
    }
   },
   "cell_type": "code",
   "source": "dataframes['train'][0].nunique()",
   "id": "b52ee2fb8e5ca77b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time                  2612\n",
       "station_id             120\n",
       "model_orography        114\n",
       "station_altitude       116\n",
       "station_latitude       120\n",
       "                     ...  \n",
       "v_mean              301729\n",
       "v_std               302992\n",
       "t_mean              245228\n",
       "t_std               302992\n",
       "number                   1\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GNN Architecture",
   "id": "102eda0f19a9c8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:00:46.012491Z",
     "start_time": "2025-05-20T18:00:45.996794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gnn architecture\n",
    "class DeepSetAggregator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(DeepSetAggregator, self).__init__()\n",
    "\n",
    "        self.input = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        self.hidden1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.hidden2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.output = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, index):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        # print(f\"DS - Input: {x.shape}\")\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        # print(f\"DS - Hidden1: {x.shape}\")\n",
    "        x = scatter(x, index, dim=0, reduce=\"mean\")\n",
    "        # print(f\"DS - scatter: {x.shape}\")\n",
    "        # print(f\"DS - index: {index}\")\n",
    "        self.hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        # print(f\"DS - Hidden2: {x.shape}\")\n",
    "        x = self.output(x)\n",
    "        # print(f\"DS - output: {x.shape}\")\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResGnn(torch.nn.Module):\n",
    "    def __init__(self, edge_dim: int, in_channels: int, out_channels: int, num_layers: int, hidden_channels: int, heads: int):\n",
    "        super(ResGnn, self).__init__()\n",
    "        assert num_layers > 0, \"num_layers must be > 0.\"\n",
    "\n",
    "        # Create Layers\n",
    "        self.convolutions = ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convolutions.append(\n",
    "                GATv2Conv(-1, hidden_channels, heads=heads, edge_dim=edge_dim, add_self_loops=True, fill_value=0.01)\n",
    "            )\n",
    "        self.lin = Linear(hidden_channels * heads, out_channels)\n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.float()\n",
    "        edge_attr = edge_attr.float()\n",
    "        for i, conv in enumerate(self.convolutions):\n",
    "            if i == 0:\n",
    "                # First Layer\n",
    "                x = conv(x, edge_index, edge_attr)\n",
    "                x = self.relu(x)\n",
    "            else:\n",
    "                x = x + self.relu(conv(x, edge_index, edge_attr))  # Residual Layers\n",
    "\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attention(\n",
    "        self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Runs a forward Pass for the given graph only though the ResGNN layer.\n",
    "        NOTE: the data that is given to this method must first pass through the layers before this layer in the Graph\n",
    "\n",
    "        :param torch.Tensor x: Tensor of Node Features (NxD)\n",
    "        :param torch.Tensor edge_index: Tensor of Edges (2xE)\n",
    "        :param torch.Tensor edge_attr: Edge Attributes (ExNum_Attr)\n",
    "        :return x, edge_index_attention, attention_weights: Tensor of Node Features (NxD), Tensor of Edges with\n",
    "        self loops (2xE), Tensor of Attention per edge (ExNum_Heads)\n",
    "        \"\"\"\n",
    "        x = x.float()\n",
    "        edge_attr = edge_attr.float()\n",
    "\n",
    "        # Pass Data though Layer to get the Attention\n",
    "        attention_list = []\n",
    "        # Note: edge_index_attention has to be added since we have self loops now\n",
    "        edge_index_attention, attention_weights = None, None\n",
    "\n",
    "        for i, conv in enumerate(\n",
    "            self.convolutions,\n",
    "        ):\n",
    "            if i == 0:\n",
    "                # First Layer\n",
    "                x, (edge_index_attention, attention_weights) = conv(\n",
    "                    x, edge_index, edge_attr, return_attention_weights=True\n",
    "                )\n",
    "                print(\"attention_weights:\")\n",
    "                print(attention_weights)\n",
    "                print(\"edge_index_attention\")\n",
    "                print(edge_index_attention)\n",
    "                print(f\"attention_weights.shape{attention_weights.shape}\")\n",
    "                print(f\"type(attention_weights){type(attention_weights)}\")\n",
    "                attention_list.append(attention_weights)\n",
    "                x = self.relu(x)\n",
    "                x = self.norm(x)\n",
    "            else:\n",
    "                x_conv, (edge_index_attention, attention_weights) = conv(\n",
    "                    x, edge_index, edge_attr, return_attention_weights=True\n",
    "                )\n",
    "                attention_list.append(attention_weights)\n",
    "                x = x + self.relu(x_conv)  # Residual Layers\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Attention weights of first layer\n",
    "        attention_weights = attention_weights.mean(dim=1)\n",
    "        print(\"attention_weights.mean(dim=1)\")\n",
    "        print(attention_weights)\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "        return x, edge_index_attention, attention_weights, attention_list\n",
    "\n",
    "# gnn architecture\n",
    "class ThisMultigraph(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        edge_dim,\n",
    "        in_channels,\n",
    "        hidden_channels_gnn,\n",
    "        out_channels_gnn,\n",
    "        num_layers_gnn,\n",
    "        heads,\n",
    "        hidden_channels_deepset,\n",
    "        optimizer_class,\n",
    "        optimizer_params,\n",
    "    ):\n",
    "        super(ThisMultigraph, self).__init__()\n",
    "\n",
    "        self.encoder = EmbedStations(num_stations_max=120, embedding_dim=embedding_dim)\n",
    "\n",
    "        self.conv = ResGnn(\n",
    "            edge_dim=edge_dim,\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels_gnn,\n",
    "            out_channels=out_channels_gnn,\n",
    "            num_layers=num_layers_gnn,\n",
    "            heads=heads,\n",
    "        )\n",
    "\n",
    "        self.aggr = DeepSetAggregator(\n",
    "            in_channels=out_channels_gnn, hidden_channels=hidden_channels_deepset, out_channels=2\n",
    "        )\n",
    "\n",
    "        self.postprocess = MakePositive()\n",
    "        self.loss_fn = NormalCRPS()\n",
    "\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch_id, node_idx = data.x, data.edge_index, data.edge_attr, data.batch, data.n_idx\n",
    "        node_idx = node_idx + batch_id * 120  # add batch_id to node_idx to get unique node indices\n",
    "        # print(f\"GNN - input: {x.shape}\")\n",
    "        x = self.encoder(x)\n",
    "        # print(f\"GNN - embedding: {x.shape}\")\n",
    "        x = self.conv(x, edge_index, edge_attr)\n",
    "        # print(f\"GNN - after conv: {x.shape}\")\n",
    "        x = self.aggr(x, node_idx)\n",
    "        # print(f\"GNN - after aggr: {x.shape}\")\n",
    "        x = self.postprocess(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=1\n",
    "        )  # The batch size is not actually 1 but the loss is already averaged over the batch\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.parameters(), **self.optimizer_params)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        y_hat = self.forward(batch)\n",
    "        loss = self.loss_fn.crps(mu_sigma=y_hat, y=batch.y)\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        return loss\n",
    "\n",
    "    def initialize(self, dataloader):\n",
    "        batch = next(iter(dataloader))\n",
    "        self.validation_step(batch, 0)"
   ],
   "id": "4b0c09236490cd26",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check DeepSetAggregator and ResGNN outside of Multigraph",
   "id": "b25f56cbcc8e7dcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T20:37:01.362483Z",
     "start_time": "2025-05-20T20:36:46.638852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    training_data=dataframes[\"train\"],\n",
    "    valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    mat=dist,\n",
    "    max_dist=config['max_dist'],\n",
    ")\n",
    "graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "graphs_test = graphs_test_rf\n",
    "\n",
    "# print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n",
    "\n",
    "print(\"[INFO] Creating data loaders...\")\n",
    "train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "print(\"[INFO] Creating model...\")\n",
    "emb_dim=20\n",
    "in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1\n"
   ],
   "id": "eb207df0bf6978e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "[INFO] Creating graph data...\n",
      "[INFO] Creating data loaders...\n",
      "[INFO] Creating model...\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:01:18.677715Z",
     "start_time": "2025-05-20T18:01:18.670713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_dim=emb_dim\n",
    "in_channels=in_channels\n",
    "hidden_channels_gnn=config['gnn_hidden']\n",
    "out_channels_gnn=config['gnn_hidden']\n",
    "num_layers_gnn=config['gnn_hidden']\n",
    "heads=config['heads']\n",
    "hidden_channels_deepset=config['gnn_hidden']\n",
    "optimizer_class=AdamW\n",
    "optimizer_params=dict(lr=config['lr'])\n"
   ],
   "id": "b977193b0cc8f5a6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:01:15.893989Z",
     "start_time": "2025-05-20T18:01:15.886320Z"
    }
   },
   "cell_type": "code",
   "source": "graphs_test_rf[0].x.shape",
   "id": "ffe86be0d54b0aa5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 65])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train GNN",
   "id": "d2a71ee480a1bedb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:27:55.858196Z",
     "start_time": "2025-05-20T18:23:37.465379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train gnn\n",
    "# build a graph with wandb => create multigraph - without summmary_statistics and no edges removed\n",
    "with wandb.init(\n",
    "    project=\"multigraph\", id=f\"training_run_24h_8\", config=args_dict, tags=[\"final_training\"]\n",
    "):\n",
    "    config = wandb.config\n",
    "    #print(\"[INFO] Starting sweep with config: \", config)\n",
    "\n",
    "    # graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    #     training_data=dataframes[\"train\"],\n",
    "    #     valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    #     mat=dist,\n",
    "    #     max_dist=config['max_dist'],\n",
    "    # )\n",
    "    # graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "    # graphs_test = graphs_test_rf\n",
    "\n",
    "    # print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n",
    "\n",
    "    # print(\"[INFO] Creating data loaders...\")\n",
    "    # train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    # print(\"[INFO] Creating model...\")\n",
    "    # emb_dim=20\n",
    "    # in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1 #(36 + 20 - 1) = 55\n",
    "\n",
    "    multigraph = ThisMultigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        edge_dim = 1,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph)\n",
    "\n",
    "    # understand what this is\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch  # .to(\"cuda\")\n",
    "    multigraph  # .to(\"cuda\")\n",
    "    multigraph.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"multigraph\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    # print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph, train_dataloaders=train_loader)\n",
    "wandb.finish()"
   ],
   "id": "38ba57bc26ec34e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250520_202337-training_run_24h_8</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph/runs/training_run_24h_8' target=\"_blank\">training_run_24h_8</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph/runs/training_run_24h_8' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph/runs/training_run_24h_8</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/gnn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 878 K  | train\n",
      "2 | aggr        | DeepSetAggregator | 197 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.317     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 327/327 [00:06<00:00, 51.46it/s, v_num=4h_8, train_loss_step=0.821, train_loss_epoch=0.561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=40` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 327/327 [00:06<00:00, 51.13it/s, v_num=4h_8, train_loss_step=0.821, train_loss_epoch=0.561]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▃▄▄▃▃▃▂▂▂▃▃▂▂▂▃▂▂▂▃▂▃▁▃▂▂▃▂▃▂▂▂▃▂▄▃▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>train_loss_epoch</td><td>0.56101</td></tr><tr><td>train_loss_step</td><td>0.8215</td></tr><tr><td>trainer/global_step</td><td>13079</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h_8</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph/runs/training_run_24h_8' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph/runs/training_run_24h_8</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/multigraph</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_202337-training_run_24h_8/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T23:22:30.120578Z",
     "start_time": "2025-04-13T23:15:18.614908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with wandb.init(\n",
    "    project=\"multigraph\", id=f\"training_run_24h_4\", config=args_dict, tags=[\"final_training\"], reinit=True\n",
    "):\n",
    "    config = wandb.config\n",
    "    edge_dim = 1\n",
    "    #print(\"[INFO] Starting sweep with config: \", config)\n",
    "\n",
    "    # graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    #     training_data=dataframes[\"train\"],\n",
    "    #     valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    #     mat=dist,\n",
    "    #     max_dist=config['max_dist'],\n",
    "    # )\n",
    "    # graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "    # graphs_test = graphs_test_rf\n",
    "\n",
    "    # print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n",
    "\n",
    "    # print(\"[INFO] Creating data loaders...\")\n",
    "    # train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    # print(\"[INFO] Creating model...\")\n",
    "    # emb_dim=20\n",
    "    # in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1 #(36 + 20 - 1) = 55\n",
    "\n",
    "    multigraph2 = Multigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph2)\n",
    "\n",
    "    # understand what this is\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch  # .to(\"cuda\")\n",
    "    multigraph2  # .to(\"cuda\")\n",
    "    multigraph2.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"multigraph\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    # print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph2, train_dataloaders=train_loader)\n",
    "wandb.finish()"
   ],
   "id": "cc5ea43f19dec856",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250414_011518-training_run_24h_4</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4' target=\"_blank\">training_run_24h_4</a></strong> to <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/gnn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.571    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:13<00:00, 31.66it/s, v_num=4h_4, train_loss_step=0.510, train_loss_epoch=0.515]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=31` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:13<00:00, 31.65it/s, v_num=4h_4, train_loss_step=0.510, train_loss_epoch=0.515]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▇▃▄▅▅▃▄▃▄▄▄▃▂▂▃▃▃▃▃▅▅▃▂▃▄▄▂▂▃▂▁▁▁▁▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_loss_epoch</td><td>0.51528</td></tr><tr><td>train_loss_step</td><td>0.51018</td></tr><tr><td>trainer/global_step</td><td>13360</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h_4</strong> at: <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_4</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_011518-training_run_24h_4/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:57:02.717440Z",
     "start_time": "2025-04-15T01:56:34.286564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l_graphs_train_rf, l_tests = normalize_features_and_create_graphs1(df_train=dataframes['train'], df_valid_test=[dataframes['test_rf'], dataframes['test_f']], station_df=dataframes['stations'], attributes=[\"geo\"], edges=[(\"geo\", 100)], sum_stats = True)\n",
    "l_graphs_test_rf, l_graphs_test_f = l_tests\n",
    "l_graphs_test = l_graphs_test_rf\n",
    "\n",
    "l_train_loader = DataLoader(l_graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "print(l_graphs_train_rf[0].num_edge_features)"
   ],
   "id": "55c030c8b9f1733a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n",
      "transform 2\n",
      "[INFO] Converting temperature values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3448/3448 [00:16<00:00, 207.67it/s]\n",
      "100%|██████████| 732/732 [00:02<00:00, 281.24it/s]\n",
      "100%|██████████| 730/730 [00:02<00:00, 264.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:57:02.727771Z",
     "start_time": "2025-04-15T01:57:02.722665Z"
    }
   },
   "cell_type": "code",
   "source": "l_graphs_train_rf[0].y",
   "id": "4b07e8bab02b0a41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.6000,  6.4000,  3.3000,  2.6000,  6.2000,  3.3000,  4.3000,  2.1000,\n",
       "         3.1000,  4.8000,  1.2000,  3.1000,  2.1000,  1.1000,  3.4000, -0.5000,\n",
       "         2.5000,  8.9000,  8.7000,     nan,  8.3000,  8.8000,  8.3000,  6.9000,\n",
       "         7.9000,  6.7000,  7.4000,  6.1000,  8.6000,  5.8000,  5.7000, -4.6000,\n",
       "        -3.2000, -4.6000,     nan, -2.0000,  5.6000,  5.9000, -1.5000,  2.7000,\n",
       "         7.8000,  2.7000,  2.9000,  0.9000, -1.2000,  2.4000, -3.7000,  0.4000,\n",
       "        -2.4000,  1.3000, -0.2000, -0.1000,  2.1000,  4.3000,  5.1000,  6.7000,\n",
       "        -3.3000,  1.6000,  2.4000,  0.0000, -1.0000, -0.1000,     nan,  5.1000,\n",
       "         0.3000,  3.5000,  6.0000,  1.1000, -5.2000,  1.7000,  3.9000,  3.0000,\n",
       "         5.4000,  6.8000,     nan, -3.2000,  4.2000,  0.4000, -1.2000,  1.6000,\n",
       "         5.2000,  9.6000,  8.8000,  8.5000,  9.1000,  8.4000,  8.3000,  8.8000,\n",
       "         8.9000,  8.7000,  7.6000,  6.9000,  8.7000,  7.8000,  6.7000,  6.3000,\n",
       "         7.4000,  7.1000,  8.2000,  8.0000,  6.7000,  4.5000,  8.5000,  7.4000,\n",
       "         7.5000,  6.1000,  5.2000,  3.8000,  4.5000,  5.6000,  8.6000,  8.0000,\n",
       "         7.0000,  6.2000,  5.9000,  5.7000,  5.8000,  6.3000,  4.2000,  3.2000,\n",
       "        -0.8000, -0.7000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T02:06:07.747931Z",
     "start_time": "2025-04-15T01:58:31.455616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with wandb.init(\n",
    "    project=\"multigraph\", id=f\"training_run_24h_10\", config=args_dict, tags=[\"final_training\"], reinit=True\n",
    "):\n",
    "    config = wandb.config\n",
    "    edge_dim = l_graphs_train_rf[0].num_edge_features\n",
    "    #print(\"[INFO] Starting sweep with config: \", config)\n",
    "\n",
    "    # graphs_train_rf, tests = normalize_features_and_create_graphs(\n",
    "    #     training_data=dataframes[\"train\"],\n",
    "    #     valid_test_data=[dataframes[\"test_rf\"], dataframes[\"test_f\"]],\n",
    "    #     mat=dist,\n",
    "    #     max_dist=config['max_dist'],\n",
    "    # )\n",
    "    # graphs_test_rf, graphs_test_f = tests\n",
    "\n",
    "    # graphs_test = graphs_test_rf\n",
    "\n",
    "    # print(graphs_test_rf[0].x.shape) (1342, 36)\n",
    "\n",
    "\n",
    "    # print(\"[INFO] Creating data loaders...\")\n",
    "    # train_loader = DataLoader(graphs_train_rf, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    # print(\"[INFO] Creating model...\")\n",
    "    # emb_dim=20\n",
    "    # in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1 #(36 + 20 - 1) = 55\n",
    "\n",
    "    multigraph3 = Multigraph(\n",
    "        embedding_dim=emb_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels_gnn=config['gnn_hidden'],\n",
    "        out_channels_gnn=config['gnn_hidden'],\n",
    "        num_layers_gnn=config['gnn_layers'],\n",
    "        heads=config['heads'],\n",
    "        hidden_channels_deepset=config['gnn_hidden'],\n",
    "        optimizer_class=AdamW,\n",
    "        optimizer_params=dict(lr=config['lr']),\n",
    "    )\n",
    "    torch.compile(multigraph3)\n",
    "\n",
    "    # understand what this is\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch  # .to(\"cuda\")\n",
    "    # multigraph3  # .to(\"cuda\")\n",
    "    multigraph3.forward(batch)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"multigraph\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=SAVEPATH, filename=f\"run_24h\", monitor=\"train_loss\", mode=\"min\", save_top_k=1\n",
    "    )\n",
    "\n",
    "    # print(\"[INFO] Training model...\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['max_epochs'],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=checkpoint_callback,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=multigraph3, train_dataloaders=l_train_loader)\n",
    "wandb.finish()"
   ],
   "id": "2e45cf05cf1cc24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250415_035831-training_run_24h_10</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10' target=\"_blank\">training_run_24h_10</a></strong> to <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ltchen/gnnpp/explored_models/gnn_24h/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.571    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:15<00:00, 28.58it/s, v_num=h_10, train_loss_step=0.473, train_loss_epoch=0.486]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=31` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 431/431 [00:15<00:00, 28.01it/s, v_num=h_10, train_loss_step=0.473, train_loss_epoch=0.486]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▆▇▄▆▅▄▅▅▂▅▃▄▂▃▃▃▂▃▃▃▄▃▂▁▁▂▂▁▂▂▂▃▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_loss_epoch</td><td>0.48608</td></tr><tr><td>train_loss_step</td><td>0.47318</td></tr><tr><td>trainer/global_step</td><td>13360</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training_run_24h_10</strong> at: <a href='https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph/runs/training_run_24h_10</a><br> View project at: <a href='https://wandb.ai/leachen_thesis/multigraph' target=\"_blank\">https://wandb.ai/leachen_thesis/multigraph</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250415_035831-training_run_24h_10/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:28:25.483276Z",
     "start_time": "2025-05-20T18:28:22.066125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate gnn\n",
    "test_loader = DataLoader(graphs_test, batch_size=1, shuffle=False)\n",
    "\n",
    "# multigraph.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "# trainer = L.Trainer(log_every_n_steps=1, accelerator=\"gpu\", devices=1, enable_progress_bar=True)\n",
    "preds_list = []\n",
    "preds = trainer.predict(model=multigraph, dataloaders=[test_loader])\n"
   ],
   "id": "649e4aadb19512f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 732/732 [00:03<00:00, 217.22it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:28:27.785050Z",
     "start_time": "2025-05-20T18:28:27.747155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds = [prediction.reshape(1, 120, 2).mean(axis=0) for prediction in preds] #ACHTUNG - reshape(1, 122, 2) mit 1 statt 5!\n",
    "preds = torch.cat(preds, dim=0)\n",
    "preds_list.append(preds)\n",
    "\n",
    "targets = dataframes[\"test_rf\"][1]\n",
    "targets = torch.tensor(targets.t2m.values) - 273.15\n",
    "\n",
    "stacked = torch.stack(preds_list)\n",
    "final_preds = torch.mean(stacked, dim=0)\n",
    "\n",
    "res = multigraph.loss_fn.crps(final_preds, targets)\n",
    "print(\"#############################################\")\n",
    "print(\"#############################################\")\n",
    "print(f\"final crps: {res.item()}\")\n",
    "print(\"#############################################\")\n",
    "print(\"#############################################\")\n"
   ],
   "id": "2525dcc85239cc4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "#############################################\n",
      "final crps: 0.6571427750898216\n",
      "#############################################\n",
      "#############################################\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:58:22.905772Z",
     "start_time": "2025-04-03T17:58:22.896280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for prediction in preds:\n",
    "    print(prediction.shape)"
   ],
   "id": "65de3e43231fce44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([122, 2])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T03:00:22.392550Z",
     "start_time": "2025-03-11T03:00:22.105868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "3315937a70662a07",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
