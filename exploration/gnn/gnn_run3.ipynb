{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Run GNNs\n",
    "with early stopping, validation dataset, and learning rate hyperparameter tuning"
   ],
   "id": "406c6b3109ab80a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:37:04.354059Z",
     "start_time": "2025-04-21T05:37:01.267845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%cd /home/ltchen/gnnpp\n",
    "import sys\n",
    "import os\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torch_geometric\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.utils import scatter\n",
    "from torch.nn import Linear, ModuleList, ReLU\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
    "from torch.optim import AdamW\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from models.loss import NormalCRPS\n",
    "from models.model_utils import MakePositive, EmbedStations\n",
    "from utils.data import (\n",
    "    load_dataframes,\n",
    "    load_distances,\n",
    "    normalize_features_and_create_graphs,\n",
    "    rm_edges,\n",
    "    summary_statistics,\n",
    ")\n",
    "from exploration.graph_creation import *\n",
    "from models.graphensemble.multigraph import *"
   ],
   "id": "fdc454e9605a4cda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ltchen/gnnpp\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:37:04.809843Z",
     "start_time": "2025-04-21T05:37:04.801732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "DIRECTORY = os.getcwd()\n",
    "SAVEPATH = os.path.join(DIRECTORY, \"explored_models/gnn3_24h/models\")\n",
    "JSONPATH = os.path.join(DIRECTORY, \"trained_models/best_24h/params.json\") # change learning rates! - check moritz' BA\n",
    "\n",
    "# with open(JSONPATH, \"r\") as f:\n",
    "#     print(f\"[INFO] Loading {JSONPATH}\")\n",
    "#     args_dict = json.load(f)\n",
    "# config = args_dict\n",
    "# learning_rates = [0.002, 0.0002, 0.00002]\n",
    "#\n",
    "# print(config)\n",
    "# print(config['lr'])\n",
    "# print(config['max_dist'])\n",
    "# print(type(config))\n",
    "# print(type(config['lr']))\n",
    "# print(type(config['gnn_hidden']))\n",
    "# print(config['gnn_hidden'])\n",
    "# print(config['batch_size'])\n",
    "# '''{\"batch_size\":8,\n",
    "# \"gnn_hidden\":265,\n",
    "# \"gnn_layers\":2,\n",
    "# \"heads\":8,\n",
    "# \"lr\":0.0002, # could also try 0.001, or 0.00005?\n",
    "# \"max_dist\":100,\n",
    "# \"max_epochs\": 31}'''"
   ],
   "id": "cf6853e515da782a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:37:16.894124Z",
     "start_time": "2025-04-21T05:37:16.888221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    \"batch_size\":8,\n",
    "    \"gnn_hidden\":265,\n",
    "    \"gnn_layers\":2,\n",
    "    \"heads\":8,\n",
    "    \"lr_list\": [0.0002, 0.00007],\n",
    "    # \"max_dist\":100,\n",
    "    \"max_epochs\": 50}"
   ],
   "id": "c706f22a99ce65c9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:37:21.368621Z",
     "start_time": "2025-04-21T05:37:18.866382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = load_dataframes(mode=\"hyperopt\", leadtime= \"24h\") # load newly created dataframes\n",
    "dataframes = summary_statistics(dataframes)\n"
   ],
   "id": "7a889d0cb132f630",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframes exist. Will load pandas dataframes.\n",
      "[INFO] Calculating summary statistics for train\n",
      "[INFO] Calculating summary statistics for valid\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph 1",
   "id": "6c6e35e6e1b7f66a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:37:44.258804Z",
     "start_time": "2025-04-21T05:37:24.839714Z"
    }
   },
   "cell_type": "code",
   "source": "graphs_train_rf, graphs_valid_rf = normalize_features_and_create_graphs1(df_train=dataframes['train'], df_valid_test=[dataframes['valid']], station_df=dataframes['stations'], attributes=[\"geo\"], edges=[(\"geo\", 100)], sum_stats = True)\n",
   "id": "4fddbe4ff4726481",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2612/2612 [00:11<00:00, 222.73it/s]\n",
      "100%|██████████| 836/836 [00:03<00:00, 251.19it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:38:34.362589Z",
     "start_time": "2025-04-21T05:38:31.410119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FILENAME = \"g1_train_run_24h\"\n",
    "PROJECTNAME = \"gnn_run3p7\"\n",
    "for lr in config['lr_list']:\n",
    "    sweep_config = {**config, \"learning_rate\": lr}\n",
    "    with wandb.init(\n",
    "                project=PROJECTNAME, id=FILENAME+f\"_{lr}\", config=sweep_config, tags=[\"earlystop\", \"lr_tuning\"], reinit=True\n",
    "        ):\n",
    "        run_config = wandb.config\n",
    "        print(run_config['batch_size'])\n",
    "\n",
    "        print(\"[INFO] Creating data loaders...\")\n",
    "        g1_train_loader = DataLoader(graphs_train_rf, batch_size=run_config['batch_size'], shuffle=True)\n",
    "        g1_valid_loader = DataLoader(graphs_valid_rf[0], batch_size=run_config['batch_size'], shuffle=False)\n",
    "        train_loader = g1_train_loader\n",
    "        valid_loader = g1_valid_loader\n",
    "\n",
    "        print(\"[INFO] Creating model...\")\n",
    "        emb_dim=20\n",
    "        in_channels = graphs_train_rf[0].x.shape[1] + emb_dim - 1\n",
    "        edge_dim = graphs_train_rf[0].num_edge_features\n",
    "\n",
    "        multigraph = Multigraph(\n",
    "            embedding_dim=emb_dim,\n",
    "            edge_dim=edge_dim,\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels_gnn=run_config['gnn_hidden'],\n",
    "            out_channels_gnn=run_config['gnn_hidden'],\n",
    "            num_layers_gnn=run_config['gnn_layers'],\n",
    "            heads=run_config['heads'],\n",
    "            hidden_channels_deepset=run_config['gnn_hidden'],\n",
    "            optimizer_class=AdamW,\n",
    "            optimizer_params=dict(lr=run_config['learning_rate']),\n",
    "        )\n",
    "        torch.compile(multigraph)\n",
    "\n",
    "        # initialize\n",
    "        batch = next(iter(train_loader))\n",
    "        multigraph.forward(batch)\n",
    "\n",
    "        wandb_logger = WandbLogger(project=PROJECTNAME)\n",
    "        early_stop = EarlyStopping(monitor=\"val_loss\", patience=7)\n",
    "        progress_bar = TQDMProgressBar(refresh_rate=0)\n",
    "\n",
    "        # Train Model ###################################################################\n",
    "        print(\"[INFO] Training model...\")\n",
    "        trainer = L.Trainer(\n",
    "            max_epochs=run_config['max_epochs'],\n",
    "            log_every_n_steps=1,\n",
    "            accelerator=\"gpu\",\n",
    "            enable_progress_bar=True,\n",
    "            logger=wandb_logger,\n",
    "            refresh_rate = 0,\n",
    "            callbacks=early_stop,\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=multigraph, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ],
   "id": "acef98af56e5014d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_073831-g1_train_run_24h_0.0002</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g1_train_run_24h_0.0002' target=\"_blank\">g1_train_run_24h_0.0002</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g1_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g1_train_run_24h_0.0002</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[INFO] Creating data loaders...\n",
      "[INFO] Creating model...\n",
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3847497/3978896556.py\", line 46, in <module>\n",
      "    trainer = L.Trainer(\n",
      "  File \"/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py\", line 70, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "TypeError: Trainer.__init__() got an unexpected keyword argument 'refresh_rate'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g1_train_run_24h_0.0002</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g1_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g1_train_run_24h_0.0002</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_073831-g1_train_run_24h_0.0002/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'refresh_rate'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 46\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# Train Model ###################################################################\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[INFO] Training model...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 46\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mL\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_epochs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_every_n_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwandb_logger\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrefresh_rate\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(model\u001B[38;5;241m=\u001B[39mmultigraph, train_dataloaders\u001B[38;5;241m=\u001B[39mtrain_loader, val_dataloaders\u001B[38;5;241m=\u001B[39mvalid_loader)\n",
      "File \u001B[0;32m~/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py:70\u001B[0m, in \u001B[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mlist\u001B[39m(env_variables\u001B[38;5;241m.\u001B[39mitems()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mitems()))\n\u001B[1;32m     69\u001B[0m \u001B[38;5;66;03m# all args were already moved to kwargs\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: Trainer.__init__() got an unexpected keyword argument 'refresh_rate'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph 2",
   "id": "212da45f7fe8b1d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:39:09.250640Z",
     "start_time": "2025-04-21T05:38:46.405938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g2_train_rf, g2_valid_rf = normalize_features_and_create_graphs1(df_train=dataframes['train'],\n",
    "                                                                 df_valid_test=[dataframes['valid']],\n",
    "                                                                 station_df=dataframes['stations'],\n",
    "                                                                 attributes=[\"geo\", \"alt\", \"lon\", \"lat\", \"alt-orog\"], edges=[(\"geo\", 100)],\n",
    "                                                                 sum_stats=True)"
   ],
   "id": "ac9b48442cdc593c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2612/2612 [00:11<00:00, 227.65it/s]\n",
      "100%|██████████| 836/836 [00:03<00:00, 266.21it/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:39:36.998245Z",
     "start_time": "2025-04-21T05:39:36.989051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[INFO] Creating data loaders...\")\n",
    "g2_train_loader = DataLoader(g2_train_rf, batch_size=config['batch_size'], shuffle=True) # GRAPH\n",
    "g2_valid_loader = DataLoader(g2_valid_rf[0], batch_size=config['batch_size'], shuffle=False) # GRAPH\n",
    "train_loader = g2_train_loader # GRAPH\n",
    "valid_loader = g2_valid_loader # GRAPH\n",
    "edge_dim = g2_train_rf[0].num_edge_features #GRAPH\n",
    "emb_dim = 20\n",
    "in_channels = g2_train_rf[0].x.shape[1] + emb_dim - 1 # GRAPH\n"
   ],
   "id": "6f7e39df21af1d6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating data loaders...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:49:21.066031Z",
     "start_time": "2025-04-21T05:39:40.418833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FILENAME = \"g2_train_run_24h\" # GRAPH\n",
    "PROJECTNAME = \"gnn_run3p7\"\n",
    "for lr in config['lr_list']:\n",
    "    sweep_config = {**config, \"learning_rate\": lr}\n",
    "    with wandb.init(\n",
    "                project=PROJECTNAME, id=FILENAME+f\"_{lr}\", config=sweep_config, tags=[\"earlystop\", \"lr_tuning\"], reinit=True\n",
    "        ):\n",
    "        run_config = wandb.config\n",
    "\n",
    "        multigraph = Multigraph(\n",
    "            embedding_dim=emb_dim,\n",
    "            edge_dim=edge_dim,\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels_gnn=run_config['gnn_hidden'],\n",
    "            out_channels_gnn=run_config['gnn_hidden'],\n",
    "            num_layers_gnn=run_config['gnn_layers'],\n",
    "            heads=run_config['heads'],\n",
    "            hidden_channels_deepset=run_config['gnn_hidden'],\n",
    "            optimizer_class=AdamW,\n",
    "            optimizer_params=dict(lr=run_config['learning_rate']),\n",
    "        )\n",
    "        torch.compile(multigraph)\n",
    "\n",
    "        # initialize\n",
    "        batch = next(iter(train_loader))\n",
    "        multigraph.forward(batch)\n",
    "\n",
    "        wandb_logger = WandbLogger(project=PROJECTNAME)\n",
    "        early_stop = EarlyStopping(monitor=\"val_loss\", patience=7)\n",
    "        progress_bar = TQDMProgressBar(refresh_rate=0)\n",
    "\n",
    "        # Train Model ###################################################################\n",
    "        print(\"[INFO] Training model...\")\n",
    "        trainer = L.Trainer(\n",
    "                max_epochs=run_config['max_epochs'],\n",
    "                log_every_n_steps=1,\n",
    "                accelerator=\"gpu\",\n",
    "                enable_progress_bar=True,\n",
    "                logger=wandb_logger,\n",
    "                callbacks=[early_stop, progress_bar],\n",
    "            )\n",
    "\n",
    "        trainer.fit(model=multigraph, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n"
   ],
   "id": "709c9c508356643b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_073940-g2_train_run_24h_0.0002</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_0.0002' target=\"_blank\">g2_train_run_24h_0.0002</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_0.0002</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.2 M    Total params\n",
      "40.639    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▃▂▂▂▂▃▂▂▂▁▂▂▂▂▁▂▂▁▂▁▁▁▁▂▂▁▂▂▁▁▁▁▁▁▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▂▂▁▁▁▁▁▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>18</td></tr><tr><td>train_loss_epoch</td><td>0.59088</td></tr><tr><td>train_loss_step</td><td>0.61253</td></tr><tr><td>trainer/global_step</td><td>6212</td></tr><tr><td>val_loss</td><td>0.67983</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g2_train_run_24h_0.0002</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_0.0002</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_073940-g2_train_run_24h_0.0002/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_074305-g2_train_run_24h_7e-05</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_7e-05' target=\"_blank\">g2_train_run_24h_7e-05</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_7e-05' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_7e-05</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.2 M    Total params\n",
      "40.639    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▃▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▂▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇██████</td></tr><tr><td>val_loss</td><td>█▅▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>34</td></tr><tr><td>train_loss_epoch</td><td>0.54642</td></tr><tr><td>train_loss_step</td><td>0.5524</td></tr><tr><td>trainer/global_step</td><td>11444</td></tr><tr><td>val_loss</td><td>0.69538</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g2_train_run_24h_7e-05</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_7e-05' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g2_train_run_24h_7e-05</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_074305-g2_train_run_24h_7e-05/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph 3",
   "id": "134f767139dd529f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:52:00.445557Z",
     "start_time": "2025-04-21T05:51:37.458064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g3_train_rf, g3_valid_rf = normalize_features_and_create_graphs1(df_train=dataframes['train'],\n",
    "                                                                 df_valid_test=[dataframes['valid']],\n",
    "                                                                 station_df=dataframes['stations'],\n",
    "                                                                 attributes=[\"geo\", \"alt\", \"lon\", \"lat\", \"alt-orog\"],\n",
    "                                                                 edges=[(\"geo\", 55), (\"alt\", 6.5), (\"alt-orog\", 2.5)],\n",
    "                                                                 sum_stats=True)"
   ],
   "id": "63efe8ac22c6a564",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2612/2612 [00:11<00:00, 222.85it/s]\n",
      "100%|██████████| 836/836 [00:03<00:00, 275.20it/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:52:00.455290Z",
     "start_time": "2025-04-21T05:52:00.450127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[INFO] Creating data loaders...\")\n",
    "g3_train_loader = DataLoader(g3_train_rf, batch_size=config['batch_size'], shuffle=True)  # GRAPH\n",
    "g3_valid_loader = DataLoader(g3_valid_rf[0], batch_size=config['batch_size'], shuffle=False)  # GRAPH\n",
    "train_loader = g3_train_loader  # GRAPH\n",
    "valid_loader = g3_valid_loader  # GRAPH\n",
    "edge_dim = g3_train_rf[0].num_edge_features  #GRAPH\n",
    "emb_dim = 20\n",
    "in_channels = g3_train_rf[0].x.shape[1] + emb_dim - 1  # GRAPH"
   ],
   "id": "752d7d12f73e46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating data loaders...\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T06:03:01.628736Z",
     "start_time": "2025-04-21T05:52:00.523816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FILENAME = \"g3_train_run_24h\"  # GRAPH\n",
    "PROJECTNAME = \"gnn_run3p7\"\n",
    "for lr in config['lr_list']:\n",
    "    sweep_config = {**config, \"learning_rate\": lr}\n",
    "    with wandb.init(\n",
    "            project=PROJECTNAME, id=FILENAME + f\"_{lr}\", config=sweep_config, tags=[\"earlystop\", \"lr_tuning\"],\n",
    "            reinit=True\n",
    "    ):\n",
    "        run_config = wandb.config\n",
    "\n",
    "        multigraph = Multigraph(\n",
    "            embedding_dim=emb_dim,\n",
    "            edge_dim=edge_dim,\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels_gnn=run_config['gnn_hidden'],\n",
    "            out_channels_gnn=run_config['gnn_hidden'],\n",
    "            num_layers_gnn=run_config['gnn_layers'],\n",
    "            heads=run_config['heads'],\n",
    "            hidden_channels_deepset=run_config['gnn_hidden'],\n",
    "            optimizer_class=AdamW,\n",
    "            optimizer_params=dict(lr=run_config['learning_rate']),\n",
    "        )\n",
    "        torch.compile(multigraph)\n",
    "\n",
    "        # initialize\n",
    "        batch = next(iter(train_loader))\n",
    "        multigraph.forward(batch)\n",
    "\n",
    "        wandb_logger = WandbLogger(project=PROJECTNAME)\n",
    "        early_stop = EarlyStopping(monitor=\"val_loss\", patience=7)\n",
    "        progress_bar = TQDMProgressBar(refresh_rate=0)\n",
    "\n",
    "        # Train Model ###################################################################\n",
    "        print(\"[INFO] Training model...\")\n",
    "        trainer = L.Trainer(\n",
    "            max_epochs=run_config['max_epochs'],\n",
    "            log_every_n_steps=1,\n",
    "            accelerator=\"gpu\",\n",
    "            enable_progress_bar=True,\n",
    "            logger=wandb_logger,\n",
    "            callbacks=[early_stop, progress_bar],\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=multigraph, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ],
   "id": "b7834f54939430a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_075200-g3_train_run_24h_0.0002</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_0.0002' target=\"_blank\">g3_train_run_24h_0.0002</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_0.0002</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory ./gnn_run3p7/g3_train_run_24h_0.0002/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.2 M    Total params\n",
      "40.639    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▄▂▂▃▂▂▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▃▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▂▁▂▁▂▂▁▁▁▂▃▂▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>26</td></tr><tr><td>train_loss_epoch</td><td>0.52703</td></tr><tr><td>train_loss_step</td><td>0.5134</td></tr><tr><td>trainer/global_step</td><td>8828</td></tr><tr><td>val_loss</td><td>0.70118</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g3_train_run_24h_0.0002</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_0.0002</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_075200-g3_train_run_24h_0.0002/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_075658-g3_train_run_24h_7e-05</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_7e-05' target=\"_blank\">g3_train_run_24h_7e-05</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_7e-05' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_7e-05</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.2 M    Total params\n",
      "40.639    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▆▅▄▄▆▅▄▃▃▄▃▅▄▂▄▂▄▂▃▄▃▃▄▁▃▃▃▁▂▂▅▂▁▂▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▁▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>32</td></tr><tr><td>train_loss_epoch</td><td>0.56314</td></tr><tr><td>train_loss_step</td><td>0.48958</td></tr><tr><td>trainer/global_step</td><td>10790</td></tr><tr><td>val_loss</td><td>0.67225</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g3_train_run_24h_7e-05</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_7e-05' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g3_train_run_24h_7e-05</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_075658-g3_train_run_24h_7e-05/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph 4",
   "id": "8c9e21bf5257e1ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T06:03:24.569914Z",
     "start_time": "2025-04-21T06:03:01.788717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g4_train_rf, g4_valid_rf = normalize_features_and_create_graphs1(df_train=dataframes['train'],\n",
    "                                                                 df_valid_test=[dataframes['valid']],\n",
    "                                                                 station_df=dataframes['stations'],\n",
    "                                                                 attributes=[\"geo\", \"alt\", \"lon\", \"lat\", \"alt-orog\"],\n",
    "                                                                 edges=[(\"geo\", 100), (\"alt\", 10), (\"alt-orog\", 5)],\n",
    "                                                                 sum_stats=True)"
   ],
   "id": "7f2ba091fcb2e41c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2612/2612 [00:11<00:00, 226.27it/s]\n",
      "100%|██████████| 836/836 [00:03<00:00, 270.15it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T06:03:24.585059Z",
     "start_time": "2025-04-21T06:03:24.576431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[INFO] Creating data loaders...\")\n",
    "g4_train_loader = DataLoader(g4_train_rf, batch_size=config['batch_size'], shuffle=True)  # GRAPH\n",
    "g4_valid_loader = DataLoader(g4_valid_rf[0], batch_size=config['batch_size'], shuffle=False)  # GRAPH\n",
    "train_loader = g4_train_loader  # GRAPH\n",
    "valid_loader = g4_valid_loader  # GRAPH\n",
    "edge_dim = g4_train_rf[0].num_edge_features  #GRAPH\n",
    "emb_dim = 20\n",
    "in_channels = g4_train_rf[0].x.shape[1] + emb_dim - 1  # GRAPH"
   ],
   "id": "b475df4221527d52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating data loaders...\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T06:19:32.312653Z",
     "start_time": "2025-04-21T06:03:24.657675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FILENAME = \"g4_train_run_24h\"  # GRAPH\n",
    "PROJECTNAME = \"gnn_run3p7\"\n",
    "for lr in config['lr_list']:\n",
    "    sweep_config = {**config, \"learning_rate\": lr}\n",
    "    with wandb.init(\n",
    "            project=PROJECTNAME, id=FILENAME + f\"_{lr}\", config=sweep_config, tags=[\"earlystop\", \"lr_tuning\"],\n",
    "            reinit=True\n",
    "    ):\n",
    "        run_config = wandb.config\n",
    "\n",
    "        multigraph = Multigraph(\n",
    "            embedding_dim=emb_dim,\n",
    "            edge_dim=edge_dim,\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels_gnn=run_config['gnn_hidden'],\n",
    "            out_channels_gnn=run_config['gnn_hidden'],\n",
    "            num_layers_gnn=run_config['gnn_layers'],\n",
    "            heads=run_config['heads'],\n",
    "            hidden_channels_deepset=run_config['gnn_hidden'],\n",
    "            optimizer_class=AdamW,\n",
    "            optimizer_params=dict(lr=run_config['learning_rate']),\n",
    "        )\n",
    "        torch.compile(multigraph)\n",
    "\n",
    "        # initialize\n",
    "        batch = next(iter(train_loader))\n",
    "        multigraph.forward(batch)\n",
    "\n",
    "        wandb_logger = WandbLogger(project=PROJECTNAME)\n",
    "        early_stop = EarlyStopping(monitor=\"val_loss\", patience=7)\n",
    "        progress_bar = TQDMProgressBar(refresh_rate=0)\n",
    "\n",
    "        # Train Model ###################################################################\n",
    "        print(\"[INFO] Training model...\")\n",
    "        trainer = L.Trainer(\n",
    "            max_epochs=run_config['max_epochs'],\n",
    "            log_every_n_steps=1,\n",
    "            accelerator=\"gpu\",\n",
    "            enable_progress_bar=True,\n",
    "            logger=wandb_logger,\n",
    "            callbacks=[early_stop, progress_bar],\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=multigraph, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ],
   "id": "d690baf8884d1f09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_080324-g4_train_run_24h_0.0002</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_0.0002' target=\"_blank\">g4_train_run_24h_0.0002</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_0.0002</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.2 M    Total params\n",
      "40.639    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▃▃▃▂▃▂▃▃▂▃▃▃▂▃▂▃▂▂▂▂▂▂▂▁▁▂▁▂▂▂▂▂▂▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▆▄▃▅▂▄▂▂▂▁▁▂▂▁▁▁▂▁▁▁▁▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>26</td></tr><tr><td>train_loss_epoch</td><td>0.53507</td></tr><tr><td>train_loss_step</td><td>0.52631</td></tr><tr><td>trainer/global_step</td><td>8828</td></tr><tr><td>val_loss</td><td>0.67461</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g4_train_run_24h_0.0002</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_0.0002</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_080324-g4_train_run_24h_0.0002/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_081019-g4_train_run_24h_7e-05</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_7e-05' target=\"_blank\">g4_train_run_24h_7e-05</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_7e-05' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_7e-05</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.2 M    Total params\n",
      "40.639    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▅▃▅▅▃▃▅▃▃▃▃▃▂▄▃▄▂▂▃▂▃▂▂▂▃▂▂▂▂▁▁▂▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▂▂▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>35</td></tr><tr><td>train_loss_epoch</td><td>0.54537</td></tr><tr><td>train_loss_step</td><td>0.46447</td></tr><tr><td>trainer/global_step</td><td>11771</td></tr><tr><td>val_loss</td><td>0.68092</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g4_train_run_24h_7e-05</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_7e-05' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7/runs/g4_train_run_24h_7e-05</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3p7</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_081019-g4_train_run_24h_7e-05/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph 5",
   "id": "a059c3df81ea883e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T06:19:47.726567Z",
     "start_time": "2025-04-21T06:19:32.534819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g5_train_rf, g5_valid_rf = normalize_features_and_create_graphs1(df_train=dataframes['train'],\n",
    "                                                                 df_valid_test=[dataframes['valid']],\n",
    "                                                                 station_df=dataframes['stations'],\n",
    "                                                                 attributes=[\"dist2\"],\n",
    "                                                                 edges=[(\"dist2\", 0.005)],\n",
    "                                                                 sum_stats=True)"
   ],
   "id": "bf3d735c796badf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Normalizing features...\n",
      "fit_transform\n",
      "transform 1\n",
      "[INFO] Loading distances from file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2612/2612 [00:11<00:00, 226.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading distances from file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 836/836 [00:03<00:00, 267.95it/s]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T06:19:47.739567Z",
     "start_time": "2025-04-21T06:19:47.732138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[INFO] Creating data loaders...\")\n",
    "g5_train_loader = DataLoader(g5_train_rf, batch_size=config['batch_size'], shuffle=True)  # GRAPH\n",
    "g5_valid_loader = DataLoader(g5_valid_rf[0], batch_size=config['batch_size'], shuffle=False)  # GRAPH\n",
    "train_loader = g5_train_loader  # GRAPH\n",
    "valid_loader = g5_valid_loader  # GRAPH\n",
    "edge_dim = g5_train_rf[0].num_edge_features  #GRAPH\n",
    "emb_dim = 20\n",
    "in_channels = g5_train_rf[0].x.shape[1] + emb_dim - 1  # GRAPH"
   ],
   "id": "6488b086f24a3024",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating data loaders...\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T06:32:59.565762Z",
     "start_time": "2025-04-21T06:19:47.809721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FILENAME = \"g5_train_run_24h\"  # GRAPH\n",
    "PROJECTNAME = \"gnn_run3\"\n",
    "for lr in config['lr_list']:\n",
    "    sweep_config = {**config, \"learning_rate\": lr}\n",
    "    with wandb.init(\n",
    "            project=PROJECTNAME, id=FILENAME + f\"_{lr}\", config=sweep_config, tags=[\"earlystop\", \"lr_tuning\"],\n",
    "            reinit=True\n",
    "    ):\n",
    "        run_config = wandb.config\n",
    "\n",
    "        multigraph = Multigraph(\n",
    "            embedding_dim=emb_dim,\n",
    "            edge_dim=edge_dim,\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels_gnn=run_config['gnn_hidden'],\n",
    "            out_channels_gnn=run_config['gnn_hidden'],\n",
    "            num_layers_gnn=run_config['gnn_layers'],\n",
    "            heads=run_config['heads'],\n",
    "            hidden_channels_deepset=run_config['gnn_hidden'],\n",
    "            optimizer_class=AdamW,\n",
    "            optimizer_params=dict(lr=run_config['learning_rate']),\n",
    "        )\n",
    "        torch.compile(multigraph)\n",
    "\n",
    "        # initialize\n",
    "        batch = next(iter(train_loader))\n",
    "        multigraph.forward(batch)\n",
    "\n",
    "        wandb_logger = WandbLogger(project=PROJECTNAME)\n",
    "        early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "        progress_bar = TQDMProgressBar(refresh_rate=0)\n",
    "\n",
    "        # Train Model ###################################################################\n",
    "        print(\"[INFO] Training model...\")\n",
    "        trainer = L.Trainer(\n",
    "            max_epochs=run_config['max_epochs'],\n",
    "            log_every_n_steps=1,\n",
    "            accelerator=\"gpu\",\n",
    "            enable_progress_bar=True,\n",
    "            logger=wandb_logger,\n",
    "            callbacks=[early_stop, progress_bar],\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=multigraph, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ],
   "id": "a3e1b5c9a1bf46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_081947-g5_train_run_24h_0.0002</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_0.0002' target=\"_blank\">g5_train_run_24h_0.0002</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_0.0002</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory ./gnn_run3/g5_train_run_24h_0.0002/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.571    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▅▄▄▃▅▂▃▃▃▃▄▃▃▄▃▃▃▂▃▄▃▄▃▃▂▂▁▃▂▄▃▄▂▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▄▄▃▃▂▃▁▅▂▂▁▁▁▂▂▁▂▃▁▂▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>27</td></tr><tr><td>train_loss_epoch</td><td>0.54943</td></tr><tr><td>train_loss_step</td><td>0.49833</td></tr><tr><td>trainer/global_step</td><td>9155</td></tr><tr><td>val_loss</td><td>0.66176</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g5_train_run_24h_0.0002</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_0.0002' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_0.0002</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_081947-g5_train_run_24h_0.0002/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/ltchen/gnnpp/wandb/run-20250421_082444-g5_train_run_24h_7e-05</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_7e-05' target=\"_blank\">g5_train_run_24h_7e-05</a></strong> to <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_7e-05' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_7e-05</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory ./gnn_run3/g5_train_run_24h_7e-05/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | encoder     | EmbedStations     | 2.4 K  | train\n",
      "1 | conv        | ResGnn            | 9.9 M  | train\n",
      "2 | aggr        | DeepSetAggregator | 212 K  | train\n",
      "3 | postprocess | MakePositive      | 0      | train\n",
      "4 | loss_fn     | NormalCRPS        | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.571    Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/ltchen/.conda/envs/gnn_env4/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▃▆▄▄▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▁▁▁▂▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▃▂▃▂▂▂▁▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>46</td></tr><tr><td>train_loss_epoch</td><td>0.52845</td></tr><tr><td>train_loss_step</td><td>0.47425</td></tr><tr><td>trainer/global_step</td><td>15368</td></tr><tr><td>val_loss</td><td>0.67147</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">g5_train_run_24h_7e-05</strong> at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_7e-05' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3/runs/g5_train_run_24h_7e-05</a><br> View project at: <a href='https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3' target=\"_blank\">https://wandb.ai/leachen01-karlsruhe-institute-of-technology/gnn_run3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_082444-g5_train_run_24h_7e-05/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
