{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "from models.loss import crps_averaged\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"trained_models\"\n",
    "MODELS = [\"drn_24h\", \"drn_72h\", \"drn_120h\"]\n",
    "DATASETS = [\"rf\", \"f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drn_24h rf CRPS: 0.65 & 2.79 & 78.381\n",
      "drn_24h f CRPS: 0.614 & 4.263 & 94.873\n",
      "drn_72h rf CRPS: 0.864 & 3.885 & 80.316\n",
      "drn_72h f CRPS: 0.789 & 5.903 & 96.371\n",
      "drn_120h rf CRPS: 1.187 & 5.273 & 79.527\n",
      "drn_120h f CRPS: 1.106 & 7.989 & 95.821\n"
     ]
    }
   ],
   "source": [
    "for m in MODELS:\n",
    "    for d in DATASETS:\n",
    "        preds = pd.read_csv(os.path.join(PATH, m, f\"{d}_results.csv\"))\n",
    "        preds = preds.dropna()\n",
    "        \n",
    "        if d == \"rf\":\n",
    "            conf = (11-1)/(11+1)\n",
    "        elif d == \"f\":\n",
    "            conf = (51-1)/(51+1)\n",
    "        \n",
    "        lower, upper = norm.interval(conf, loc=preds[\"mu\"], scale=preds[\"sigma\"])\n",
    "        length = upper -lower\n",
    "        preds[\"lower\"] = lower\n",
    "        preds[\"upper\"] = upper\n",
    "        preds[\"length\"] = length\n",
    "        preds[\"hit\"] = (preds[\"lower\"] <= preds[\"t2m\"]) & (preds[\"upper\"] >= preds[\"t2m\"])\n",
    "        \n",
    "        preds.to_csv(os.path.join(PATH, m, f\"{d}_results.csv\"), index=False)\n",
    "        \n",
    "        mean_length = preds[\"length\"].mean()\n",
    "        coverage = preds[\"hit\"].mean() * 100\n",
    "        \n",
    "        mu_sigma = torch.stack([torch.Tensor(preds.mu.values), torch.Tensor(preds.sigma.values)], dim=1)\n",
    "        y = torch.Tensor(preds.t2m.values)\n",
    "        crps = crps_averaged(mu_sigma, y).item()\n",
    "        \n",
    "        print(f\"{m} {d} CRPS: {round(crps, 3)} & {round(mean_length, 3)} & {round(coverage, 3)}\")\n",
    "        \n",
    "        #Log results\n",
    "        with open(os.path.join(PATH, m, f\"{d}.txt\"), 'a') as file:\n",
    "            file.write(\"\\nMean PI length: \" + str(preds[\"length\"].mean()))\n",
    "            file.write(\"\\nCoverage: \" + str(preds[\"hit\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################\n",
      "[INFO] Starting evaluation with data: rf and leadtime: 24h\n",
      "#################################################\n",
      "[INFO] Loading trained_models/best_24h/params.json\n",
      "[INFO] Starting eval with config:  {'batch_size': 8, 'gnn_hidden': 265, 'gnn_layers': 2, 'heads': 8, 'lr': 0.0002, 'max_dist': 100, 'max_epochs': 31}\n",
      "[INFO] Creating data loaders...\n",
      "[INFO] Creating ensemble...\n",
      "[INFO] Loading model from run_1.ckpt\n",
      "[INFO] Loading model...\n",
      "[INFO] Compiling model...\n",
      "[INFO] Dummy forward pass...\n",
      "[INFO] Summary...\n",
      "+-----------------------------------------+---------------------------+----------------+------------+\n",
      "| Layer                                   | Input Shape               | Output Shape   | #Param     |\n",
      "|-----------------------------------------+---------------------------+----------------+------------|\n",
      "| Multigraph                              |                           | [859, 2]       | 10,019,707 |\n",
      "| ├─(encoder)EmbedStations                | [40, 36]                  | [40, 55]       | 2,440      |\n",
      "| │    └─(embed)Embedding                 | [40]                      | [40, 20]       | 2,440      |\n",
      "| ├─(conv)ResGnn                          | [40, 55], [2, 40], [40]   | [40, 265]      | 9,805,265  |\n",
      "| │    └─(convolutions)ModuleList         | --                        | --             | 9,243,200  |\n",
      "| │    │    └─(0)GATv2ConvJittable_11a38e | [40, 55], [2, 40], [40]   | [40, 2120]     | 243,800    |\n",
      "| │    │    └─(1)GATv2ConvJittable_63f1a5 | [40, 2120], [2, 40], [40] | [40, 2120]     | 8,999,400  |\n",
      "| │    └─(lin)Linear                      | [40, 2120]                | [40, 265]      | 562,065    |\n",
      "| │    └─(relu)ReLU                       | [40, 2120]                | [40, 2120]     | --         |\n",
      "| ├─(aggr)DeepSetAggregator               | [40, 265], [40]           | [859, 2]       | 212,002    |\n",
      "| │    └─(input)Linear                    | [40, 265]                 | [40, 265]      | 70,490     |\n",
      "| │    └─(hidden1)Linear                  | [40, 265]                 | [40, 265]      | 70,490     |\n",
      "| │    └─(hidden2)Linear                  | [859, 265]                | [859, 265]     | 70,490     |\n",
      "| │    └─(output)Linear                   | [859, 265]                | [859, 2]       | 532        |\n",
      "| │    └─(relu)ReLU                       | [40, 265]                 | [40, 265]      | --         |\n",
      "| ├─(postprocess)MakePositive             | [859, 2]                  | [859, 2]       | --         |\n",
      "| ├─(loss_fn)NormalCRPS                   | --                        | --             | --         |\n",
      "+-----------------------------------------+---------------------------+----------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from utils.data import load_dataframes, load_distances, normalize_features_and_create_graphs, split_graph\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from models.graphensemble.multigraph import Multigraph\n",
    "import torch_geometric\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from torch_geometric.nn import summary\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    class Args:\n",
    "        def __init__(self):\n",
    "            self.data = \"rf\"\n",
    "            self.leadtime = \"24h\"\n",
    "    args = Args()\n",
    "    \n",
    "    print(\"#################################################\")\n",
    "    print(f\"[INFO] Starting evaluation with data: {args.data} and leadtime: {args.leadtime}\")\n",
    "    print(\"#################################################\")\n",
    "\n",
    "    CHECKPOINT_FOLDER = f\"trained_models/best_{args.leadtime}\"\n",
    "    JSONPATH = os.path.join(CHECKPOINT_FOLDER, \"params.json\")\n",
    "\n",
    "    # Load the JSON file\n",
    "    with open(JSONPATH, \"r\") as f:\n",
    "        print(f\"[INFO] Loading {JSONPATH}\")\n",
    "        args_dict = json.load(f)\n",
    "\n",
    "    @dataclass\n",
    "    class DummyConfig:\n",
    "        pass\n",
    "\n",
    "    for key, value in args_dict.items():\n",
    "        setattr(DummyConfig, key, value)\n",
    "\n",
    "    config = DummyConfig()\n",
    "    print(\"[INFO] Starting eval with config: \", args_dict)\n",
    "\n",
    "    # Dummy Data ####################################################################\n",
    "    dummy_data =  Data(\n",
    "            x=torch.ones((5, 36)),\n",
    "            edge_index=torch.tensor([[0,1,2,3,4],[0,1,2,3,4]], dtype=torch.long),\n",
    "            edge_attr=torch.tensor([1,2,3,4,5], dtype=torch.float),\n",
    "            y=torch.tensor([1,2,3,4,5], dtype=torch.float),\n",
    "            timestamp=None,\n",
    "            n_idx=torch.tensor([0,1,2,3,4], dtype=torch.long)\n",
    "        )\n",
    "    dummy_test = [dummy_data for _ in range(100)]\n",
    "    # Create Data Loaders ###########################################################\n",
    "    print(\"[INFO] Creating data loaders...\")\n",
    "    train_loader = DataLoader(dummy_test, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    # Create Model ##################################################################\n",
    "    print(\"[INFO] Creating ensemble...\")\n",
    "\n",
    "    emb_dim = 20\n",
    "    in_channels = 55  # graphs_train_rf[0].x.shape[1] + emb_dim - 1\n",
    "\n",
    "    FOLDER = os.path.join(CHECKPOINT_FOLDER, \"models\")\n",
    "    preds_list = []\n",
    "    for path in os.listdir(FOLDER):\n",
    "        if path.endswith(\".ckpt\"):\n",
    "            print(f\"[INFO] Loading model from {path}\")\n",
    "            # Load Model from chekcpoint\n",
    "            #checkpoint = torch.load(os.path.join(FOLDER, path), map_location=\"cpu\")\n",
    "            print(f\"[INFO] Loading model...\")\n",
    "            multigraph = Multigraph(\n",
    "                embedding_dim=emb_dim,\n",
    "                in_channels=in_channels,\n",
    "                hidden_channels_gnn=config.gnn_hidden,\n",
    "                out_channels_gnn=config.gnn_hidden,\n",
    "                num_layers_gnn=config.gnn_layers,\n",
    "                heads=config.heads,\n",
    "                hidden_channels_deepset=config.gnn_hidden,\n",
    "                optimizer_class=AdamW,\n",
    "                optimizer_params=dict(lr=config.lr),\n",
    "            )\n",
    "            print(f\"[INFO] Compiling model...\")\n",
    "            torch_geometric.compile(multigraph)\n",
    "\n",
    "            print(\"[INFO] Dummy forward pass...\")\n",
    "            # run a dummy forward pass to initialize the model\n",
    "            batch = next(iter(train_loader))\n",
    "            batch = batch  # .to(\"cuda\")\n",
    "            multigraph  # .to(\"cuda\")\n",
    "            multigraph.forward(batch)\n",
    "\n",
    "            print(\"[INFO] Summary...\")\n",
    "            #multigraph.load_state_dict(checkpoint[\"state_dict\"])\n",
    "            print(summary(model=multigraph, data=batch))\n",
    "            break\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
